{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19db082",
      "metadata": {
        "id": "f19db082"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e58ad32",
      "metadata": {
        "id": "2e58ad32"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Architecture Overview:\n",
        "1. Embedding: Token IDs -> Vectors (wte)\n",
        "2. Stack of Blocks (Repeated L times):\n",
        "   - RMSNorm\n",
        "   - Attention (Mixing info between tokens)\n",
        "   - RMSNorm\n",
        "   - MLP (Processing info within a token)\n",
        "3. Final Norm\n",
        "4. LMHead: Vectors -> Logits (Probabilities)\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    \"\"\"\n",
        "    Hyperparameters for the model.\n",
        "    \"\"\"\n",
        "    # ┌─────────────────────────────────────────────────────────┐\n",
        "    # │           321M CONVERSATIONAL MODEL                     │\n",
        "    # ├─────────────────────────────────────────────────────────┤\n",
        "    # │  hidden_dim:        1024                                │\n",
        "    # │  layers:            24                                  │\n",
        "    # │  heads:             8                                   │\n",
        "    # │  head_dim:          128                                 │\n",
        "    # │  mlp_ratio:         3x                                  │\n",
        "    # │  vocab_size:        32K                                 │\n",
        "    # │  context_length:    1024                                │\n",
        "    # │  embedding:         tied (input = output projection)    │\n",
        "    # │  activation:        relu squared                        │\n",
        "    # │  position encoding: RoPE                                │\n",
        "    # ├─────────────────────────────────────────────────────────┤\n",
        "    # │  TOTAL PARAMETERS:  243,269,632                         │\n",
        "    # └─────────────────────────────────────────────────────────┘\n",
        "    # No KV cache\n",
        "    # No GQA\n",
        "\n",
        "    hidden_dim: int = 512 # hidden dimension\n",
        "    n_layers: int = 5 # May need to reduce to 22 or 20\n",
        "    n_heads: int = 4 # head dimension = hidden_dim / n_heads = 128\n",
        "    mlp_ratio: int = 3\n",
        "    vocab_size: int = 32*1024\n",
        "    # vocab_size: int = 50257\n",
        "    sequence_len: int = 256\n",
        "\n",
        "\n",
        "def norm(x):\n",
        "    \"\"\"\n",
        "    RMSNorm (Root Mean Square Layer Normalization).\n",
        "    Used to stabilize training by normalizing activation magnitudes.\n",
        "    \"\"\"\n",
        "    # Purely functional rmsnorm with no learnable params\n",
        "    return F.rms_norm(x, (x.size(-1),))\n",
        "\n",
        "\n",
        "def apply_rotatory_positional_encoding(x, cos, sin):\n",
        "    \"\"\"\n",
        "    Applies Rotary Positional Embeddings (RoPE).\n",
        "    Rotates the query and key vectors to encode relative positions.\n",
        "    \"\"\"\n",
        "    assert x.ndim == 4  # multihead attention\n",
        "    d = x.shape[3] // 2\n",
        "    x1, x2 = x[..., :d], x[..., d:] # split up last time into two halves\n",
        "    y1 = x1 * cos + x2 * sin # rotate pairs of dims\n",
        "    y2 = x1 * (-sin) + x2 * cos\n",
        "    out = torch.cat([y1, y2], 3) # re-assemble\n",
        "    out = out.to(x.dtype) # ensure input/output dtypes match\n",
        "    return out\n",
        "\n",
        "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c550322",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c550322",
        "outputId": "6dd60d26-d783-4ad8-9d51-add9a9216079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTConfig(hidden_dim=512, n_layers=5, n_heads=4, mlp_ratio=3, vocab_size=32768, sequence_len=256)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "config = GPTConfig()\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2883e9f8",
      "metadata": {
        "id": "2883e9f8"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Causal Self Attention.\n",
        "\n",
        "    1. Projects input to Q, K, V.\n",
        "    2. Applies RoPE to Q, K for position info.\n",
        "    3. Computes attention scores (Q @ K) to see how much each token cares about others. Aggregates values (V) based on scores.\n",
        "    4. Projects output to mix information across heads.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.n_heads = config.n_heads\n",
        "        self.hidden_dim = config.hidden_dim\n",
        "        self.head_dim = config.hidden_dim // config.n_heads\n",
        "\n",
        "        # Linear projections for Query, Key, Value\n",
        "        self.key = nn.Linear(self.hidden_dim, self.head_dim * self.n_heads, bias=False)\n",
        "        self.query = nn.Linear(self.hidden_dim, self.head_dim * self.n_heads, bias=False)\n",
        "        self.value = nn.Linear(self.hidden_dim, self.head_dim * self.n_heads, bias=False)\n",
        "\n",
        "        # Output projection (\"o\"): mixes results from all heads back into n_embd\n",
        "        self.proj = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cos_sin: torch.Tensor) -> torch.Tensor:\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        # 1. Projects input to Q, K, V.\n",
        "        # reshape to (B, T, n_heads, head_dim)\n",
        "        k = self.key(x).view(B, T, self.n_heads, self.head_dim)\n",
        "        q = self.query(x).view(B, T, self.n_heads, self.head_dim)\n",
        "        v = self.value(x).view(B, T, self.n_heads, self.head_dim)\n",
        "\n",
        "        # 2. Applies RoPE to Q, K for position info.\n",
        "        cos, sin = cos_sin\n",
        "        k, q = apply_rotatory_positional_encoding(k, cos, sin), apply_rotatory_positional_encoding(q, cos, sin)\n",
        "\n",
        "        # 3. Computes attention scores (Q @ K) to see how much each token cares about others.\n",
        "        q, k = norm(q), norm(k) # QK norm\n",
        "\n",
        "        # make head be batch dim, i.e. (B, T, n_heads, head_dim) -> (B, n_heads, T, head_dim)\n",
        "        # We are making the n_heads into a batch dimension so pytorch treats it as batches and\n",
        "        # applies the attention function on each head separately in parallel\n",
        "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "\n",
        "        # Re-assemble the heads side by side and project back to residual stream\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "\n",
        "        # 4. Projects output to mix information across heads.\n",
        "        y = self.proj(y)\n",
        "        return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bcf98f",
      "metadata": {
        "id": "21bcf98f"
      },
      "outputs": [],
      "source": [
        "# attn = MultiHeadAttention(config)\n",
        "# attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ed627ed",
      "metadata": {
        "id": "4ed627ed"
      },
      "outputs": [],
      "source": [
        "# for param in attn.parameters():\n",
        "#     print(type(param), param.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe7e4bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbe7e4bb",
        "outputId": "8c893b00-09fc-4d17-c9a1-95b534ade37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b48b87d",
      "metadata": {
        "id": "1b48b87d"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# summary(attn, input_size=(1, config.sequence_len, config.hidden_dim), dtypes=[torch.float32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2fc9c8",
      "metadata": {
        "id": "bc2fc9c8"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Feed Forward Network (MLP).\n",
        "    Processes each token independently (no mixing between tokens).\n",
        "    Structure: Expand -> ReLU^2 -> Contract\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.proj_up = nn.Linear(config.hidden_dim, config.hidden_dim * config.mlp_ratio, bias=False)\n",
        "        self.proj_down = nn.Linear(config.hidden_dim * config.mlp_ratio, config.hidden_dim, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.proj_up(x)\n",
        "        x = F.relu(x).square()\n",
        "        # TODO: Check if swiglu is better for 3 x hidden_dim -\n",
        "        # gelu and silu are alternatives but difference seems marginal so sticking with relu^2\n",
        "        x = self.proj_down(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bebf83f",
      "metadata": {
        "id": "6bebf83f"
      },
      "outputs": [],
      "source": [
        "# ff = FeedForward(config)\n",
        "# ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6291466b",
      "metadata": {
        "id": "6291466b"
      },
      "outputs": [],
      "source": [
        "# summary(ff, input_size=(1, config.sequence_len, config.hidden_dim), dtypes=[torch.float32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4eed103",
      "metadata": {
        "id": "f4eed103"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single Transformer Block.\n",
        "    Contains:\n",
        "    1. Attention (Communication)\n",
        "    2. MLP (Computation)\n",
        "    Both use Residual Connections (x + ...) and Pre-Norm.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "        self.ff = FeedForward(config)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cos_sin: torch.Tensor) -> torch.Tensor:\n",
        "        # Attention with residual connection\n",
        "        x = x + self.attn(norm(x), cos_sin)\n",
        "        # MLP with residual connection\n",
        "        x = x + self.ff(norm(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c4ae3c3",
      "metadata": {
        "id": "7c4ae3c3"
      },
      "outputs": [],
      "source": [
        "# block = TransformerBlock(GPTConfig())\n",
        "# block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe299056",
      "metadata": {
        "id": "fe299056"
      },
      "outputs": [],
      "source": [
        "# summary(block, input_size=(1, config.sequence_len, config.hidden_dim), dtypes=[torch.float32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694a4e76",
      "metadata": {
        "id": "694a4e76"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "    \"\"\"\n",
        "    The full GPT model.\n",
        "    Contains:\n",
        "    1. Token Embedding\n",
        "    2. Transformer Blocks (stacked)\n",
        "    3. Final Normalization\n",
        "    4. LM Head - Tied weights with token embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding = nn.Embedding(config.vocab_size, config.hidden_dim)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
        "        self.lm_head = nn.Linear(config.hidden_dim, config.vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.token_embedding.weight\n",
        "\n",
        "        self.rotary_seq_len = config.sequence_len * 10 # 10X over-compute\n",
        "        # Why 10x? This provides a generous buffer for inference/generation, allowing the model\n",
        "        # to generate sequences longer than its training length without recomputing embeddings.\n",
        "        # Note: While the embeddings support 10x length, the model's quality degrades beyond ~1.5-2x\n",
        "        # the training length due to unseen attention patterns. This buffer is for convenience,\n",
        "        # not an expectation of good performance at 10x length. Memory cost is negligible.\n",
        "\n",
        "        head_dim = config.hidden_dim // config.n_heads\n",
        "        cos, sin = self._precompute_rotary_embeddings(self.rotary_seq_len, head_dim)\n",
        "        self.register_buffer(\"cos\", cos, persistent=False) # persistent=False means it's not saved to the checkpoint\n",
        "        self.register_buffer(\"sin\", sin, persistent=False)\n",
        "\n",
        "    def forward(self, idx, targets=None, loss_reduction=\"mean\") -> torch.Tensor:\n",
        "        T = idx.shape[1]\n",
        "        cos_sin = self.cos[:, :T], self.sin[:, :T] # truncate cache to current sequence length\n",
        "        x = self.token_embedding(idx)\n",
        "        x = norm(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x, cos_sin)\n",
        "        x = norm(x)\n",
        "\n",
        "        softcap = 15 # smoothly cap the logits to the range [-softcap, softcap]\n",
        "        logits = self.lm_head(x)\n",
        "        logits = logits.float() # switch to fp32 for logit softcap and loss computation\n",
        "        logits = softcap * torch.tanh(logits / softcap) # squash the logits\n",
        "\n",
        "        if targets is not None:\n",
        "            # training: given the targets, compute and return the loss\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1, reduction=loss_reduction)\n",
        "            return loss\n",
        "        else:\n",
        "            # inference: just return the logits directly\n",
        "            return logits\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        Custom weight initialization scheme.\n",
        "\n",
        "        The initialization logic deviates from PyTorch defaults (Kaiming defaults) to improve training\n",
        "        stability and convergence for deep Transformers.\n",
        "\n",
        "        Key Difference:\n",
        "        Zero Initialization for Output Projections:\n",
        "        - Function: Sets the weights of the final linear layer in each block to zero.\n",
        "        - Why: This ensures that at initialization, the residual blocks contribute nothing to the\n",
        "            residual stream (y = x + 0). The model effectively starts as an identity function, allowing\n",
        "            unimpeded gradient flow from top to bottom. This prevents vanishing/exploding gradients\n",
        "            and provides a stable starting point for the model to gradually learn features.\n",
        "        \"\"\"\n",
        "        # Initialize the weights of the model\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Zero out the output projections of the blocks\n",
        "        for block in self.blocks:\n",
        "            torch.nn.init.zeros_(block.ff.proj_down.weight)\n",
        "            torch.nn.init.zeros_(block.attn.proj.weight)\n",
        "\n",
        "        # init the rotary embeddings\n",
        "        head_dim = self.config.hidden_dim // self.config.n_heads\n",
        "        cos, sin = self._precompute_rotary_embeddings(self.rotary_seq_len, head_dim)\n",
        "        self.cos, self.sin = cos, sin\n",
        "\n",
        "        # Cast the embeddings from fp32 to bf16: optim can tolerate it and it saves memory: both in the model and the activations\n",
        "        if self.token_embedding.weight.device.type == \"cuda\":\n",
        "            self.token_embedding.to(dtype=torch.bfloat16)\n",
        "\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"\n",
        "        Custom initialization for Linear and Embedding layers.\n",
        "\n",
        "        1. Controlled Variance (Linear Layers):\n",
        "           - Formula: std = 1 / sqrt(fan_in) * min(1, sqrt(fan_out / fan_in))\n",
        "           - Why: Standard Kaiming init often leads to activation variance that grows with depth in\n",
        "             Transformers. This custom initialization (ref: https://arxiv.org/pdf/2310.17813) stabilizes\n",
        "             activation variance across layers, specifically accounting for the network width.\n",
        "\n",
        "        2. Unit Variance (Embeddings):\n",
        "           - Function: Normal distribution with std=1.0.\n",
        "           - Why: Ensures strong initial signal strength before it enters the first normalization layer.\n",
        "        \"\"\"\n",
        "        # TODO: lm_head is linear so embedding gets initialized again as linear. Check if issue?\n",
        "        if isinstance(module, nn.Linear):\n",
        "            # https://arxiv.org/pdf/2310.17813\n",
        "            fan_out = module.weight.size(0)\n",
        "            fan_in = module.weight.size(1)\n",
        "            std = 1.0 / math.sqrt(fan_in) * min(1.0, math.sqrt(fan_out / fan_in))\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=1.0)\n",
        "\n",
        "\n",
        "    def _precompute_rotary_embeddings(self, seq_len, head_dim, base=10000, device=None):\n",
        "        # autodetect the device from model embeddings\n",
        "        if device is None:\n",
        "            device = self.token_embedding.weight.device\n",
        "        # stride the channels\n",
        "        channel_range = torch.arange(0, head_dim, 2, dtype=torch.float32, device=device)\n",
        "        inv_freq = 1.0 / (base ** (channel_range / head_dim))\n",
        "        # stride the time steps\n",
        "        t = torch.arange(seq_len, dtype=torch.float32, device=device)\n",
        "        # calculate the rotation frequencies at each (time, channel) pair\n",
        "        freqs = torch.outer(t, inv_freq)\n",
        "        cos, sin = freqs.cos(), freqs.sin()\n",
        "        cos, sin = cos.bfloat16(), sin.bfloat16() # keep them in bfloat16\n",
        "        cos, sin = cos[None, :, None, :], sin[None, :, None, :] # add batch and head dims for later broadcasting\n",
        "        return cos, sin\n",
        "\n",
        "    def setup_optimizers(self, embedding_lr=0.2, matrix_lr=0.02, weight_decay=0.0):\n",
        "        \"\"\"\n",
        "        Sets up the optimizers.\n",
        "        Uses AdamW for embeddings/head and Muon for internal linear layers.\n",
        "\n",
        "        Detailed Explanation of Hybrid Strategy:\n",
        "        ----------------------------------------\n",
        "        We use two different optimizers because different parts of the Transformer have different\n",
        "        geometric properties and optimization landscapes.\n",
        "\n",
        "        1. Muon (for internal 2D matrices):\n",
        "           - Applied to: Attention projections (c_q, c_k, c_v, c_proj) and MLP weights (c_fc, c_proj).\n",
        "           - Mechanism: Muon forces weight *updates* to be orthogonal. In linear algebra, orthogonal\n",
        "             transformations (like rotation or reflection) preserve the magnitude (norm) of the vector\n",
        "             they act on.\n",
        "           - Benefit: Deep networks suffer from vanishing/exploding gradients because signals get\n",
        "             scaled up or down at every layer. By forcing updates to be orthogonal, Muon ensures\n",
        "             signals propagate through the network without exploding in magnitude, allowing for\n",
        "             much faster and more stable training of deep layers.\n",
        "\n",
        "        2. AdamW (for embeddings & head):\n",
        "           - Applied to: Token embeddings (wte) and the final output head (lm_head).\n",
        "           - Reason: These parameters are not dense 2D matrices in the same sense (embeddings are\n",
        "             lookup tables). The concept of \"orthogonal updates\" is mathematically ill-defined or\n",
        "             harmful for vectors/lookups. AdamW is ideal here as it adapts learning rates per-parameter\n",
        "             based on update frequency (handling the sparse nature of token updates).\n",
        "\n",
        "        Do they conflict?\n",
        "        No. Both optimizers step in directions derived from the same global loss gradient, so they\n",
        "        optimize the same function. The risk is learning speed mismatch (one part learning faster\n",
        "        than the other), which we handle by manually scaling the AdamW learning rate below.\n",
        "        \"\"\"\n",
        "        model_dim = self.config.hidden_dim\n",
        "        # ddp, rank, local_rank, world_size = get_dist_info()\n",
        "        # Separate out all parameters into 3 groups (matrix, embedding, lm_head)\n",
        "        matrix_params = list(self.blocks.parameters())\n",
        "        embedding_params = list(self.token_embedding.parameters())\n",
        "        assert len(list(self.parameters())) == len(matrix_params) + len(embedding_params)\n",
        "\n",
        "        # Create the AdamW optimizer for the embedding\n",
        "        # Scale the LR for the AdamW parameters by ∝1/√dmodel (having tuned the LRs for 768 dim model)\n",
        "        dmodel_lr_scale = (model_dim / 768) ** -0.5\n",
        "        # if rank == 0:\n",
        "        print(f\"Scaling the LR for the AdamW parameters ∝1/√({model_dim}/768) = {dmodel_lr_scale:.6f}\")\n",
        "        adam_groups = [\n",
        "            dict(params=embedding_params, lr=embedding_lr * dmodel_lr_scale),\n",
        "        ]\n",
        "        adamw_kwargs = dict(betas=(0.8, 0.95), eps=1e-10, weight_decay=weight_decay)\n",
        "        AdamWFactory = partial(torch.optim.AdamW, fused=True)\n",
        "        adamw_optimizer = AdamWFactory(adam_groups, **adamw_kwargs)\n",
        "\n",
        "        # Create the Muon optimizer for the linear layers\n",
        "        muon_kwargs = dict(lr=matrix_lr, momentum=0.95)\n",
        "        muon_optimizer = Muon(matrix_params, **muon_kwargs)\n",
        "\n",
        "        # Combine the two optimizers into one list\n",
        "        optimizers = [adamw_optimizer, muon_optimizer]\n",
        "        for opt in optimizers:\n",
        "            for group in opt.param_groups:\n",
        "                group[\"initial_lr\"] = group[\"lr\"]\n",
        "        return optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6254fe9b",
      "metadata": {
        "id": "6254fe9b"
      },
      "outputs": [],
      "source": [
        "gpt = GPT(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb5f41f",
      "metadata": {
        "id": "afb5f41f"
      },
      "outputs": [],
      "source": [
        "gpt = gpt.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f25595",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6f25595",
        "outputId": "99a21d3c-3fa7-418d-dbd5-b78f485f78a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "GPT                                      [1, 256, 32768]           --\n",
              "├─Embedding: 1-1                         [1, 256, 512]             16,777,216\n",
              "├─ModuleList: 1-2                        --                        --\n",
              "│    └─TransformerBlock: 2-1             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-1      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-2             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-2             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-3      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-4             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-3             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-5      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-6             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-4             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-7      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-8             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-5             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-9      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-10            [1, 256, 512]             1,572,864\n",
              "├─Linear: 1-3                            [1, 256, 32768]           16,777,216\n",
              "==========================================================================================\n",
              "Total params: 46,661,632\n",
              "Trainable params: 46,661,632\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 46.66\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 110.10\n",
              "Params size (MB): 186.65\n",
              "Estimated Total Size (MB): 296.75\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "summary(gpt, input_size=(1, config.sequence_len), dtypes=[torch.long])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47fa1992",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47fa1992",
        "outputId": "c8946f00-9c86-4858-f7d4-6a0df9181484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual unique parameters: 29,884,416\n"
          ]
        }
      ],
      "source": [
        "# The weight tying is working correctly — torchinfo just doesn't detect shared parameters by default.\n",
        "# It counts each layer's parameters independently.\n",
        "\n",
        "# This counts UNIQUE parameters (correct count with tying)\n",
        "real_params = sum(p.numel() for p in gpt.parameters())\n",
        "print(f\"Actual unique parameters: {real_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "934e412b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "934e412b",
        "outputId": "95b156b2-9e6e-4917-f2db-edb00ecf1cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same object: True\n",
            "Same memory: True\n"
          ]
        }
      ],
      "source": [
        "# These should all be True\n",
        "print(\"Same object:\", gpt.lm_head.weight is gpt.token_embedding.weight)\n",
        "print(\"Same memory:\", gpt.lm_head.weight.data_ptr() == gpt.token_embedding.weight.data_ptr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01093d00",
      "metadata": {
        "id": "01093d00"
      },
      "outputs": [],
      "source": [
        "gpt.init_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0192d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e0192d8",
        "outputId": "88ddbda6-ba26-43b8-c853-4976676881a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer Name                               | Type            | Dtype\n",
            "----------------------------------------------------------------------\n",
            "token_embedding.weight                   | Parameter       | torch.bfloat16\n",
            "blocks.0.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.0.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.0.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.0.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.0.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.0.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.1.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.1.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.1.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.1.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.1.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.1.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.2.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.2.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.2.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.2.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.2.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.2.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.3.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.3.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.3.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.3.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.3.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.3.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.4.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.4.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.4.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.4.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.4.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.4.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "cos                                      | Buffer          | torch.bfloat16\n",
            "sin                                      | Buffer          | torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "def check_model_dtypes(model):\n",
        "    print(f\"{'Layer Name':<40} | {'Type':<15} | {'Dtype'}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Check Parameters\n",
        "    for name, param in model.named_parameters():\n",
        "        print(f\"{name:<40} | Parameter       | {param.dtype}\")\n",
        "\n",
        "    # Check Buffers (like RoPE cos/sin)\n",
        "    for name, buf in model.named_buffers():\n",
        "        print(f\"{name:<40} | Buffer          | {buf.dtype}\")\n",
        "check_model_dtypes(gpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "993fe345",
      "metadata": {
        "id": "993fe345"
      },
      "outputs": [],
      "source": [
        "# # sample input for gpt model\n",
        "# sample_input = torch.ones((1, 1), dtype=torch.int64)\n",
        "# sample_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd36d2bb",
      "metadata": {
        "id": "dd36d2bb"
      },
      "outputs": [],
      "source": [
        "# gpt.eval()\n",
        "# with torch.no_grad(): # Good practice for inference to save memory\n",
        "#     op = gpt(sample_input)\n",
        "\n",
        "# print(f\"Output shape: {op.shape}\") # Should be (1, 1, vocab_size)\n",
        "# print(f\"Max logit: {op.max().item():.4f}\")\n",
        "# print(f\"Predicted token ID: {op.argmax().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e766a77b",
      "metadata": {
        "id": "e766a77b"
      },
      "source": [
        "Predicted token is always same as the input value. Why?\n",
        "1. Weight Tying: We have set self.lm_head.weight = self.token_embedding.weight.\n",
        "2. Zero-Init Blocks: init_weights function sets the output projection of every Transformer block to zero.\n",
        " - This means the blocks (Attention and MLP) contribute nothing to the residual stream at initialization.\n",
        " - The model effectively acts as an identity function for the embeddings: Embedding(token) -> Norm -> Logits.\n",
        "3. Self-Similarity: Since the output head uses the same weights as the embedding, it calculates the dot product of the token's embedding vector with all other embedding vectors.\n",
        " - A vector's dot product with itself ($v \\cdot v$) is almost always much higher than with other random vectors ($v \\cdot w$).\n",
        " - Therefore, the model assigns the highest probability to the token that was input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b1f4c95",
      "metadata": {
        "id": "6b1f4c95"
      },
      "outputs": [],
      "source": [
        "# # loss\n",
        "# sample_input2 = torch.ones((1, 1), dtype=torch.int64)*100\n",
        "# sample_input2 = sample_input2.to(device_type)\n",
        "# print(f'loss when taget = input: {gpt(sample_input2, sample_input2)}')\n",
        "# print(f'loss when target != input: {gpt(sample_input2, sample_input2*2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cf34a5",
      "metadata": {
        "id": "93cf34a5"
      },
      "outputs": [],
      "source": [
        "# orig_model = gpt # original, uncompiled model, for saving raw model state_dict and for inference/evaluation (because the shapes may change shape)\n",
        "# # torch.compile: optimizing the model execution graph (JIT compilation)\n",
        "# model = torch.compile(gpt, dynamic=False) # the inputs to model will never change shape so dynamic=False is safe\n",
        "# num_params = sum(p.numel() for p in model.parameters())\n",
        "# print(f\"Number of parameters: {num_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc1aa760",
      "metadata": {
        "id": "dc1aa760"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "\n",
        "@torch.compile\n",
        "def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:\n",
        "    \"\"\"\n",
        "    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\n",
        "    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\n",
        "    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at\n",
        "    zero even beyond the point where the iteration no longer converges all the way to one everywhere\n",
        "    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T\n",
        "    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model\n",
        "    performance at all relative to UV^T, where USV^T = G is the SVD.\n",
        "    \"\"\"\n",
        "    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng\n",
        "    a, b, c = (3.4445, -4.7750,  2.0315)\n",
        "    X = G.bfloat16()\n",
        "    if G.size(-2) > G.size(-1):\n",
        "        X = X.mT\n",
        "\n",
        "    # Ensure spectral norm is at most 1\n",
        "    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)\n",
        "    # Perform the NS iterations\n",
        "    for _ in range(steps):\n",
        "        A = X @ X.mT\n",
        "        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng\n",
        "        X = a * X + B @ X\n",
        "\n",
        "    if G.size(-2) > G.size(-1):\n",
        "        X = X.mT\n",
        "    return X\n",
        "\n",
        "\n",
        "class Muon(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Muon - MomentUm Orthogonalized by Newton-schulz\n",
        "\n",
        "    https://kellerjordan.github.io/posts/muon/\n",
        "\n",
        "    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-\n",
        "    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal\n",
        "    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has\n",
        "    the advantage that it can be stably run in bfloat16 on the GPU.\n",
        "\n",
        "    Some warnings:\n",
        "    - This optimizer should not be used for the embedding layer, the final fully connected layer,\n",
        "    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).\n",
        "    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.\n",
        "\n",
        "    Arguments:\n",
        "        lr: The learning rate used by the internal SGD.\n",
        "        momentum: The momentum used by the internal SGD.\n",
        "        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)\n",
        "        ns_steps: The number of Newton-Schulz iteration steps to use.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):\n",
        "        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)\n",
        "        params: list[Tensor] = [*params]\n",
        "        param_groups = []\n",
        "        for size in {p.numel() for p in params}:\n",
        "            group = dict(params=[p for p in params if p.numel() == size])\n",
        "            param_groups.append(group)\n",
        "        super().__init__(param_groups, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            params: list[Tensor] = group[\"params\"]\n",
        "            for p in params:\n",
        "                g = p.grad\n",
        "                assert g is not None\n",
        "                state = self.state[p]\n",
        "                if \"momentum_buffer\" not in state:\n",
        "                    state[\"momentum_buffer\"] = torch.zeros_like(g)\n",
        "                buf: Tensor = state[\"momentum_buffer\"]\n",
        "                buf.lerp_(g, 1 - group[\"momentum\"])\n",
        "                g = g.lerp_(buf, group[\"momentum\"]) if group[\"nesterov\"] else buf\n",
        "                g = zeropower_via_newtonschulz5(g, steps=group[\"ns_steps\"])\n",
        "                p.add_(g, alpha=-group[\"lr\"] * max(1, p.size(-2) / p.size(-1))**0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3600722b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3600722b",
        "outputId": "2e95489d-8aad-41c5-88ca-1dc8cafdc938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaling the LR for the AdamW parameters ∝1/√(512/768) = 1.224745\n"
          ]
        }
      ],
      "source": [
        "embedding_lr = 0.2\n",
        "weight_decay = 0.0\n",
        "matrix_lr = 0.02\n",
        "from functools import partial\n",
        "\n",
        "optimizers = gpt.setup_optimizers(embedding_lr=embedding_lr, matrix_lr=matrix_lr, weight_decay=weight_decay)\n",
        "adamw_optimizer, muon_optimizer = optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb255ac3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb255ac3",
        "outputId": "1c15906d-0693-4b41-a1e1-ab05b39d0569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated: 0.09 GB\n",
            "Cached: 0.24 GB\n"
          ]
        }
      ],
      "source": [
        "# works on gpu\n",
        "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e67bd8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e67bd8d",
        "outputId": "e4a63bcc-e579-4346-a3a1-78c61ee53556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved the first 51200.0 KB of '/content/gutenberg_shard_00000.txt' to 'gutenberg_1kb.txt'.\n"
          ]
        }
      ],
      "source": [
        "input_file_path = '/content/gutenberg_shard_00000.txt'\n",
        "output_file_path = 'gutenberg_1kb.txt'\n",
        "bytes_to_read = 1024*1024*50 # 50 MB\n",
        "\n",
        "try:\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as infile:\n",
        "        content = infile.read(bytes_to_read)\n",
        "\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "    print(f\"Successfully saved the first {bytes_to_read / 1024} KB of '{input_file_path}' to '{output_file_path}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{input_file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gutenberg_1kb.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    print(text[:10240])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8hFEN6i0DqU",
        "outputId": "279c921f-e580-4e1c-a420-1d02cfdd7157"
      },
      "id": "M8hFEN6i0DqU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Declaration of Independence of the United States of America\n",
            "This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook.\n",
            "Title: The Declaration of Independence of the United States of America\n",
            "Author: Thomas Jefferson\n",
            "Release date: December 1, 1971 [eBook #1] Most recently updated: December 6, 2024\n",
            "Language: English\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE DECLARATION OF INDEPENDENCE OF THE UNITED STATES OF AMERICA ***\n",
            "===========================================================\n",
            "NOTE:  This file combines the first two Project Gutenberg files, both of which were given the filenumber #1. There are several duplicate files here. There were many updates over the years.  All of the original files are included in the \"old\" subdirectory which may be accessed under the \"More Files\" listing in the PG Catalog of this file. No changes have been made in these original etexts.\n",
            "===========================================================\n",
            "**Welcome To The World of Free Plain Vanilla Electronic Texts**\n",
            "**Etexts Readable By Both Humans and By Computers, Since 1971**\n",
            "*These Etexts Prepared By Hundreds of Volunteers and Donations*\n",
            "Below you will find the first nine Project Gutenberg Etexts, in one file, with one header for the entire file.  This is to keep the overhead down, and in response to requests from Gopher site keeper to eliminate as much of the headers as possible.\n",
            "However, for legal and financial reasons, we must request these headers be left at the beginning of each file that is posted in any general user areas, as Project Gutenberg is run mostly by a donation from people like you.\n",
            "If you see our books posted ANYWHERE without these headers, you are requested to send them a note requesting they re-attach the header, otherwise they have no legal protection and we have the loss of the donations we hope will keep Project Gutenberg going long enough to post 10,000 books, plays, musical pieces, etc.\n",
            "***START**THE SMALL PRINT!**FOR PUBLIC DOMAIN ETEXTS**START*** Why is this \"Small Print!\" statement here?  You know: lawyers. They tell us you might sue us if there is something wrong with your copy of this etext, even if you got it for free from someone other than us, and even if what's wrong is not our fault.  So, among other things, this \"Small Print!\" statement disclaims most of our liability to you.  It also tells you how you can distribute copies of this etext if you want to.\n",
            "*BEFORE!* YOU USE OR READ THIS ETEXT By using or reading any part of this PROJECT GUTENBERG-tm etext, you indicate that you understand, agree to and accept this \"Small Print!\" statement.  If you do not, you can receive a refund of the money (if any) you paid for this etext by sending a request within 30 days of receiving it to the person you got it from.  If you received this etext on a physical medium (such as a disk), you must return it with your request.\n",
            "ABOUT PROJECT GUTENBERG-TM ETEXTS This PROJECT GUTENBERG-tm etext, like most PROJECT GUTENBERG- tm etexts, is a \"public domain\" work distributed by Professor Michael S. Hart through the Project Gutenberg Association at Illinois Benedictine College (the \"Project\").  Among other things, this means that no one owns a United States copyright on or for this work, so the Project (and you!) can copy and distribute it in the United States without permission and without paying copyright royalties.  Special rules, set forth below, apply if you wish to copy and distribute this etext under the Project's \"PROJECT GUTENBERG\" trademark.\n",
            "To create these etexts, the Project expends considerable efforts to identify, transcribe and proofread public domain works.  Despite these efforts, the Project's etexts and any medium they may be on may contain \"Defects\".  Among other things, Defects may take the form of incomplete, inaccurate or corrupt data, transcription errors, a copyright or other intellectual property infringement, a defective or damaged disk or other etext medium, a computer virus, or computer codes that damage or cannot be read by your equipment.\n",
            "LIMITED WARRANTY; DISCLAIMER OF DAMAGES But for the \"Right of Replacement or Refund\" described below, [1] the Project (and any other party you may receive this etext from as a PROJECT GUTENBERG-tm etext) disclaims all liability to you for damages, costs and expenses, including legal fees, and [2] YOU HAVE NO REMEDIES FOR NEGLIGENCE OR UNDER STRICT LIABILITY, OR FOR BREACH OF WARRANTY OR CONTRACT, INCLUDING BUT NOT LIMITED TO INDIRECT, CONSEQUENTIAL, PUNITIVE OR INCIDENTAL DAMAGES, EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH DAMAGES.\n",
            "If you discover a Defect in this etext within 90 days of receiving it, you can receive a refund of the money (if any) you paid for it by sending an explanatory note within that time to the person you received it from.  If you received it on a physical medium, you must return it with your note, and such person may choose to alternatively give you a replacement copy.  If you received it electronically, such person may choose to alternatively give you a second opportunity to receive it electronically.\n",
            "THIS ETEXT IS OTHERWISE PROVIDED TO YOU \"AS-IS\".  NO OTHER WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, ARE MADE TO YOU AS TO THE ETEXT OR ANY MEDIUM IT MAY BE ON, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.\n",
            "Some states do not allow disclaimers of implied warranties or the exclusion or limitation of consequential damages, so the above disclaimers and exclusions may not apply to you, and you may have other legal rights.\n",
            "INDEMNITY You will indemnify and hold the Project, its directors, officers, members and agents harmless from all liability, cost and expense, including legal fees, that arise directly or indirectly from any of the following that you do or cause: [1] distribution of this etext, [2] alteration, modification, or addition to the etext, or [3] any Defect.\n",
            "DISTRIBUTION UNDER \"PROJECT GUTENBERG-tm\" You may distribute copies of this etext electronically, or by disk, book or any other medium if you either delete this \"Small Print!\" and all other references to Project Gutenberg, or:\n",
            "[1]  Only give exact copies of it.  Among other things, this requires that you do not remove, alter or modify the etext or this \"small print!\" statement.  You may however, if you wish, distribute this etext in machine readable binary, compressed, mark-up, or proprietary form, including any form resulting from conversion by word pro- cessing or hypertext software, but only so long as *EITHER*:\n",
            "[*]  The etext, when displayed, is clearly readable, and does *not* contain characters other than those intended by the author of the work, although tilde (~), asterisk (*) and underline (_) characters may be used to convey punctuation intended by the author, and additional characters may be used to indicate hypertext links; OR\n",
            "[*]  The etext may be readily converted by the reader at no expense into plain ASCII, EBCDIC or equivalent form by the program that displays the etext (as is the case, for instance, with most word processors); OR\n",
            "[*]  You provide, or agree to also provide on request at no additional cost, fee or expense, a copy of the etext in its original plain ASCII form (or in EBCDIC or other equivalent proprietary form).\n",
            "[2]  Honor the etext refund and replacement provisions of this \"Small Print!\" statement.\n",
            "[3]  Pay a trademark license fee to the Project of 20% of the net profits you derive calculated using the method you already use to calculate your applicable taxes.  If you don't derive profits, no royalty is due.  Royalties are payable to \"Project Gutenberg Association / Illinois Benedictine College\" within the 60 days following each date you prepare (or were legally required to prepare) your annual (or equivalent periodic) tax return.\n",
            "WHAT IF YOU *WANT* TO SEND MONEY EVEN IF YOU DON'T HAVE TO? The Project gratefully accepts contributions in money, time, scanning machines, OCR software, public domain etexts, royalty free copyright licenses, and every other sort of contribution you can think of.  Money should be paid to \"Project Gutenberg Association / Illinois Benedictine College\".\n",
            "This \"Small Print!\" by Charles B. Kramer, Attorney Internet (72600.2026@compuserve.com); TEL: (212-254-5093) *END*THE SMALL PRINT! FOR PUBLIC DOMAIN ETEXTS*Ver.04.29.93*END*\n",
            "December, 1971  [Etext #1]\n",
            "The Project Gutenberg Etext of The Declaration of Independence.\n",
            "All of the original Project Gutenberg Etexts from the 1970's were produced in ALL CAPS, no lower case.  The computers we used then didn't have lower case at all.\n",
            "This is a retranscription of one of the first Project Gutenberg Etexts, officially dated December, 1971-- and now officially re-released on December 31, 1993--\n",
            "The United States Declaration of Independence was the first Etext released by Project Gutenberg, early in 1971.  The title was stored in an emailed instruction set which required a tape or diskpack be hand mounted for retrieval.  The diskpack was the size of a large cake in a cake carrier, cost $1500, and contained 5 megabytes, of which this file took 1-2%.  Two tape backups were kept plus one on paper tape.  The 10,000 files we hope to have online by the end of 2001 should take about 1-2% of a comparably priced drive in 2001.\n",
            "This file was never copyrighted, Sharewared, etc., and is thus for all to use and copy in any manner they choose.  Please feel free to make your own edition using this as a base.\n",
            "In my research for creating this transcription of our first Etext, I have come across enough discrepancies [even within that official documentation provided by the United States] to conclude that even \"facsimiles\" of the Declaration of Indendence will NOT going to be all the same as the original, nor of other \"facsimiles.\"  There is a plethora of variations in capitaliza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThdLPYcP0Gyk",
        "outputId": "d5321179-de0e-4ed1-e31d-c7b17ef9359d"
      },
      "id": "ThdLPYcP0Gyk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52428800"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tiktoken\n",
        "# enc = tiktoken.get_encoding('gpt2')\n",
        "# tokenizer\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "\n",
        "with open(\"/content/tokenizer.pkl\", \"rb\") as f:\n",
        "    enc = pickle.load(f)\n",
        "print(enc)\n",
        "tokens = enc.encode(\"hello world\")\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "id": "1aQd4Sms0R-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a527e3-1573-4def-9e1b-08edbdcb64cc"
      },
      "id": "1aQd4Sms0R-v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Encoding 'rustbpe'>\n",
            "[13726, 111, 1170]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = enc.encode(text)\n",
        "print(len(input_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu5o_dxK0oiA",
        "outputId": "048c1041-7d59-402c-d3c7-d7a729f8cc86"
      },
      "id": "vu5o_dxK0oiA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14561610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = 32\n",
        "\n",
        "start = 0\n",
        "\n",
        "def load_next_batch():\n",
        "    global start\n",
        "    end = (start + B*config.sequence_len + 1) % len(input_tokens)\n",
        "    if end < start:\n",
        "        start = 0\n",
        "        end = B*T + 1\n",
        "    buf = torch.tensor(input_tokens[start:end])\n",
        "    start = end\n",
        "\n",
        "    x = buf[:-1].view(B, config.sequence_len)\n",
        "    y = buf[1:].view(B, config.sequence_len)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def get_gpu_stats():\n",
        "    print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "AzUgFYvOEHJc"
      },
      "id": "AzUgFYvOEHJc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tiktokenize_tokens(tokens):\n",
        "  for i, token in enumerate(tokens):\n",
        "    print(f\"\\033[{i%4+41}m{enc.decode([token])}\\033[0m\", end=\"\")\n",
        "  print()\n",
        "\n",
        "x_val, y_val = load_next_batch()\n",
        "x_val = x_val.to(device_type)\n",
        "y_val = y_val.to(device_type)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "tiktokenize_tokens(x_val[0])\n",
        "print(\"-\"*50)\n",
        "tiktokenize_tokens(y_val[0])\n",
        "\n",
        "start = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFtqfz7EWBY5",
        "outputId": "71009f9a-8d04-4833-e98e-0d2f91c5c4eb"
      },
      "id": "sFtqfz7EWBY5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "\u001b[41m﻿The\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m The\u001b[0m\u001b[43m Declaration\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Independence\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m of\u001b[0m\u001b[43m America\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mThis\u001b[0m\u001b[42m ebook\u001b[0m\u001b[43m is\u001b[0m\u001b[44m for\u001b[0m\u001b[41m the\u001b[0m\u001b[42m use\u001b[0m\u001b[43m of\u001b[0m\u001b[44m anyone\u001b[0m\u001b[41m anywhere\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m and\u001b[0m\u001b[43m most\u001b[0m\u001b[44m other\u001b[0m\u001b[41m parts\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m world\u001b[0m\u001b[41m at\u001b[0m\u001b[42m no\u001b[0m\u001b[43m cost\u001b[0m\u001b[44m and\u001b[0m\u001b[41m with\u001b[0m\u001b[42m almost\u001b[0m\u001b[43m no\u001b[0m\u001b[44m restrictions\u001b[0m\u001b[41m whatsoever\u001b[0m\u001b[42m.\u001b[0m\u001b[43m You\u001b[0m\u001b[44m may\u001b[0m\u001b[41m copy\u001b[0m\u001b[42m it\u001b[0m\u001b[43m,\u001b[0m\u001b[44m give\u001b[0m\u001b[41m it\u001b[0m\u001b[42m away\u001b[0m\u001b[43m or\u001b[0m\u001b[44m re\u001b[0m\u001b[41m-use\u001b[0m\u001b[42m it\u001b[0m\u001b[43m under\u001b[0m\u001b[44m the\u001b[0m\u001b[41m terms\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m License\u001b[0m\u001b[43m included\u001b[0m\u001b[44m with\u001b[0m\u001b[41m this\u001b[0m\u001b[42m ebook\u001b[0m\u001b[43m or\u001b[0m\u001b[44m online\u001b[0m\u001b[41m at\u001b[0m\u001b[42m www\u001b[0m\u001b[43m.gutenberg\u001b[0m\u001b[44m.org\u001b[0m\u001b[41m.\u001b[0m\u001b[42m If\u001b[0m\u001b[43m you\u001b[0m\u001b[44m are\u001b[0m\u001b[41m not\u001b[0m\u001b[42m located\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m United\u001b[0m\u001b[42m States\u001b[0m\u001b[43m,\u001b[0m\u001b[44m you\u001b[0m\u001b[41m will\u001b[0m\u001b[42m have\u001b[0m\u001b[43m to\u001b[0m\u001b[44m check\u001b[0m\u001b[41m the\u001b[0m\u001b[42m laws\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m country\u001b[0m\u001b[42m where\u001b[0m\u001b[43m you\u001b[0m\u001b[44m are\u001b[0m\u001b[41m located\u001b[0m\u001b[42m before\u001b[0m\u001b[43m using\u001b[0m\u001b[44m this\u001b[0m\u001b[41m eBook\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mTitle\u001b[0m\u001b[41m:\u001b[0m\u001b[42m The\u001b[0m\u001b[43m Declaration\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Independence\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m of\u001b[0m\u001b[43m America\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mAuthor\u001b[0m\u001b[42m:\u001b[0m\u001b[43m Thomas\u001b[0m\u001b[44m Jefferson\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mRelease\u001b[0m\u001b[43m date\u001b[0m\u001b[44m:\u001b[0m\u001b[41m December\u001b[0m\u001b[42m \u001b[0m\u001b[43m1\u001b[0m\u001b[44m,\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\u001b[43m71\u001b[0m\u001b[44m [\u001b[0m\u001b[41meBook\u001b[0m\u001b[42m #\u001b[0m\u001b[43m1\u001b[0m\u001b[44m]\u001b[0m\u001b[41m Most\u001b[0m\u001b[42m recently\u001b[0m\u001b[43m updated\u001b[0m\u001b[44m:\u001b[0m\u001b[41m December\u001b[0m\u001b[42m \u001b[0m\u001b[43m6\u001b[0m\u001b[44m,\u001b[0m\u001b[41m \u001b[0m\u001b[42m20\u001b[0m\u001b[43m24\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mLanguage\u001b[0m\u001b[42m:\u001b[0m\u001b[43m English\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m***\u001b[0m\u001b[42m START\u001b[0m\u001b[43m OF\u001b[0m\u001b[44m THE\u001b[0m\u001b[41m PROJECT\u001b[0m\u001b[42m GUTENBERG\u001b[0m\u001b[43m EBOOK\u001b[0m\u001b[44m THE\u001b[0m\u001b[41m DE\u001b[0m\u001b[42mCL\u001b[0m\u001b[43mAR\u001b[0m\u001b[44mATION\u001b[0m\u001b[41m OF\u001b[0m\u001b[42m IND\u001b[0m\u001b[43mEP\u001b[0m\u001b[44mEND\u001b[0m\u001b[41mENCE\u001b[0m\u001b[42m OF\u001b[0m\u001b[43m THE\u001b[0m\u001b[44m UN\u001b[0m\u001b[41mITED\u001b[0m\u001b[42m ST\u001b[0m\u001b[43mAT\u001b[0m\u001b[44mES\u001b[0m\u001b[41m OF\u001b[0m\u001b[42m AM\u001b[0m\u001b[43mER\u001b[0m\u001b[44mIC\u001b[0m\u001b[41mA\u001b[0m\u001b[42m ***\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m========\u001b[0m\u001b[41m========\u001b[0m\u001b[42m========\u001b[0m\u001b[43m========\u001b[0m\u001b[44m========\u001b[0m\u001b[41m========\u001b[0m\u001b[42m========\u001b[0m\u001b[43m==\u001b[0m\u001b[44m=\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mNOT\u001b[0m\u001b[43mE\u001b[0m\u001b[44m:\u001b[0m\u001b[41m \u001b[0m\u001b[42m This\u001b[0m\u001b[43m file\u001b[0m\u001b[44m combines\u001b[0m\u001b[41m the\u001b[0m\u001b[42m first\u001b[0m\u001b[43m two\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m files\u001b[0m\u001b[43m,\u001b[0m\u001b[44m both\u001b[0m\u001b[41m of\u001b[0m\u001b[42m which\u001b[0m\u001b[43m were\u001b[0m\u001b[44m given\u001b[0m\u001b[41m the\u001b[0m\u001b[42m fil\u001b[0m\u001b[43men\u001b[0m\u001b[44mumber\u001b[0m\u001b[41m #\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m There\u001b[0m\u001b[41m are\u001b[0m\u001b[42m several\u001b[0m\u001b[43m dupl\u001b[0m\u001b[44micate\u001b[0m\u001b[41m files\u001b[0m\u001b[42m here\u001b[0m\u001b[43m.\u001b[0m\u001b[44m There\u001b[0m\u001b[41m were\u001b[0m\u001b[42m many\u001b[0m\u001b[43m updates\u001b[0m\u001b[44m over\u001b[0m\u001b[41m the\u001b[0m\u001b[42m years\u001b[0m\u001b[43m.\u001b[0m\u001b[44m \u001b[0m\u001b[41m All\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m original\u001b[0m\u001b[41m files\u001b[0m\u001b[42m are\u001b[0m\u001b[43m included\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m \"\u001b[0m\u001b[43mold\u001b[0m\u001b[44m\"\u001b[0m\u001b[41m subd\u001b[0m\u001b[42mirect\u001b[0m\u001b[43mory\u001b[0m\u001b[44m which\u001b[0m\n",
            "--------------------------------------------------\n",
            "\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m eBook\u001b[0m\u001b[44m of\u001b[0m\u001b[41m The\u001b[0m\u001b[42m Declaration\u001b[0m\u001b[43m of\u001b[0m\u001b[44m Independence\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m of\u001b[0m\u001b[42m America\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mThis\u001b[0m\u001b[41m ebook\u001b[0m\u001b[42m is\u001b[0m\u001b[43m for\u001b[0m\u001b[44m the\u001b[0m\u001b[41m use\u001b[0m\u001b[42m of\u001b[0m\u001b[43m anyone\u001b[0m\u001b[44m anywhere\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m and\u001b[0m\u001b[42m most\u001b[0m\u001b[43m other\u001b[0m\u001b[44m parts\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m world\u001b[0m\u001b[44m at\u001b[0m\u001b[41m no\u001b[0m\u001b[42m cost\u001b[0m\u001b[43m and\u001b[0m\u001b[44m with\u001b[0m\u001b[41m almost\u001b[0m\u001b[42m no\u001b[0m\u001b[43m restrictions\u001b[0m\u001b[44m whatsoever\u001b[0m\u001b[41m.\u001b[0m\u001b[42m You\u001b[0m\u001b[43m may\u001b[0m\u001b[44m copy\u001b[0m\u001b[41m it\u001b[0m\u001b[42m,\u001b[0m\u001b[43m give\u001b[0m\u001b[44m it\u001b[0m\u001b[41m away\u001b[0m\u001b[42m or\u001b[0m\u001b[43m re\u001b[0m\u001b[44m-use\u001b[0m\u001b[41m it\u001b[0m\u001b[42m under\u001b[0m\u001b[43m the\u001b[0m\u001b[44m terms\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m License\u001b[0m\u001b[42m included\u001b[0m\u001b[43m with\u001b[0m\u001b[44m this\u001b[0m\u001b[41m ebook\u001b[0m\u001b[42m or\u001b[0m\u001b[43m online\u001b[0m\u001b[44m at\u001b[0m\u001b[41m www\u001b[0m\u001b[42m.gutenberg\u001b[0m\u001b[43m.org\u001b[0m\u001b[44m.\u001b[0m\u001b[41m If\u001b[0m\u001b[42m you\u001b[0m\u001b[43m are\u001b[0m\u001b[44m not\u001b[0m\u001b[41m located\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m,\u001b[0m\u001b[43m you\u001b[0m\u001b[44m will\u001b[0m\u001b[41m have\u001b[0m\u001b[42m to\u001b[0m\u001b[43m check\u001b[0m\u001b[44m the\u001b[0m\u001b[41m laws\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m country\u001b[0m\u001b[41m where\u001b[0m\u001b[42m you\u001b[0m\u001b[43m are\u001b[0m\u001b[44m located\u001b[0m\u001b[41m before\u001b[0m\u001b[42m using\u001b[0m\u001b[43m this\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43mTitle\u001b[0m\u001b[44m:\u001b[0m\u001b[41m The\u001b[0m\u001b[42m Declaration\u001b[0m\u001b[43m of\u001b[0m\u001b[44m Independence\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m of\u001b[0m\u001b[42m America\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mAuthor\u001b[0m\u001b[41m:\u001b[0m\u001b[42m Thomas\u001b[0m\u001b[43m Jefferson\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mRelease\u001b[0m\u001b[42m date\u001b[0m\u001b[43m:\u001b[0m\u001b[44m December\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m,\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m71\u001b[0m\u001b[43m [\u001b[0m\u001b[44meBook\u001b[0m\u001b[41m #\u001b[0m\u001b[42m1\u001b[0m\u001b[43m]\u001b[0m\u001b[44m Most\u001b[0m\u001b[41m recently\u001b[0m\u001b[42m updated\u001b[0m\u001b[43m:\u001b[0m\u001b[44m December\u001b[0m\u001b[41m \u001b[0m\u001b[42m6\u001b[0m\u001b[43m,\u001b[0m\u001b[44m \u001b[0m\u001b[41m20\u001b[0m\u001b[42m24\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mLanguage\u001b[0m\u001b[41m:\u001b[0m\u001b[42m English\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m***\u001b[0m\u001b[41m START\u001b[0m\u001b[42m OF\u001b[0m\u001b[43m THE\u001b[0m\u001b[44m PROJECT\u001b[0m\u001b[41m GUTENBERG\u001b[0m\u001b[42m EBOOK\u001b[0m\u001b[43m THE\u001b[0m\u001b[44m DE\u001b[0m\u001b[41mCL\u001b[0m\u001b[42mAR\u001b[0m\u001b[43mATION\u001b[0m\u001b[44m OF\u001b[0m\u001b[41m IND\u001b[0m\u001b[42mEP\u001b[0m\u001b[43mEND\u001b[0m\u001b[44mENCE\u001b[0m\u001b[41m OF\u001b[0m\u001b[42m THE\u001b[0m\u001b[43m UN\u001b[0m\u001b[44mITED\u001b[0m\u001b[41m ST\u001b[0m\u001b[42mAT\u001b[0m\u001b[43mES\u001b[0m\u001b[44m OF\u001b[0m\u001b[41m AM\u001b[0m\u001b[42mER\u001b[0m\u001b[43mIC\u001b[0m\u001b[44mA\u001b[0m\u001b[41m ***\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m========\u001b[0m\u001b[44m========\u001b[0m\u001b[41m========\u001b[0m\u001b[42m========\u001b[0m\u001b[43m========\u001b[0m\u001b[44m========\u001b[0m\u001b[41m========\u001b[0m\u001b[42m==\u001b[0m\u001b[43m=\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mNOT\u001b[0m\u001b[42mE\u001b[0m\u001b[43m:\u001b[0m\u001b[44m \u001b[0m\u001b[41m This\u001b[0m\u001b[42m file\u001b[0m\u001b[43m combines\u001b[0m\u001b[44m the\u001b[0m\u001b[41m first\u001b[0m\u001b[42m two\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m files\u001b[0m\u001b[42m,\u001b[0m\u001b[43m both\u001b[0m\u001b[44m of\u001b[0m\u001b[41m which\u001b[0m\u001b[42m were\u001b[0m\u001b[43m given\u001b[0m\u001b[44m the\u001b[0m\u001b[41m fil\u001b[0m\u001b[42men\u001b[0m\u001b[43mumber\u001b[0m\u001b[44m #\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m There\u001b[0m\u001b[44m are\u001b[0m\u001b[41m several\u001b[0m\u001b[42m dupl\u001b[0m\u001b[43micate\u001b[0m\u001b[44m files\u001b[0m\u001b[41m here\u001b[0m\u001b[42m.\u001b[0m\u001b[43m There\u001b[0m\u001b[44m were\u001b[0m\u001b[41m many\u001b[0m\u001b[42m updates\u001b[0m\u001b[43m over\u001b[0m\u001b[44m the\u001b[0m\u001b[41m years\u001b[0m\u001b[42m.\u001b[0m\u001b[43m \u001b[0m\u001b[44m All\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m original\u001b[0m\u001b[44m files\u001b[0m\u001b[41m are\u001b[0m\u001b[42m included\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m \"\u001b[0m\u001b[42mold\u001b[0m\u001b[43m\"\u001b[0m\u001b[44m subd\u001b[0m\u001b[41mirect\u001b[0m\u001b[42mory\u001b[0m\u001b[43m which\u001b[0m\u001b[44m may\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autocast_ctx = torch.amp.autocast(device_type=device_type, dtype=torch.bfloat16) if device_type == \"cuda\" else nullcontext()\n",
        "\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "eYduD3PuI_uJ"
      },
      "id": "eYduD3PuI_uJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "# todo: test if this makes it faster\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "def training_loop(iter=500):\n",
        "\n",
        "  # validation set\n",
        "  sample = enc.encode(\"The Project Gutenberg eBook of\")\n",
        "  buf = torch.tensor(sample)\n",
        "  x_sample_base = buf.view(1, -1)\n",
        "  x_sample_base = x_sample_base.to(device_type)\n",
        "\n",
        "  # train\n",
        "  t0 = time.time()\n",
        "  for i in range(iter):\n",
        "    optimizer.zero_grad()\n",
        "    x, y = load_next_batch()\n",
        "    x = x.to(device_type)\n",
        "    y = y.to(device_type)\n",
        "\n",
        "    with autocast_ctx:\n",
        "        loss = gpt(x, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 10 == 0:\n",
        "        t1 = time.time()\n",
        "        gpt.eval()\n",
        "        with autocast_ctx:\n",
        "          val_loss = gpt(x_val, y_val)\n",
        "        gpt.train()\n",
        "\n",
        "        print(f\"step {i}, validation loss: {val_loss.item()}, loss: {loss} average time over last 10 steps = {(t1-t0)/10}\")\n",
        "        t0 = t1\n",
        "\n",
        "        if i%100 == 0:\n",
        "\n",
        "            gpt.eval()\n",
        "            x_sample = x_sample_base\n",
        "            for _ in range(25):\n",
        "                with torch.no_grad(): # Good practice for inference to save memory\n",
        "                    with autocast_ctx:\n",
        "                        op = gpt(x_sample)\n",
        "                    op = op[:,-1,:]\n",
        "\n",
        "                    next_ids = torch.argmax(op, dim=-1, keepdim=True)\n",
        "                    x_sample = torch.cat((x_sample, next_ids), dim=1)\n",
        "                    next_token = next_ids.item()\n",
        "                    # print(f\"{enc.decode([next_token])}\", end = \"\")\n",
        "                    # print(\"\\n\", x_sample.shape)\n",
        "            tiktokenize_tokens(x_sample[0])\n",
        "            gpt.train()\n",
        "\n",
        "            get_gpu_stats()\n",
        "\n",
        "\n",
        "training_loop(5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yel2Jim82DTT",
        "outputId": "b4158c98-426a-4a9b-dd76-309a1956a2be"
      },
      "id": "yel2Jim82DTT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0, validation loss: 6.024102687835693, average time over last 10 steps = 0.0023022890090942383\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 10, validation loss: 6.1195573806762695, average time over last 10 steps = 0.8296464443206787\n",
            "step 20, validation loss: 6.17494010925293, average time over last 10 steps = 0.8212828874588013\n",
            "step 30, validation loss: 5.7937846183776855, average time over last 10 steps = 0.838221263885498\n",
            "step 40, validation loss: 5.8871636390686035, average time over last 10 steps = 0.8483931303024292\n",
            "step 50, validation loss: 5.8090996742248535, average time over last 10 steps = 0.8373467922210693\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m is\u001b[0m\u001b[44m a\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m is\u001b[0m\u001b[43m a\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m work\u001b[0m\u001b[41m is\u001b[0m\u001b[42m a\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 60, validation loss: 5.9071125984191895, average time over last 10 steps = 0.8420436382293701\n",
            "step 70, validation loss: 5.938328742980957, average time over last 10 steps = 0.8272908449172973\n",
            "step 80, validation loss: 6.213301658630371, average time over last 10 steps = 0.8052340030670166\n",
            "step 90, validation loss: 6.259651184082031, average time over last 10 steps = 0.8134978771209717\n",
            "step 100, validation loss: 6.267325401306152, average time over last 10 steps = 0.8149991273880005\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m work\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m05\u001b[0m\u001b[42m:\u001b[0m\u001b[43m00\u001b[0m\u001b[44m1\u001b[0m\u001b[41m:\u001b[0m\u001b[42m00\u001b[0m\u001b[43m1\u001b[0m\u001b[44m And\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m said\u001b[0m\u001b[44m unto\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m,\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m05\u001b[0m\u001b[42m:\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 110, validation loss: 6.277763366699219, average time over last 10 steps = 0.8318932056427002\n",
            "step 120, validation loss: 6.200129985809326, average time over last 10 steps = 0.8192293643951416\n",
            "step 130, validation loss: 6.165148735046387, average time over last 10 steps = 0.8185601472854614\n",
            "step 140, validation loss: 6.285186290740967, average time over last 10 steps = 0.8258763074874877\n",
            "step 150, validation loss: 6.265898704528809, average time over last 10 steps = 0.8242875576019287\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m work\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m work\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m work\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m work\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m19\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 160, validation loss: 6.324590682983398, average time over last 10 steps = 0.8419863462448121\n",
            "step 170, validation loss: 6.340104103088379, average time over last 10 steps = 0.8199108600616455\n",
            "step 180, validation loss: 6.313141822814941, average time over last 10 steps = 0.820814061164856\n",
            "step 190, validation loss: 6.275043964385986, average time over last 10 steps = 0.8221884489059448\n",
            "step 200, validation loss: 6.217690467834473, average time over last 10 steps = 0.8169847726821899\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m42\u001b[0m\u001b[43m:\u001b[0m\u001b[44m00\u001b[0m\u001b[41m9\u001b[0m\u001b[42m:\u001b[0m\u001b[43m01\u001b[0m\u001b[44m0\u001b[0m\u001b[41m And\u001b[0m\u001b[42m when\u001b[0m\u001b[43m he\u001b[0m\u001b[44m had\u001b[0m\u001b[41m made\u001b[0m\u001b[42m a\u001b[0m\u001b[43m man\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m said\u001b[0m\u001b[43m unto\u001b[0m\u001b[44m them\u001b[0m\u001b[41m,\u001b[0m\u001b[42m I\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 210, validation loss: 6.169133186340332, average time over last 10 steps = 0.8317729473114014\n",
            "step 220, validation loss: 6.11911678314209, average time over last 10 steps = 0.8172884941101074\n",
            "step 230, validation loss: 5.905963897705078, average time over last 10 steps = 0.8173805713653565\n",
            "step 240, validation loss: 5.853220462799072, average time over last 10 steps = 0.8176664352416992\n",
            "step 250, validation loss: 5.660872936248779, average time over last 10 steps = 0.8183138132095337\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 260, validation loss: 5.694972991943359, average time over last 10 steps = 0.8377765893936158\n",
            "step 270, validation loss: 5.859288215637207, average time over last 10 steps = 0.8177712202072144\n",
            "step 280, validation loss: 5.835318565368652, average time over last 10 steps = 0.8178046226501465\n",
            "step 290, validation loss: 5.9623942375183105, average time over last 10 steps = 0.8244972467422486\n",
            "step 300, validation loss: 5.85647439956665, average time over last 10 steps = 0.8225504398345947\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m user\u001b[0m\u001b[44m's\u001b[0m\u001b[41m name\u001b[0m\u001b[42m is\u001b[0m\u001b[43m a\u001b[0m\u001b[44m program\u001b[0m\u001b[41m to\u001b[0m\u001b[42m be\u001b[0m\u001b[43m used\u001b[0m\u001b[44m to\u001b[0m\u001b[41m be\u001b[0m\u001b[42m used\u001b[0m\u001b[43m to\u001b[0m\u001b[44m be\u001b[0m\u001b[41m used\u001b[0m\u001b[42m to\u001b[0m\u001b[43m be\u001b[0m\u001b[44m used\u001b[0m\u001b[41m to\u001b[0m\u001b[42m be\u001b[0m\u001b[43m used\u001b[0m\u001b[44m to\u001b[0m\u001b[41m be\u001b[0m\u001b[42m used\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 310, validation loss: 5.837465763092041, average time over last 10 steps = 0.8375165462493896\n",
            "step 320, validation loss: 5.819427013397217, average time over last 10 steps = 0.819750714302063\n",
            "step 330, validation loss: 5.823200225830078, average time over last 10 steps = 0.8179173231124878\n",
            "step 340, validation loss: 5.876502990722656, average time over last 10 steps = 0.8199963808059693\n",
            "step 350, validation loss: 5.877439022064209, average time over last 10 steps = 0.822245192527771\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 360, validation loss: 5.790401458740234, average time over last 10 steps = 0.8365801334381103\n",
            "step 370, validation loss: 5.811558723449707, average time over last 10 steps = 0.8219081401824951\n",
            "step 380, validation loss: 5.875578880310059, average time over last 10 steps = 0.821065878868103\n",
            "step 390, validation loss: 5.624248504638672, average time over last 10 steps = 0.8197784423828125\n",
            "step 400, validation loss: 5.730856895446777, average time over last 10 steps = 0.820811414718628\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m0\u001b[0m\u001b[41m (\u001b[0m\u001b[42mC\u001b[0m\u001b[43m /\u001b[0m\u001b[44mT\u001b[0m\u001b[41mimes\u001b[0m\u001b[42m-Roman\u001b[0m\u001b[43m /\u001b[0m\u001b[44mf\u001b[0m\u001b[41mont\u001b[0m\u001b[42m40\u001b[0m\u001b[43m AN\u001b[0m\u001b[44mSI\u001b[0m\u001b[41mF\u001b[0m\u001b[42mont\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 410, validation loss: 5.757386684417725, average time over last 10 steps = 0.835214900970459\n",
            "step 420, validation loss: 5.7821760177612305, average time over last 10 steps = 0.8195681810379029\n",
            "step 430, validation loss: 5.803806304931641, average time over last 10 steps = 0.8174566268920899\n",
            "step 440, validation loss: 5.695775032043457, average time over last 10 steps = 0.8170732736587525\n",
            "step 450, validation loss: 5.725234508514404, average time over last 10 steps = 0.820599365234375\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m or\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m or\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 460, validation loss: 5.651461601257324, average time over last 10 steps = 0.8323263645172119\n",
            "step 470, validation loss: 5.829340934753418, average time over last 10 steps = 0.8174927711486817\n",
            "step 480, validation loss: 5.844601631164551, average time over last 10 steps = 0.8204100131988525\n",
            "step 490, validation loss: 5.864450931549072, average time over last 10 steps = 0.819876742362976\n",
            "step 500, validation loss: 5.892992973327637, average time over last 10 steps = 0.8193923234939575\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 510, validation loss: 5.9502105712890625, average time over last 10 steps = 0.8391433000564575\n",
            "step 520, validation loss: 5.962847709655762, average time over last 10 steps = 0.8151784420013428\n",
            "step 530, validation loss: 5.991154670715332, average time over last 10 steps = 0.8210467338562012\n",
            "step 540, validation loss: 8.506333351135254, average time over last 10 steps = 0.8199627161026001\n",
            "step 550, validation loss: 9.725687980651855, average time over last 10 steps = 0.8144012212753295\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m38\u001b[0m\u001b[44m92\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\u001b[43m \u001b[0m\u001b[44m38\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\u001b[43m92\u001b[0m\u001b[44m \u001b[0m\u001b[41m38\u001b[0m\u001b[42m92\u001b[0m\u001b[43m92\u001b[0m\u001b[44m92\u001b[0m\u001b[41m92\u001b[0m\u001b[42m \u001b[0m\u001b[43m38\u001b[0m\u001b[44m92\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\u001b[43m \u001b[0m\u001b[44m38\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 560, validation loss: 10.082049369812012, average time over last 10 steps = 0.8262614965438843\n",
            "step 570, validation loss: 10.485931396484375, average time over last 10 steps = 0.8176478862762451\n",
            "step 580, validation loss: 10.345940589904785, average time over last 10 steps = 0.8175805568695068\n",
            "step 590, validation loss: 10.489385604858398, average time over last 10 steps = 0.816024899482727\n",
            "step 600, validation loss: 10.634145736694336, average time over last 10 steps = 0.8184903621673584\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m20\u001b[0m\u001b[44m20\u001b[0m\u001b[41m20\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m91\u001b[0m\u001b[43m91\u001b[0m\u001b[44m91\u001b[0m\u001b[41m91\u001b[0m\u001b[42m \u001b[0m\u001b[43m19\u001b[0m\u001b[44m91\u001b[0m\u001b[41m91\u001b[0m\u001b[42m91\u001b[0m\u001b[43m91\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m91\u001b[0m\u001b[43m91\u001b[0m\u001b[44m91\u001b[0m\u001b[41m91\u001b[0m\u001b[42m \u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 610, validation loss: 10.713346481323242, average time over last 10 steps = 0.8387495517730713\n",
            "step 620, validation loss: 10.72623062133789, average time over last 10 steps = 0.8153129816055298\n",
            "step 630, validation loss: 6.626347064971924, average time over last 10 steps = 0.8162482023239136\n",
            "step 640, validation loss: 6.164364814758301, average time over last 10 steps = 0.8207346677780152\n",
            "step 650, validation loss: 5.783856391906738, average time over last 10 steps = 0.8195324897766113\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 660, validation loss: 5.785619735717773, average time over last 10 steps = 0.8346967220306396\n",
            "step 670, validation loss: 5.657232284545898, average time over last 10 steps = 0.8215094566345215\n",
            "step 680, validation loss: 5.6370344161987305, average time over last 10 steps = 0.8188746929168701\n",
            "step 690, validation loss: 5.564116477966309, average time over last 10 steps = 0.8215549707412719\n",
            "step 700, validation loss: 5.5412492752075195, average time over last 10 steps = 0.8175608873367309\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 710, validation loss: 6.26772403717041, average time over last 10 steps = 0.8319935321807861\n",
            "step 720, validation loss: 5.978111743927002, average time over last 10 steps = 0.8217746257781983\n",
            "step 730, validation loss: 8.012216567993164, average time over last 10 steps = 0.8122478008270264\n",
            "step 740, validation loss: 9.775409698486328, average time over last 10 steps = 0.8101706743240357\n",
            "step 750, validation loss: 10.240896224975586, average time over last 10 steps = 0.8121178865432739\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 760, validation loss: 8.993864059448242, average time over last 10 steps = 0.8356042861938476\n",
            "step 770, validation loss: 9.027339935302734, average time over last 10 steps = 0.8171735763549804\n",
            "step 780, validation loss: 6.194745063781738, average time over last 10 steps = 0.8202389717102051\n",
            "step 790, validation loss: 5.908310413360596, average time over last 10 steps = 0.8246711492538452\n",
            "step 800, validation loss: 5.7287516593933105, average time over last 10 steps = 0.8232528448104859\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 810, validation loss: 6.054421901702881, average time over last 10 steps = 0.8268224477767945\n",
            "step 820, validation loss: 5.858434677124023, average time over last 10 steps = 0.8164382696151733\n",
            "step 830, validation loss: 5.854859352111816, average time over last 10 steps = 0.8220471382141114\n",
            "step 840, validation loss: 5.700778007507324, average time over last 10 steps = 0.8219289064407349\n",
            "step 850, validation loss: 5.732512950897217, average time over last 10 steps = 0.8224381685256958\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mThe\u001b[0m\u001b[43m Foundation\u001b[0m\u001b[44m’s\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m you\u001b[0m\u001b[44m are\u001b[0m\u001b[41m located\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 860, validation loss: 5.778020858764648, average time over last 10 steps = 0.8345464706420899\n",
            "step 870, validation loss: 5.690155982971191, average time over last 10 steps = 0.8224225044250488\n",
            "step 880, validation loss: 5.724200248718262, average time over last 10 steps = 0.821495532989502\n",
            "step 890, validation loss: 5.650038242340088, average time over last 10 steps = 0.8198154449462891\n",
            "step 900, validation loss: 5.624883651733398, average time over last 10 steps = 0.8218269109725952\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 910, validation loss: 5.604562282562256, average time over last 10 steps = 0.8381437063217163\n",
            "step 920, validation loss: 5.7614850997924805, average time over last 10 steps = 0.8182414531707763\n",
            "step 930, validation loss: 5.90634298324585, average time over last 10 steps = 0.8189434289932251\n",
            "step 940, validation loss: 5.826498985290527, average time over last 10 steps = 0.8170700311660767\n",
            "step 950, validation loss: 5.846360683441162, average time over last 10 steps = 0.8186549186706543\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 960, validation loss: 5.684191703796387, average time over last 10 steps = 0.8345660448074341\n",
            "step 970, validation loss: 5.742852210998535, average time over last 10 steps = 0.8204695463180542\n",
            "step 980, validation loss: 5.6167426109313965, average time over last 10 steps = 0.821454668045044\n",
            "step 990, validation loss: 5.637219429016113, average time over last 10 steps = 0.8198864459991455\n",
            "step 1000, validation loss: 5.585240364074707, average time over last 10 steps = 0.8213371992111206\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1010, validation loss: 5.582864284515381, average time over last 10 steps = 0.8366617441177369\n",
            "step 1020, validation loss: 5.566638946533203, average time over last 10 steps = 0.8202749013900756\n",
            "step 1030, validation loss: 5.523058891296387, average time over last 10 steps = 0.8250838041305542\n",
            "step 1040, validation loss: 5.528639793395996, average time over last 10 steps = 0.8225548028945923\n",
            "step 1050, validation loss: 5.5532965660095215, average time over last 10 steps = 0.8204146146774292\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1060, validation loss: 5.518769264221191, average time over last 10 steps = 0.8344964742660522\n",
            "step 1070, validation loss: 5.489145755767822, average time over last 10 steps = 0.8200648546218872\n",
            "step 1080, validation loss: 5.528295516967773, average time over last 10 steps = 0.8205774545669555\n",
            "step 1090, validation loss: 5.639066696166992, average time over last 10 steps = 0.8205316543579102\n",
            "step 1100, validation loss: 5.698869705200195, average time over last 10 steps = 0.8222255229949951\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1110, validation loss: 5.743199825286865, average time over last 10 steps = 0.8373348951339722\n",
            "step 1120, validation loss: 5.754611968994141, average time over last 10 steps = 0.8239229917526245\n",
            "step 1130, validation loss: 5.777327537536621, average time over last 10 steps = 0.8243869543075562\n",
            "step 1140, validation loss: 5.795767784118652, average time over last 10 steps = 0.8172047138214111\n",
            "step 1150, validation loss: 5.805895805358887, average time over last 10 steps = 0.8200936555862427\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1160, validation loss: 5.941144943237305, average time over last 10 steps = 0.833069109916687\n",
            "step 1170, validation loss: 6.327024936676025, average time over last 10 steps = 0.817087721824646\n",
            "step 1180, validation loss: 6.435285568237305, average time over last 10 steps = 0.8191255807876587\n",
            "step 1190, validation loss: 6.463505744934082, average time over last 10 steps = 0.8179639339447021\n",
            "step 1200, validation loss: 6.487067222595215, average time over last 10 steps = 0.8162934303283691\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m.\u001b[0m\u001b[44m \u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m   \u001b[0m\u001b[43m \u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m%\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\u001b[43m79\u001b[0m\u001b[44m   \u001b[0m\u001b[41m \u001b[0m\u001b[42m0\u001b[0m\u001b[43m.\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m00\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1210, validation loss: 6.508044242858887, average time over last 10 steps = 0.8315102100372315\n",
            "step 1220, validation loss: 6.132296085357666, average time over last 10 steps = 0.8187109231948853\n",
            "step 1230, validation loss: 6.580850124359131, average time over last 10 steps = 0.8162546157836914\n",
            "step 1240, validation loss: 6.755958080291748, average time over last 10 steps = 0.8179999589920044\n",
            "step 1250, validation loss: 6.86682653427124, average time over last 10 steps = 0.8188406229019165\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m terms\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m terms\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1260, validation loss: 5.793595314025879, average time over last 10 steps = 0.8307613134384155\n",
            "step 1270, validation loss: 5.758490085601807, average time over last 10 steps = 0.8204538106918335\n",
            "step 1280, validation loss: 5.484800338745117, average time over last 10 steps = 0.8186621904373169\n",
            "step 1290, validation loss: 5.063593864440918, average time over last 10 steps = 0.8170713663101197\n",
            "step 1300, validation loss: 5.360307693481445, average time over last 10 steps = 0.8167834043502807\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1310, validation loss: 5.488428115844727, average time over last 10 steps = 0.8325886726379395\n",
            "step 1320, validation loss: 5.522707462310791, average time over last 10 steps = 0.8176400899887085\n",
            "step 1330, validation loss: 5.563495635986328, average time over last 10 steps = 0.8181406021118164\n",
            "step 1340, validation loss: 5.556849479675293, average time over last 10 steps = 0.818489670753479\n",
            "step 1350, validation loss: 5.566920757293701, average time over last 10 steps = 0.8177310228347778\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m God\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m the\u001b[0m\u001b[42m children\u001b[0m\u001b[43m of\u001b[0m\u001b[44m Israel\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m the\u001b[0m\u001b[44m children\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Israel\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m the\u001b[0m\u001b[42m children\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1360, validation loss: 5.611201763153076, average time over last 10 steps = 0.8334648370742798\n",
            "step 1370, validation loss: 5.662576675415039, average time over last 10 steps = 0.8206609964370728\n",
            "step 1380, validation loss: 5.634964466094971, average time over last 10 steps = 0.8165798425674439\n",
            "step 1390, validation loss: 5.654552936553955, average time over last 10 steps = 0.8207524299621582\n",
            "step 1400, validation loss: 5.627071857452393, average time over last 10 steps = 0.819098711013794\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m as\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m License\u001b[0m\u001b[41m as\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m as\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1410, validation loss: 5.582999229431152, average time over last 10 steps = 0.8331455230712891\n",
            "step 1420, validation loss: 5.585062503814697, average time over last 10 steps = 0.8187525510787964\n",
            "step 1430, validation loss: 5.375321865081787, average time over last 10 steps = 0.8181010007858276\n",
            "step 1440, validation loss: 5.3708696365356445, average time over last 10 steps = 0.8173707246780395\n",
            "step 1450, validation loss: 5.440679550170898, average time over last 10 steps = 0.817169189453125\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1460, validation loss: 5.4637861251831055, average time over last 10 steps = 0.8353597402572632\n",
            "step 1470, validation loss: 5.467081546783447, average time over last 10 steps = 0.8204970121383667\n",
            "step 1480, validation loss: 5.506750106811523, average time over last 10 steps = 0.8188482522964478\n",
            "step 1490, validation loss: 5.501911163330078, average time over last 10 steps = 0.8185965776443481\n",
            "step 1500, validation loss: 5.492332935333252, average time over last 10 steps = 0.8165811061859131\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1510, validation loss: 5.379566192626953, average time over last 10 steps = 0.8356541156768799\n",
            "step 1520, validation loss: 5.362983703613281, average time over last 10 steps = 0.8197465896606445\n",
            "step 1530, validation loss: 5.305593013763428, average time over last 10 steps = 0.8182208776473999\n",
            "step 1540, validation loss: 5.270211219787598, average time over last 10 steps = 0.8199959039688111\n",
            "step 1550, validation loss: 5.214201927185059, average time over last 10 steps = 0.8202949523925781\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1560, validation loss: 5.3945112228393555, average time over last 10 steps = 0.8425408124923706\n",
            "step 1570, validation loss: 5.40844202041626, average time over last 10 steps = 0.8217880964279175\n",
            "step 1580, validation loss: 5.401155948638916, average time over last 10 steps = 0.8216301441192627\n",
            "step 1590, validation loss: 5.272826671600342, average time over last 10 steps = 0.8196141481399536\n",
            "step 1600, validation loss: 5.252547264099121, average time over last 10 steps = 0.8228217601776123\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1610, validation loss: 5.2195587158203125, average time over last 10 steps = 0.8355799674987793\n",
            "step 1620, validation loss: 5.214841365814209, average time over last 10 steps = 0.8167067289352417\n",
            "step 1630, validation loss: 5.541810989379883, average time over last 10 steps = 0.8196093559265136\n",
            "step 1640, validation loss: 5.274866104125977, average time over last 10 steps = 0.8208331346511841\n",
            "step 1650, validation loss: 5.411862373352051, average time over last 10 steps = 0.81736159324646\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1660, validation loss: 5.594394683837891, average time over last 10 steps = 0.836340856552124\n",
            "step 1670, validation loss: 5.553990364074707, average time over last 10 steps = 0.8224505424499512\n",
            "step 1680, validation loss: 5.569445610046387, average time over last 10 steps = 0.8179158926010132\n",
            "step 1690, validation loss: 5.652068138122559, average time over last 10 steps = 0.8170965909957886\n",
            "step 1700, validation loss: 5.631214141845703, average time over last 10 steps = 0.8181466817855835\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m,\u001b[0m\u001b[44m you\u001b[0m\u001b[41m paid\u001b[0m\u001b[42m for\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m,\u001b[0m\u001b[42m you\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1710, validation loss: 5.2053022384643555, average time over last 10 steps = 0.8374562501907349\n",
            "step 1720, validation loss: 5.252326011657715, average time over last 10 steps = 0.8194322347640991\n",
            "step 1730, validation loss: 5.340530872344971, average time over last 10 steps = 0.8185316324234009\n",
            "step 1740, validation loss: 5.393317222595215, average time over last 10 steps = 0.8166288614273072\n",
            "step 1750, validation loss: 5.392930507659912, average time over last 10 steps = 0.81797354221344\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1760, validation loss: 5.41698694229126, average time over last 10 steps = 0.835619854927063\n",
            "step 1770, validation loss: 5.440778732299805, average time over last 10 steps = 0.8215121984481811\n",
            "step 1780, validation loss: 5.4418816566467285, average time over last 10 steps = 0.8208369016647339\n",
            "step 1790, validation loss: 5.469735145568848, average time over last 10 steps = 0.8210899353027343\n",
            "step 1800, validation loss: 5.545999050140381, average time over last 10 steps = 0.818882417678833\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1810, validation loss: 5.265484809875488, average time over last 10 steps = 0.8344829082489014\n",
            "step 1820, validation loss: 5.228918075561523, average time over last 10 steps = 0.8187145471572876\n",
            "step 1830, validation loss: 5.194683074951172, average time over last 10 steps = 0.8194126605987548\n",
            "step 1840, validation loss: 5.251046180725098, average time over last 10 steps = 0.8183056592941285\n",
            "step 1850, validation loss: 5.43758487701416, average time over last 10 steps = 0.8199437379837036\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1860, validation loss: 5.574708938598633, average time over last 10 steps = 0.8424856185913085\n",
            "step 1870, validation loss: 5.552081108093262, average time over last 10 steps = 0.8191031694412232\n",
            "step 1880, validation loss: 5.5993452072143555, average time over last 10 steps = 0.820086407661438\n",
            "step 1890, validation loss: 5.5919623374938965, average time over last 10 steps = 0.8219776391983032\n",
            "step 1900, validation loss: 5.579150199890137, average time over last 10 steps = 0.8201216936111451\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1910, validation loss: 5.551065444946289, average time over last 10 steps = 0.8362797737121582\n",
            "step 1920, validation loss: 5.6476216316223145, average time over last 10 steps = 0.821066164970398\n",
            "step 1930, validation loss: 5.6238627433776855, average time over last 10 steps = 0.8193091630935669\n",
            "step 1940, validation loss: 5.667879104614258, average time over last 10 steps = 0.8215690612792969\n",
            "step 1950, validation loss: 5.671261787414551, average time over last 10 steps = 0.8191360235214233\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1960, validation loss: 5.694904327392578, average time over last 10 steps = 0.8395719051361084\n",
            "step 1970, validation loss: 5.659710884094238, average time over last 10 steps = 0.815667200088501\n",
            "step 1980, validation loss: 5.618035316467285, average time over last 10 steps = 0.8198651552200318\n",
            "step 1990, validation loss: 5.536045074462891, average time over last 10 steps = 0.8195224523544311\n",
            "step 2000, validation loss: 5.465114593505859, average time over last 10 steps = 0.8178315162658691\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m If\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2010, validation loss: 5.333744049072266, average time over last 10 steps = 0.8333280563354493\n",
            "step 2020, validation loss: 5.247952461242676, average time over last 10 steps = 0.8188053369522095\n",
            "step 2030, validation loss: 5.1903228759765625, average time over last 10 steps = 0.816428828239441\n",
            "step 2040, validation loss: 5.202431678771973, average time over last 10 steps = 0.8170116186141968\n",
            "step 2050, validation loss: 5.231071949005127, average time over last 10 steps = 0.8194036722183228\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2060, validation loss: 5.375676155090332, average time over last 10 steps = 0.830428671836853\n",
            "step 2070, validation loss: 5.35640287399292, average time over last 10 steps = 0.8179023742675782\n",
            "step 2080, validation loss: 5.353512763977051, average time over last 10 steps = 0.8186239957809448\n",
            "step 2090, validation loss: 5.3207550048828125, average time over last 10 steps = 0.8184240579605102\n",
            "step 2100, validation loss: 5.35435676574707, average time over last 10 steps = 0.818054461479187\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2110, validation loss: 5.3665571212768555, average time over last 10 steps = 0.8321063041687011\n",
            "step 2120, validation loss: 5.403404235839844, average time over last 10 steps = 0.8154648780822754\n",
            "step 2130, validation loss: 5.385547637939453, average time over last 10 steps = 0.819629454612732\n",
            "step 2140, validation loss: 5.343398571014404, average time over last 10 steps = 0.8188628673553466\n",
            "step 2150, validation loss: 5.382684707641602, average time over last 10 steps = 0.8202960968017579\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m,\u001b[0m\u001b[41m you\u001b[0m\u001b[42m can\u001b[0m\u001b[43m do\u001b[0m\u001b[44m with\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m you\u001b[0m\u001b[41m can\u001b[0m\u001b[42m do\u001b[0m\u001b[43m with\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2160, validation loss: 5.403958797454834, average time over last 10 steps = 0.8330190181732178\n",
            "step 2170, validation loss: 5.218347549438477, average time over last 10 steps = 0.8232885837554932\n",
            "step 2180, validation loss: 5.284811019897461, average time over last 10 steps = 0.8191172122955322\n",
            "step 2190, validation loss: 5.266315460205078, average time over last 10 steps = 0.8205677986145019\n",
            "step 2200, validation loss: 5.267714023590088, average time over last 10 steps = 0.8216898441314697\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m8\u001b[0m\u001b[43m.\u001b[0m\u001b[44m If\u001b[0m\u001b[41m you\u001b[0m\u001b[42m are\u001b[0m\u001b[43m located\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2210, validation loss: 5.297929763793945, average time over last 10 steps = 0.8456097364425659\n",
            "step 2220, validation loss: 5.2216291427612305, average time over last 10 steps = 0.8210183382034302\n",
            "step 2230, validation loss: 5.25284481048584, average time over last 10 steps = 0.8207526206970215\n",
            "step 2240, validation loss: 5.288784503936768, average time over last 10 steps = 0.8203664302825928\n",
            "step 2250, validation loss: 5.346899032592773, average time over last 10 steps = 0.8198331832885742\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2260, validation loss: 5.413386821746826, average time over last 10 steps = 0.8340667486190796\n",
            "step 2270, validation loss: 5.411416530609131, average time over last 10 steps = 0.8207722902297974\n",
            "step 2280, validation loss: 5.434157371520996, average time over last 10 steps = 0.8216445446014404\n",
            "step 2290, validation loss: 5.454849720001221, average time over last 10 steps = 0.8226524591445923\n",
            "step 2300, validation loss: 5.464158535003662, average time over last 10 steps = 0.8178014516830444\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2310, validation loss: 5.362888336181641, average time over last 10 steps = 0.8332040309906006\n",
            "step 2320, validation loss: 5.700160980224609, average time over last 10 steps = 0.8167083024978637\n",
            "step 2330, validation loss: 5.955768585205078, average time over last 10 steps = 0.8175347805023193\n",
            "step 2340, validation loss: 6.05708122253418, average time over last 10 steps = 0.8164632320404053\n",
            "step 2350, validation loss: 6.1000800132751465, average time over last 10 steps = 0.815306282043457\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2360, validation loss: 6.120967864990234, average time over last 10 steps = 0.8344074964523316\n",
            "step 2370, validation loss: 6.132110118865967, average time over last 10 steps = 0.8170061588287354\n",
            "step 2380, validation loss: 6.139022350311279, average time over last 10 steps = 0.8164040565490722\n",
            "step 2390, validation loss: 6.145716667175293, average time over last 10 steps = 0.8149852514266968\n",
            "step 2400, validation loss: 6.151135444641113, average time over last 10 steps = 0.8140417337417603\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m \u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m \u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m \u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m \u001b[0m\u001b[42m50\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2410, validation loss: 5.476408958435059, average time over last 10 steps = 0.8330727577209472\n",
            "step 2420, validation loss: 5.353397369384766, average time over last 10 steps = 0.8204766273498535\n",
            "step 2430, validation loss: 5.254688262939453, average time over last 10 steps = 0.818273377418518\n",
            "step 2440, validation loss: 5.289935111999512, average time over last 10 steps = 0.822408652305603\n",
            "step 2450, validation loss: 5.196014881134033, average time over last 10 steps = 0.8211259365081787\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2460, validation loss: 5.221175193786621, average time over last 10 steps = 0.8349323272705078\n",
            "step 2470, validation loss: 5.1575164794921875, average time over last 10 steps = 0.8187979459762573\n",
            "step 2480, validation loss: 5.173078536987305, average time over last 10 steps = 0.8189699649810791\n",
            "step 2490, validation loss: 5.183897972106934, average time over last 10 steps = 0.8180872917175293\n",
            "step 2500, validation loss: 5.18778133392334, average time over last 10 steps = 0.8181450366973877\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2510, validation loss: 5.305978775024414, average time over last 10 steps = 0.8272583246231079\n",
            "step 2520, validation loss: 5.439653396606445, average time over last 10 steps = 0.8126130342483521\n",
            "step 2530, validation loss: 5.531460762023926, average time over last 10 steps = 0.8067820072174072\n",
            "step 2540, validation loss: 5.559813976287842, average time over last 10 steps = 0.8146098136901856\n",
            "step 2550, validation loss: 5.4126386642456055, average time over last 10 steps = 0.8187283277511597\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m.\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2560, validation loss: 5.3225555419921875, average time over last 10 steps = 0.8361407518386841\n",
            "step 2570, validation loss: 5.272750377655029, average time over last 10 steps = 0.819452953338623\n",
            "step 2580, validation loss: 5.320997714996338, average time over last 10 steps = 0.8188616037368774\n",
            "step 2590, validation loss: 5.509289741516113, average time over last 10 steps = 0.813286542892456\n",
            "step 2600, validation loss: 5.402092933654785, average time over last 10 steps = 0.8207459211349487\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2610, validation loss: 5.259662628173828, average time over last 10 steps = 0.8371423959732056\n",
            "step 2620, validation loss: 5.205160140991211, average time over last 10 steps = 0.819325304031372\n",
            "step 2630, validation loss: 5.23978853225708, average time over last 10 steps = 0.8200413703918457\n",
            "step 2640, validation loss: 5.208001136779785, average time over last 10 steps = 0.8195994377136231\n",
            "step 2650, validation loss: 5.274066925048828, average time over last 10 steps = 0.8215693235397339\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2660, validation loss: 5.258874893188477, average time over last 10 steps = 0.8355875015258789\n",
            "step 2670, validation loss: 5.196277618408203, average time over last 10 steps = 0.8204571723937988\n",
            "step 2680, validation loss: 5.179675102233887, average time over last 10 steps = 0.8230595588684082\n",
            "step 2690, validation loss: 5.164453029632568, average time over last 10 steps = 0.8184857845306397\n",
            "step 2700, validation loss: 5.373897552490234, average time over last 10 steps = 0.8177862644195557\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2710, validation loss: 5.399137496948242, average time over last 10 steps = 0.8337522745132446\n",
            "step 2720, validation loss: 5.384289741516113, average time over last 10 steps = 0.8200108051300049\n",
            "step 2730, validation loss: 5.386088848114014, average time over last 10 steps = 0.8176727771759034\n",
            "step 2740, validation loss: 5.253535747528076, average time over last 10 steps = 0.8194024801254273\n",
            "step 2750, validation loss: 5.3192596435546875, average time over last 10 steps = 0.8194183349609375\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2760, validation loss: 5.257493495941162, average time over last 10 steps = 0.8354279518127441\n",
            "step 2770, validation loss: 5.193537712097168, average time over last 10 steps = 0.820146918296814\n",
            "step 2780, validation loss: 5.203105926513672, average time over last 10 steps = 0.820747685432434\n",
            "step 2790, validation loss: 5.20850944519043, average time over last 10 steps = 0.8240711212158203\n",
            "step 2800, validation loss: 5.165727615356445, average time over last 10 steps = 0.8218502759933471\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2810, validation loss: 5.1867170333862305, average time over last 10 steps = 0.8339752435684205\n",
            "step 2820, validation loss: 5.18481969833374, average time over last 10 steps = 0.8196565389633179\n",
            "step 2830, validation loss: 5.203917503356934, average time over last 10 steps = 0.8162472248077393\n",
            "step 2840, validation loss: 5.156701564788818, average time over last 10 steps = 0.8175369024276733\n",
            "step 2850, validation loss: 5.158380508422852, average time over last 10 steps = 0.8189965486526489\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2860, validation loss: 5.247537612915039, average time over last 10 steps = 0.8345747232437134\n",
            "step 2870, validation loss: 5.303951740264893, average time over last 10 steps = 0.8171207189559937\n",
            "step 2880, validation loss: 5.368274688720703, average time over last 10 steps = 0.8195877552032471\n",
            "step 2890, validation loss: 5.385313034057617, average time over last 10 steps = 0.8161436080932617\n",
            "step 2900, validation loss: 5.3891496658325195, average time over last 10 steps = 0.8174968004226685\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2910, validation loss: 5.404877662658691, average time over last 10 steps = 0.8333601236343384\n",
            "step 2920, validation loss: 5.414946556091309, average time over last 10 steps = 0.8178393602371216\n",
            "step 2930, validation loss: 5.435819625854492, average time over last 10 steps = 0.8173234224319458\n",
            "step 2940, validation loss: 5.570307731628418, average time over last 10 steps = 0.8197147369384765\n",
            "step 2950, validation loss: 5.815670013427734, average time over last 10 steps = 0.8170559167861938\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m00\u001b[0m\u001b[44m%\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\u001b[43m93\u001b[0m\u001b[44m   \u001b[0m\u001b[41m \u001b[0m\u001b[42m0\u001b[0m\u001b[43m.\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m00\u001b[0m\u001b[43m   \u001b[0m\u001b[44m \u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2960, validation loss: 5.886375427246094, average time over last 10 steps = 0.8352414131164551\n",
            "step 2970, validation loss: 6.093250274658203, average time over last 10 steps = 0.8181771993637085\n",
            "step 2980, validation loss: 6.03275203704834, average time over last 10 steps = 0.8198572158813476\n",
            "step 2990, validation loss: 5.503974914550781, average time over last 10 steps = 0.8182614803314209\n",
            "step 3000, validation loss: 6.196558952331543, average time over last 10 steps = 0.8170418977737427\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m any\u001b[0m\u001b[42m other\u001b[0m\u001b[43m than\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m any\u001b[0m\u001b[44m other\u001b[0m\u001b[41m terms\u001b[0m\u001b[42m of\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3010, validation loss: 6.426998138427734, average time over last 10 steps = 0.8333780527114868\n",
            "step 3020, validation loss: 6.258671760559082, average time over last 10 steps = 0.8170264959335327\n",
            "step 3030, validation loss: 5.913238525390625, average time over last 10 steps = 0.8181366682052612\n",
            "step 3040, validation loss: 5.342403411865234, average time over last 10 steps = 0.8177024602890015\n",
            "step 3050, validation loss: 5.340741157531738, average time over last 10 steps = 0.8203032970428467\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3060, validation loss: 4.918810844421387, average time over last 10 steps = 0.8340243339538574\n",
            "step 3070, validation loss: 4.827877998352051, average time over last 10 steps = 0.8175088882446289\n",
            "step 3080, validation loss: 5.169578552246094, average time over last 10 steps = 0.8197976350784302\n",
            "step 3090, validation loss: 5.2382659912109375, average time over last 10 steps = 0.8179476261138916\n",
            "step 3100, validation loss: 5.284278869628906, average time over last 10 steps = 0.818268609046936\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m children\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m children\u001b[0m\u001b[42m of\u001b[0m\u001b[43m Israel\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m children\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m children\u001b[0m\u001b[42m of\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3110, validation loss: 5.3301310539245605, average time over last 10 steps = 0.8342218637466431\n",
            "step 3120, validation loss: 5.301016807556152, average time over last 10 steps = 0.8189741611480713\n",
            "step 3130, validation loss: 5.29665994644165, average time over last 10 steps = 0.8207029581069947\n",
            "step 3140, validation loss: 5.406132221221924, average time over last 10 steps = 0.8225949287414551\n",
            "step 3150, validation loss: 5.390827655792236, average time over last 10 steps = 0.8197708845138549\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3160, validation loss: 5.363302230834961, average time over last 10 steps = 0.8393942356109619\n",
            "step 3170, validation loss: 5.36931848526001, average time over last 10 steps = 0.819656229019165\n",
            "step 3180, validation loss: 5.370354175567627, average time over last 10 steps = 0.8185571432113647\n",
            "step 3190, validation loss: 5.310869216918945, average time over last 10 steps = 0.8182689428329468\n",
            "step 3200, validation loss: 5.187933444976807, average time over last 10 steps = 0.8197712421417236\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m:\u001b[0m\u001b[43m1\u001b[0m\u001b[44m And\u001b[0m\u001b[41m when\u001b[0m\u001b[42m the\u001b[0m\u001b[43m works\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m License\u001b[0m\u001b[42m as\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3210, validation loss: 4.977025985717773, average time over last 10 steps = 0.8330884218215943\n",
            "step 3220, validation loss: 4.974509239196777, average time over last 10 steps = 0.8172090291976929\n",
            "step 3230, validation loss: 5.0370192527771, average time over last 10 steps = 0.817003583908081\n",
            "step 3240, validation loss: 5.038086891174316, average time over last 10 steps = 0.8183366298675537\n",
            "step 3250, validation loss: 5.0598602294921875, average time over last 10 steps = 0.817401647567749\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3260, validation loss: 5.095611572265625, average time over last 10 steps = 0.8305432796478271\n",
            "step 3270, validation loss: 5.091052055358887, average time over last 10 steps = 0.8186082601547241\n",
            "step 3280, validation loss: 4.974369049072266, average time over last 10 steps = 0.8164983987808228\n",
            "step 3290, validation loss: 4.998106002807617, average time over last 10 steps = 0.8183119535446167\n",
            "step 3300, validation loss: 4.963557720184326, average time over last 10 steps = 0.818405556678772\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m including\u001b[0m\u001b[42m legal\u001b[0m\u001b[43m fees\u001b[0m\u001b[44m to\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m (\u001b[0m\u001b[41mc\u001b[0m\u001b[42m.i\u001b[0m\u001b[43m.f\u001b[0m\u001b[44m.,\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3310, validation loss: 4.974104881286621, average time over last 10 steps = 0.8370420217514039\n",
            "step 3320, validation loss: 4.920985221862793, average time over last 10 steps = 0.8175536394119263\n",
            "step 3330, validation loss: 4.984203815460205, average time over last 10 steps = 0.816291356086731\n",
            "step 3340, validation loss: 5.0844316482543945, average time over last 10 steps = 0.8173354387283325\n",
            "step 3350, validation loss: 5.061925888061523, average time over last 10 steps = 0.8176537275314331\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m including\u001b[0m\u001b[44m legal\u001b[0m\u001b[41m fees\u001b[0m\u001b[42m to\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3360, validation loss: 5.102402210235596, average time over last 10 steps = 0.8343645572662354\n",
            "step 3370, validation loss: 4.959033966064453, average time over last 10 steps = 0.8175651550292968\n",
            "step 3380, validation loss: 4.927326679229736, average time over last 10 steps = 0.8189541578292847\n",
            "step 3390, validation loss: 4.946597099304199, average time over last 10 steps = 0.8166552305221557\n",
            "step 3400, validation loss: 5.011869430541992, average time over last 10 steps = 0.8194355487823486\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3410, validation loss: 5.281163692474365, average time over last 10 steps = 0.8316126585006713\n",
            "step 3420, validation loss: 4.9023847579956055, average time over last 10 steps = 0.816936445236206\n",
            "step 3430, validation loss: 5.060836315155029, average time over last 10 steps = 0.8171381473541259\n",
            "step 3440, validation loss: 5.157101631164551, average time over last 10 steps = 0.8172352313995361\n",
            "step 3450, validation loss: 5.212174415588379, average time over last 10 steps = 0.818409776687622\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m8\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m8\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m8\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3460, validation loss: 5.228368759155273, average time over last 10 steps = 0.8380274772644043\n",
            "step 3470, validation loss: 5.228828430175781, average time over last 10 steps = 0.8211495876312256\n",
            "step 3480, validation loss: 4.976435661315918, average time over last 10 steps = 0.8181197643280029\n",
            "step 3490, validation loss: 4.913153648376465, average time over last 10 steps = 0.8168954133987427\n",
            "step 3500, validation loss: 5.013087749481201, average time over last 10 steps = 0.8197868824005127\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3510, validation loss: 5.087911605834961, average time over last 10 steps = 0.8358469724655151\n",
            "step 3520, validation loss: 5.1222991943359375, average time over last 10 steps = 0.8192390680313111\n",
            "step 3530, validation loss: 5.1422319412231445, average time over last 10 steps = 0.8201030492782593\n",
            "step 3540, validation loss: 5.148352146148682, average time over last 10 steps = 0.8178910493850708\n",
            "step 3550, validation loss: 5.171754360198975, average time over last 10 steps = 0.8173990488052368\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.16 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3560, validation loss: 5.153852939605713, average time over last 10 steps = 0.8337522268295288\n",
            "step 3570, validation loss: 5.0383710861206055, average time over last 10 steps = 0.8175605773925781\n",
            "step 3580, validation loss: 5.317078590393066, average time over last 10 steps = 0.817280387878418\n",
            "step 3590, validation loss: 4.951458930969238, average time over last 10 steps = 0.8170310258865356\n",
            "step 3600, validation loss: 4.93257999420166, average time over last 10 steps = 0.8172910928726196\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m work\u001b[0m\u001b[41m in\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3610, validation loss: 4.932371139526367, average time over last 10 steps = 0.8322682619094849\n",
            "step 3620, validation loss: 5.011502742767334, average time over last 10 steps = 0.8193115711212158\n",
            "step 3630, validation loss: 5.209064960479736, average time over last 10 steps = 0.8167091846466065\n",
            "step 3640, validation loss: 5.31571102142334, average time over last 10 steps = 0.8170129060745239\n",
            "step 3650, validation loss: 5.308131694793701, average time over last 10 steps = 0.8182460069656372\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.F\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.F\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3660, validation loss: 5.362669467926025, average time over last 10 steps = 0.8311264276504516\n",
            "step 3670, validation loss: 5.328639030456543, average time over last 10 steps = 0.8172183752059936\n",
            "step 3680, validation loss: 5.3304243087768555, average time over last 10 steps = 0.8194242477416992\n",
            "step 3690, validation loss: 5.2686309814453125, average time over last 10 steps = 0.8157721996307373\n",
            "step 3700, validation loss: 5.355538368225098, average time over last 10 steps = 0.8185297966003418\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m8\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m:\u001b[0m\u001b[42m00\u001b[0m\u001b[43m8\u001b[0m\u001b[44m:\u001b[0m\u001b[41m00\u001b[0m\u001b[42m8\u001b[0m\u001b[43m I\u001b[0m\u001b[44m am\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3710, validation loss: 5.332887649536133, average time over last 10 steps = 0.8312497615814209\n",
            "step 3720, validation loss: 5.324615478515625, average time over last 10 steps = 0.8162714719772339\n",
            "step 3730, validation loss: 5.327448844909668, average time over last 10 steps = 0.8180524110794067\n",
            "step 3740, validation loss: 5.345383644104004, average time over last 10 steps = 0.8183971166610717\n",
            "step 3750, validation loss: 5.324902534484863, average time over last 10 steps = 0.8164808511734009\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m:\u001b[0m\u001b[44m00\u001b[0m\u001b[41m1\u001b[0m\u001b[42m:\u001b[0m\u001b[43m00\u001b[0m\u001b[44m1\u001b[0m\u001b[41m And\u001b[0m\u001b[42m when\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m License\u001b[0m\u001b[44m when\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3760, validation loss: 5.295654296875, average time over last 10 steps = 0.8331257104873657\n",
            "step 3770, validation loss: 5.124076843261719, average time over last 10 steps = 0.8178579568862915\n",
            "step 3780, validation loss: 5.059718608856201, average time over last 10 steps = 0.817749810218811\n",
            "step 3790, validation loss: 4.956387519836426, average time over last 10 steps = 0.818551778793335\n",
            "step 3800, validation loss: 4.958043575286865, average time over last 10 steps = 0.8179788589477539\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.F\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.F\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.F\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3810, validation loss: 4.9485764503479, average time over last 10 steps = 0.8309757709503174\n",
            "step 3820, validation loss: 4.920001983642578, average time over last 10 steps = 0.8177746772766114\n",
            "step 3830, validation loss: 4.969728946685791, average time over last 10 steps = 0.8214064121246338\n",
            "step 3840, validation loss: 5.0889177322387695, average time over last 10 steps = 0.8185899019241333\n",
            "step 3850, validation loss: 5.088662147521973, average time over last 10 steps = 0.8176713466644288\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m are\u001b[0m\u001b[42m not\u001b[0m\u001b[43m accepted\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m United\u001b[0m\u001b[43m States\u001b[0m\u001b[44m,\u001b[0m\u001b[41m but\u001b[0m\u001b[42m not\u001b[0m\u001b[43m protected\u001b[0m\u001b[44m by\u001b[0m\u001b[41m U\u001b[0m\u001b[42m.S\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3860, validation loss: 5.017473220825195, average time over last 10 steps = 0.8350079536437989\n",
            "step 3870, validation loss: 5.078733921051025, average time over last 10 steps = 0.8166695833206177\n",
            "step 3880, validation loss: 5.0850138664245605, average time over last 10 steps = 0.8177025794982911\n",
            "step 3890, validation loss: 5.096153259277344, average time over last 10 steps = 0.8208272457122803\n",
            "step 3900, validation loss: 5.078437328338623, average time over last 10 steps = 0.8168246030807496\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m or\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m or\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3910, validation loss: 5.093780040740967, average time over last 10 steps = 0.8333857536315918\n",
            "step 3920, validation loss: 5.065431118011475, average time over last 10 steps = 0.8217523097991943\n",
            "step 3930, validation loss: 5.1220293045043945, average time over last 10 steps = 0.8159979104995727\n",
            "step 3940, validation loss: 4.988332748413086, average time over last 10 steps = 0.8182296276092529\n",
            "step 3950, validation loss: 4.954158782958984, average time over last 10 steps = 0.8191774129867554\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m you\u001b[0m\u001b[43m must\u001b[0m\u001b[44m,\u001b[0m\u001b[41m do\u001b[0m\u001b[42m not\u001b[0m\u001b[43m agree\u001b[0m\u001b[44m to\u001b[0m\u001b[41m the\u001b[0m\u001b[42m terms\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m United\u001b[0m\u001b[42m States\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3960, validation loss: 4.957050323486328, average time over last 10 steps = 0.8328772068023682\n",
            "step 3970, validation loss: 4.95144510269165, average time over last 10 steps = 0.8173146724700928\n",
            "step 3980, validation loss: 4.9828715324401855, average time over last 10 steps = 0.8176223754882812\n",
            "step 3990, validation loss: 5.005643844604492, average time over last 10 steps = 0.816858172416687\n",
            "step 4000, validation loss: 4.941884517669678, average time over last 10 steps = 0.8174205541610717\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m accordance\u001b[0m\u001b[42m with\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m in\u001b[0m\u001b[42m accordance\u001b[0m\u001b[43m with\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4010, validation loss: 4.971771240234375, average time over last 10 steps = 0.8318655252456665\n",
            "step 4020, validation loss: 5.072455883026123, average time over last 10 steps = 0.817380404472351\n",
            "step 4030, validation loss: 5.079419136047363, average time over last 10 steps = 0.8181536674499512\n",
            "step 4040, validation loss: 5.112264633178711, average time over last 10 steps = 0.81868417263031\n",
            "step 4050, validation loss: 5.117144584655762, average time over last 10 steps = 0.8185133695602417\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m any\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m including\u001b[0m\u001b[44m legal\u001b[0m\u001b[41m fees\u001b[0m\u001b[42m to\u001b[0m\u001b[43m and\u001b[0m\u001b[44m (\u001b[0m\u001b[41mnon\u001b[0m\u001b[42m-US\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4060, validation loss: 5.124337196350098, average time over last 10 steps = 0.8341306924819947\n",
            "step 4070, validation loss: 5.137903213500977, average time over last 10 steps = 0.8169549703598022\n",
            "step 4080, validation loss: 5.128199577331543, average time over last 10 steps = 0.8164456605911254\n",
            "step 4090, validation loss: 5.045633316040039, average time over last 10 steps = 0.8170602083206177\n",
            "step 4100, validation loss: 5.256174087524414, average time over last 10 steps = 0.8141196489334106\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m20\u001b[0m\u001b[44m67\u001b[0m\u001b[41m67\u001b[0m\u001b[42m67\u001b[0m\u001b[43m \u001b[0m\u001b[44m30\u001b[0m\u001b[41m00\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m \u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m49\u001b[0m\u001b[41m49\u001b[0m\u001b[42m49\u001b[0m\u001b[43m \u001b[0m\u001b[44m12\u001b[0m\u001b[41m59\u001b[0m\u001b[42m49\u001b[0m\u001b[43m49\u001b[0m\u001b[44m49\u001b[0m\u001b[41m \u001b[0m\u001b[42m12\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4110, validation loss: 5.451045036315918, average time over last 10 steps = 0.8312833786010743\n",
            "step 4120, validation loss: 5.601281642913818, average time over last 10 steps = 0.8100386619567871\n",
            "step 4130, validation loss: 5.668724536895752, average time over last 10 steps = 0.8128432035446167\n",
            "step 4140, validation loss: 5.701027870178223, average time over last 10 steps = 0.8109819650650024\n",
            "step 4150, validation loss: 5.710933208465576, average time over last 10 steps = 0.811535382270813\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m20\u001b[0m\u001b[44m67\u001b[0m\u001b[41m67\u001b[0m\u001b[42m67\u001b[0m\u001b[43m \u001b[0m\u001b[44m20\u001b[0m\u001b[41m67\u001b[0m\u001b[42m67\u001b[0m\u001b[43m67\u001b[0m\u001b[44m67\u001b[0m\u001b[41m \u001b[0m\u001b[42m20\u001b[0m\u001b[43m20\u001b[0m\u001b[44m20\u001b[0m\u001b[41m20\u001b[0m\u001b[42m67\u001b[0m\u001b[43m \u001b[0m\u001b[44m17\u001b[0m\u001b[41m17\u001b[0m\u001b[42m17\u001b[0m\u001b[43m17\u001b[0m\u001b[44m17\u001b[0m\u001b[41m \u001b[0m\u001b[42m17\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4160, validation loss: 5.715185165405273, average time over last 10 steps = 0.8260100364685059\n",
            "step 4170, validation loss: 5.725979328155518, average time over last 10 steps = 0.8129620313644409\n",
            "step 4180, validation loss: 5.300201892852783, average time over last 10 steps = 0.8138370037078857\n",
            "step 4190, validation loss: 5.140252590179443, average time over last 10 steps = 0.8182390451431274\n",
            "step 4200, validation loss: 5.010202884674072, average time over last 10 steps = 0.8227951526641846\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m you\u001b[0m\u001b[44m must\u001b[0m\u001b[41m,\u001b[0m\u001b[42m you\u001b[0m\u001b[43m must\u001b[0m\u001b[44m,\u001b[0m\u001b[41m if\u001b[0m\u001b[42m you\u001b[0m\u001b[43m are\u001b[0m\u001b[44m located\u001b[0m\u001b[41m before\u001b[0m\u001b[42m using\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4210, validation loss: 5.018918037414551, average time over last 10 steps = 0.8333924770355224\n",
            "step 4220, validation loss: 5.00636100769043, average time over last 10 steps = 0.8209997415542603\n",
            "step 4230, validation loss: 4.974940299987793, average time over last 10 steps = 0.8197835445404053\n",
            "step 4240, validation loss: 4.9901580810546875, average time over last 10 steps = 0.8167455434799195\n",
            "step 4250, validation loss: 4.928256511688232, average time over last 10 steps = 0.8171699285507202\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4260, validation loss: 4.953821659088135, average time over last 10 steps = 0.8349521875381469\n",
            "step 4270, validation loss: 4.929906368255615, average time over last 10 steps = 0.8162991523742675\n",
            "step 4280, validation loss: 5.01629638671875, average time over last 10 steps = 0.813915467262268\n",
            "step 4290, validation loss: 5.5127410888671875, average time over last 10 steps = 0.810203242301941\n",
            "step 4300, validation loss: 5.862133979797363, average time over last 10 steps = 0.8114214420318604\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m43\u001b[0m\u001b[44m43\u001b[0m\u001b[41m \u001b[0m\u001b[42m43\u001b[0m\u001b[43m43\u001b[0m\u001b[44m \u001b[0m\u001b[41m47\u001b[0m\u001b[42m47\u001b[0m\u001b[43m \u001b[0m\u001b[44m43\u001b[0m\u001b[41m43\u001b[0m\u001b[42m \u001b[0m\u001b[43m43\u001b[0m\u001b[44m43\u001b[0m\u001b[41m \u001b[0m\u001b[42m43\u001b[0m\u001b[43m \u001b[0m\u001b[44m43\u001b[0m\u001b[41m \u001b[0m\u001b[42m43\u001b[0m\u001b[43m43\u001b[0m\u001b[44m \u001b[0m\u001b[41m43\u001b[0m\u001b[42m43\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4310, validation loss: 6.207114219665527, average time over last 10 steps = 0.8241227149963379\n",
            "step 4320, validation loss: 5.64212703704834, average time over last 10 steps = 0.8142355918884278\n",
            "step 4330, validation loss: 5.289117336273193, average time over last 10 steps = 0.8179103612899781\n",
            "step 4340, validation loss: 5.204453945159912, average time over last 10 steps = 0.8191351175308228\n",
            "step 4350, validation loss: 5.053005218505859, average time over last 10 steps = 0.8162766933441162\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m terms\u001b[0m\u001b[43m of\u001b[0m\u001b[44m this\u001b[0m\u001b[41m work\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4360, validation loss: 5.103891372680664, average time over last 10 steps = 0.8282131671905517\n",
            "step 4370, validation loss: 5.109236717224121, average time over last 10 steps = 0.8098062753677369\n",
            "step 4380, validation loss: 5.037840843200684, average time over last 10 steps = 0.8191206216812134\n",
            "step 4390, validation loss: 4.9526262283325195, average time over last 10 steps = 0.8187635898590088\n",
            "step 4400, validation loss: 4.983442306518555, average time over last 10 steps = 0.816330099105835\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m United\u001b[0m\u001b[43m States\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m.\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4410, validation loss: 5.012979507446289, average time over last 10 steps = 0.8332478284835816\n",
            "step 4420, validation loss: 5.037189483642578, average time over last 10 steps = 0.8187083005905151\n",
            "step 4430, validation loss: 5.148440361022949, average time over last 10 steps = 0.8160221815109253\n",
            "step 4440, validation loss: 5.005144119262695, average time over last 10 steps = 0.8189987182617188\n",
            "step 4450, validation loss: 4.990790843963623, average time over last 10 steps = 0.8209697723388671\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4460, validation loss: 4.948293685913086, average time over last 10 steps = 0.832893681526184\n",
            "step 4470, validation loss: 4.986748218536377, average time over last 10 steps = 0.8197884559631348\n",
            "step 4480, validation loss: 5.138838291168213, average time over last 10 steps = 0.8204572439193726\n",
            "step 4490, validation loss: 5.175476551055908, average time over last 10 steps = 0.8180638074874877\n",
            "step 4500, validation loss: 5.15285587310791, average time over last 10 steps = 0.819834566116333\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m \u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m \u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4510, validation loss: 5.103106498718262, average time over last 10 steps = 0.8367667436599732\n",
            "step 4520, validation loss: 5.065990447998047, average time over last 10 steps = 0.8168182611465454\n",
            "step 4530, validation loss: 5.035915374755859, average time over last 10 steps = 0.8176807880401611\n",
            "step 4540, validation loss: 5.015637397766113, average time over last 10 steps = 0.8176611661911011\n",
            "step 4550, validation loss: 4.961582660675049, average time over last 10 steps = 0.8209359645843506\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m If\u001b[0m\u001b[43m you\u001b[0m\u001b[44m do\u001b[0m\u001b[41m not\u001b[0m\u001b[42m agree\u001b[0m\u001b[43m to\u001b[0m\u001b[44m,\u001b[0m\u001b[41m you\u001b[0m\u001b[42m must\u001b[0m\u001b[43m,\u001b[0m\u001b[44m do\u001b[0m\u001b[41m not\u001b[0m\u001b[42m agree\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4560, validation loss: 4.976654529571533, average time over last 10 steps = 0.8342585802078247\n",
            "step 4570, validation loss: 4.978618621826172, average time over last 10 steps = 0.8192708969116211\n",
            "step 4580, validation loss: 4.943048477172852, average time over last 10 steps = 0.8203904390335083\n",
            "step 4590, validation loss: 4.973529815673828, average time over last 10 steps = 0.8178879261016846\n",
            "step 4600, validation loss: 4.971278667449951, average time over last 10 steps = 0.820944857597351\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4610, validation loss: 4.973095893859863, average time over last 10 steps = 0.8314060211181641\n",
            "step 4620, validation loss: 4.953221321105957, average time over last 10 steps = 0.8171254873275757\n",
            "step 4630, validation loss: 4.927063941955566, average time over last 10 steps = 0.8190541982650756\n",
            "step 4640, validation loss: 5.032873153686523, average time over last 10 steps = 0.8175575971603394\n",
            "step 4650, validation loss: 5.091490268707275, average time over last 10 steps = 0.8169324159622192\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4660, validation loss: 5.119013786315918, average time over last 10 steps = 0.8324687957763672\n",
            "step 4670, validation loss: 5.133035659790039, average time over last 10 steps = 0.817126202583313\n",
            "step 4680, validation loss: 5.142886161804199, average time over last 10 steps = 0.81753089427948\n",
            "step 4690, validation loss: 5.1605682373046875, average time over last 10 steps = 0.81829993724823\n",
            "step 4700, validation loss: 5.179582118988037, average time over last 10 steps = 0.8172440767288208\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m License\u001b[0m\u001b[42m must\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4710, validation loss: 5.219923973083496, average time over last 10 steps = 0.8335327863693237\n",
            "step 4720, validation loss: 5.277814865112305, average time over last 10 steps = 0.8176703929901123\n",
            "step 4730, validation loss: 5.388391017913818, average time over last 10 steps = 0.8167015552520752\n",
            "step 4740, validation loss: 5.418181419372559, average time over last 10 steps = 0.8168662786483765\n",
            "step 4750, validation loss: 5.439157485961914, average time over last 10 steps = 0.8193769216537475\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m   \u001b[0m\u001b[43m \u001b[0m\u001b[44m4\u001b[0m\u001b[41m%\u001b[0m\u001b[42m Est\u001b[0m\u001b[43m.\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m93\u001b[0m\u001b[43m  \u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m.\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m   \u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4760, validation loss: 5.422653675079346, average time over last 10 steps = 0.8405360221862793\n",
            "step 4770, validation loss: 5.175199508666992, average time over last 10 steps = 0.817507529258728\n",
            "step 4780, validation loss: 5.69397497177124, average time over last 10 steps = 0.8205554246902466\n",
            "step 4790, validation loss: 5.780699253082275, average time over last 10 steps = 0.8147503852844238\n",
            "step 4800, validation loss: 5.815398216247559, average time over last 10 steps = 0.8173633575439453\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m84\u001b[0m\u001b[41m11\u001b[0m\u001b[42m.\u001b[0m\u001b[43m10\u001b[0m\u001b[44m.\u001b[0m\u001b[41m00\u001b[0m\u001b[42m A\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m84\u001b[0m\u001b[41m12\u001b[0m\u001b[42m.\u001b[0m\u001b[43m10\u001b[0m\u001b[44m.\u001b[0m\u001b[41m00\u001b[0m\u001b[42m A\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m84\u001b[0m\u001b[41m84\u001b[0m\u001b[42m.\u001b[0m\u001b[43m90\u001b[0m\u001b[44m.\u001b[0m\u001b[41m00\u001b[0m\u001b[42m A\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4810, validation loss: 5.0774993896484375, average time over last 10 steps = 0.8319115161895752\n",
            "step 4820, validation loss: 5.0291972160339355, average time over last 10 steps = 0.8166697978973388\n",
            "step 4830, validation loss: 5.023346900939941, average time over last 10 steps = 0.8176826000213623\n",
            "step 4840, validation loss: 4.5386271476745605, average time over last 10 steps = 0.8174148321151733\n",
            "step 4850, validation loss: 4.7116193771362305, average time over last 10 steps = 0.8174466609954834\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m included\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4860, validation loss: 4.950217247009277, average time over last 10 steps = 0.8309845924377441\n",
            "step 4870, validation loss: 4.973875045776367, average time over last 10 steps = 0.8175827503204346\n",
            "step 4880, validation loss: 5.075793266296387, average time over last 10 steps = 0.8171236038208007\n",
            "step 4890, validation loss: 5.048326015472412, average time over last 10 steps = 0.8171704530715942\n",
            "step 4900, validation loss: 5.045876979827881, average time over last 10 steps = 0.8192315816879272\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m God\u001b[0m\u001b[43m of\u001b[0m\u001b[44m Israel\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m children\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m the\u001b[0m\u001b[44m children\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Israel\u001b[0m\u001b[43m,\u001b[0m\u001b[44m the\u001b[0m\u001b[41m children\u001b[0m\u001b[42m of\u001b[0m\u001b[43m Israel\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m children\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4910, validation loss: 5.061458587646484, average time over last 10 steps = 0.8338188886642456\n",
            "step 4920, validation loss: 5.147325038909912, average time over last 10 steps = 0.816918921470642\n",
            "step 4930, validation loss: 5.184009552001953, average time over last 10 steps = 0.8186743974685669\n",
            "step 4940, validation loss: 5.1301164627075195, average time over last 10 steps = 0.8186764717102051\n",
            "step 4950, validation loss: 5.154748916625977, average time over last 10 steps = 0.8170047998428345\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m God\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m people\u001b[0m\u001b[42m of\u001b[0m\u001b[43m Israel\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m people\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m the\u001b[0m\u001b[42m people\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4960, validation loss: 5.146257400512695, average time over last 10 steps = 0.8341023921966553\n",
            "step 4970, validation loss: 5.079036712646484, average time over last 10 steps = 0.8182807683944702\n",
            "step 4980, validation loss: 4.822497367858887, average time over last 10 steps = 0.8193175077438355\n",
            "step 4990, validation loss: 4.666287422180176, average time over last 10 steps = 0.8182462453842163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_generations(sample_text = \"The Project Gutenberg eBook of\", len_gen = 10):\n",
        "  sample = enc.encode(sample_text)\n",
        "  buf = torch.tensor(sample)\n",
        "  sample = buf.view(1, -1).to(device_type)\n",
        "\n",
        "  for _ in range(len_gen):\n",
        "    with torch.no_grad(): # Good practice for inference to save memory\n",
        "        with autocast_ctx:\n",
        "            op = gpt(sample)\n",
        "        op = op[:,-1,:]\n",
        "\n",
        "        next_ids = torch.argmax(op, dim=-1, keepdim=True)\n",
        "        sample = torch.cat((sample, next_ids), dim=1)\n",
        "        next_token = next_ids.item()\n",
        "  tiktokenize_tokens(sample[0])\n",
        "  print()\n",
        "\n",
        "test_model_generations(sample_text=\"Project Gutenberg is\", len_gen=25)\n",
        "test_model_generations(sample_text=\"He was the main\", len_gen=50)\n",
        "test_model_generations(sample_text=\"The place is well known for its\", len_gen=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBqtyUh4cOjT",
        "outputId": "956b53da-2f3a-49cc-bbcb-7f8ac674ed37"
      },
      "id": "xBqtyUh4cOjT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m the\u001b[0m\u001b[41m fee\u001b[0m\u001b[42m is\u001b[0m\u001b[43m the\u001b[0m\u001b[44m use\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mSection\u001b[0m\u001b[42m \u001b[0m\u001b[43m3\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Information\u001b[0m\u001b[42m about\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m PG\u001b[0m\u001b[42m search\u001b[0m\u001b[43m facility\u001b[0m\u001b[44m:\u001b[0m\u001b[41m \u001b[0m\u001b[42m4\u001b[0m\u001b[43m%\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m labor\u001b[0m\u001b[43m force\u001b[0m\u001b[44m;\u001b[0m\u001b[41m \u001b[0m\u001b[42m4\u001b[0m\u001b[43m%\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m labor\u001b[0m\u001b[43m force\u001b[0m\u001b[44m;\u001b[0m\u001b[41m \u001b[0m\u001b[42m4\u001b[0m\u001b[43m%\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m labor\u001b[0m\u001b[43m force\u001b[0m\u001b[44m;\u001b[0m\u001b[41m \u001b[0m\u001b[42m4\u001b[0m\u001b[43m%\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m labor\u001b[0m\u001b[43m force\u001b[0m\u001b[44m;\u001b[0m\u001b[41m \u001b[0m\u001b[42m4\u001b[0m\u001b[43m%\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m labor\u001b[0m\u001b[43m force\u001b[0m\u001b[44m;\u001b[0m\u001b[41m \u001b[0m\u001b[42m4\u001b[0m\u001b[43m%\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m labor\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m own\u001b[0m\u001b[41m sake\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mThe\u001b[0m\u001b[41m Foundation\u001b[0m\u001b[42m is\u001b[0m\u001b[43m a\u001b[0m\u001b[44m registered\u001b[0m\u001b[41m trademark\u001b[0m\u001b[42m as\u001b[0m\u001b[43m set\u001b[0m\u001b[44m forth\u001b[0m\u001b[41m in\u001b[0m\u001b[42m paragraph\u001b[0m\u001b[43m \u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m3\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m5\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m•\u001b[0m\u001b[41m You\u001b[0m\u001b[42m provide\u001b[0m\u001b[43m a\u001b[0m\u001b[44m replacement\u001b[0m\u001b[41m copy\u001b[0m\u001b[42m,\u001b[0m\u001b[43m a\u001b[0m\u001b[44m replacement\u001b[0m\u001b[41m copy\u001b[0m\u001b[42m,\u001b[0m\u001b[43m or\u001b[0m\u001b[44m other\u001b[0m\u001b[41m medium\u001b[0m\u001b[42m,\u001b[0m\u001b[43m a\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m work\u001b[0m\u001b[41m,\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text), start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mzeMcq1erd-",
        "outputId": "e31a7a54-5cab-4332-9c3b-69dbcf1a3dbc"
      },
      "id": "-mzeMcq1erd-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52428800 4096500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUWTMC2YmUSN",
        "outputId": "b61dfae3-1ea3-4938-f657-f74c3c5eb514"
      },
      "id": "WUWTMC2YmUSN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the filename with timestamp\n",
        "filename = f\"gpt_weights_{timestamp}.pth\"\n",
        "\n",
        "# save gpt model weights to drive\n",
        "torch.save(gpt.state_dict(), f'/content/drive/MyDrive/{filename}')"
      ],
      "metadata": {
        "id": "u6rnII2ep85M"
      },
      "id": "u6rnII2ep85M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi optimizers"
      ],
      "metadata": {
        "id": "bbV3d4hIcbjt"
      },
      "id": "bbV3d4hIcbjt"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_lr = 0.2 # learning rate for the embedding parameters (Adam)\n",
        "unembedding_lr = 0.004 # learning rate for the unembedding parameters (Adam)\n",
        "weight_decay = 0.0 # weight decay for the embedding/unembedding parameters (Adam)\n",
        "matrix_lr = 0.02 # learning rate for the matrix parameters (Muon) - Muon needs different LR scaling than Adam\n",
        "\n",
        "grad_clip = 1.0 # gradient clipping value (0.0 = disabled): prevents gradient explosions\n",
        "warmup_ratio = 0.0 # ratio of iterations for LR warmup: start slow then ramp up\n",
        "warmdown_ratio = 0.2 # ratio of iterations for LR warmdown: cosine decay at the end\n",
        "final_lr_frac = 0.0 # final LR is this fraction of the initial LR\n",
        "resume_from_step = -1 # resume training from this step of the optimization (-1 = disable)\n",
        "num_iterations = 10 # explicit number of steps of the optimization (-1 = disable)\n",
        "\n",
        "# Learning rate scheduler (Warmup -> Constant -> Warmdown/Cos Decay)\n",
        "def get_lr_multiplier(it):\n",
        "    warmup_iters = round(warmup_ratio * num_iterations)\n",
        "    warmdown_iters = round(warmdown_ratio * num_iterations)\n",
        "    if it < warmup_iters:\n",
        "        return (it + 1) / warmup_iters\n",
        "    elif it <= num_iterations - warmdown_iters:\n",
        "        return 1.0\n",
        "    else:\n",
        "        progress = (num_iterations - it) / warmdown_iters\n",
        "        return progress * 1.0 + (1 - progress) * final_lr_frac\n",
        "\n",
        "\n",
        "def get_muon_momentum(it):\n",
        "    frac = min(it / 300, 1)\n",
        "    momentum = (1 - frac) * 0.85 + frac * 0.95\n",
        "    return momentum"
      ],
      "metadata": {
        "id": "ejIzoLez2rrT"
      },
      "id": "ejIzoLez2rrT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10): # Use 'i' as the loop counter\n",
        "  model.zero_grad(set_to_none=True) # Zero gradients at the beginning of the current iteration\n",
        "\n",
        "  loss = model(x, y) # Forward pass\n",
        "  print(f\"step {i}, loss: {loss.item()} before learning\")\n",
        "  loss.backward() # Backward pass\n",
        "\n",
        "  # Calculate learning rate and momentum based on current iteration 'i'\n",
        "  lrm = get_lr_multiplier(i)\n",
        "\n",
        "  for opt in optimizers:\n",
        "      for group in opt.param_groups:\n",
        "          group[\"lr\"] = group[\"initial_lr\"] * lrm\n",
        "\n",
        "  print(\"here 1\")\n",
        "  muon_momentum = get_muon_momentum(i)\n",
        "  for group in muon_optimizer.param_groups:\n",
        "      group[\"momentum\"] = muon_momentum\n",
        "\n",
        "  print(\"here 2\")\n",
        "  for opt in optimizers:\n",
        "      opt.step() # Update weights\n",
        "\n",
        "  print(f\"step {i}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ptOvqBMB2roe",
        "outputId": "efaf75ad-3e71-4edd-cb9f-6dc4b5d4dc77"
      },
      "id": "ptOvqBMB2roe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0, loss: 14.51890754699707 before learning\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2948167658.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"step {i}, loss: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3112447904.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nesterov\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeropower_via_newtonschulz5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ns_steps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36mcompile_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mUnsupported\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3112447904.py\u001b[0m in \u001b[0;36mzeropower_via_newtonschulz5\u001b[0;34m(G, steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzeropower_via_newtonschulz5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_callback_from_stance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mfull_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_buffers_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mfull_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;31m# Just for convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mruntime_wrapper\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0mrecord_runtime_wrapper_prologue_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 all_outs = call_func_at_runtime_with_args(\n\u001b[0m\u001b[1;32m    354\u001b[0m                     \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_amp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteal_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py\u001b[0m in \u001b[0;36mcall_func_at_runtime_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_boxed_call\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# TODO: Please remove soon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36minner_fn\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mold_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;31m# Inductor cache DummyModule can return None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(runtime_args)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 )\n\u001b[1;32m    525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    611\u001b[0m                 \u001b[0;34mf\"## Call CompiledFxGraph {self._fx_graph_cache_key} ##\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             ):\n\u001b[0;32m--> 613\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0mget_runtime_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torchinductor_root/c2/cc26krhxclqmcrpsx2az72ervawabtpm4a6w2niplhojvcfqde3q.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mbuf13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf8\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mbuf8\u001b[0m  \u001b[0;31m# reuse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Topologically Sorted Source Nodes: [mul_5], Original ATen: [aten.mul, aten.addmm]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mextern_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mbuf14\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf7\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mbuf7\u001b[0m  \u001b[0;31m# reuse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# Topologically Sorted Source Nodes: [getattr_3, A_2], Original ATen: [aten.transpose, aten.mm]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear cuda cache\n",
        "torch.cuda.empty_cache()\n",
        "# works on gpu\n",
        "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
      ],
      "metadata": {
        "id": "xzNNfXNw4O8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6eb3cd-d892-4534-8f11-481eafa96c54"
      },
      "id": "xzNNfXNw4O8v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated: 10.95 GB\n",
            "Cached: 11.69 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88I2CUcQbYrE"
      },
      "id": "88I2CUcQbYrE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsW7sAyEbig9"
      },
      "id": "dsW7sAyEbig9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}