{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f19db082",
      "metadata": {
        "id": "f19db082"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2e58ad32",
      "metadata": {
        "id": "2e58ad32"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Architecture Overview:\n",
        "1. Embedding: Token IDs -> Vectors (wte)\n",
        "2. Stack of Blocks (Repeated L times):\n",
        "   - RMSNorm\n",
        "   - Attention (Mixing info between tokens)\n",
        "   - RMSNorm\n",
        "   - MLP (Processing info within a token)\n",
        "3. Final Norm\n",
        "4. LMHead: Vectors -> Logits (Probabilities)\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    \"\"\"\n",
        "    Hyperparameters for the model.\n",
        "    \"\"\"\n",
        "    # ┌─────────────────────────────────────────────────────────┐\n",
        "    # │           321M CONVERSATIONAL MODEL                     │\n",
        "    # ├─────────────────────────────────────────────────────────┤\n",
        "    # │  hidden_dim:        1024                                │\n",
        "    # │  layers:            24                                  │\n",
        "    # │  heads:             8                                   │\n",
        "    # │  head_dim:          128                                 │\n",
        "    # │  mlp_ratio:         3x                                  │\n",
        "    # │  vocab_size:        32K                                 │\n",
        "    # │  context_length:    1024                                │\n",
        "    # │  embedding:         tied (input = output projection)    │\n",
        "    # │  activation:        relu squared                        │\n",
        "    # │  position encoding: RoPE                                │\n",
        "    # ├─────────────────────────────────────────────────────────┤\n",
        "    # │  TOTAL PARAMETERS:  243,269,632                         │\n",
        "    # └─────────────────────────────────────────────────────────┘\n",
        "    # No KV cache\n",
        "    # No GQA\n",
        "\n",
        "    hidden_dim: int = 512 # hidden dimension\n",
        "    n_layers: int = 5 # May need to reduce to 22 or 20\n",
        "    n_heads: int = 4 # head dimension = hidden_dim / n_heads = 128\n",
        "    mlp_ratio: int = 3\n",
        "    vocab_size: int = 32*1024\n",
        "    # vocab_size: int = 50257\n",
        "    sequence_len: int = 256\n",
        "\n",
        "\n",
        "def norm(x):\n",
        "    \"\"\"\n",
        "    RMSNorm (Root Mean Square Layer Normalization).\n",
        "    Used to stabilize training by normalizing activation magnitudes.\n",
        "    \"\"\"\n",
        "    # Purely functional rmsnorm with no learnable params\n",
        "    return F.rms_norm(x, (x.size(-1),))\n",
        "\n",
        "\n",
        "def apply_rotatory_positional_encoding(x, cos, sin):\n",
        "    \"\"\"\n",
        "    Applies Rotary Positional Embeddings (RoPE).\n",
        "    Rotates the query and key vectors to encode relative positions.\n",
        "    \"\"\"\n",
        "    assert x.ndim == 4  # multihead attention\n",
        "    d = x.shape[3] // 2\n",
        "    x1, x2 = x[..., :d], x[..., d:] # split up last time into two halves\n",
        "    y1 = x1 * cos + x2 * sin # rotate pairs of dims\n",
        "    y2 = x1 * (-sin) + x2 * cos\n",
        "    out = torch.cat([y1, y2], 3) # re-assemble\n",
        "    out = out.to(x.dtype) # ensure input/output dtypes match\n",
        "    return out\n",
        "\n",
        "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c550322",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c550322",
        "outputId": "f8cdbee4-58e1-44fb-8f73-39a90f2d6aea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTConfig(hidden_dim=512, n_layers=5, n_heads=4, mlp_ratio=3, vocab_size=32768, sequence_len=256)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = GPTConfig()\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2883e9f8",
      "metadata": {
        "id": "2883e9f8"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Causal Self Attention.\n",
        "\n",
        "    1. Projects input to Q, K, V.\n",
        "    2. Applies RoPE to Q, K for position info.\n",
        "    3. Computes attention scores (Q @ K) to see how much each token cares about others. Aggregates values (V) based on scores.\n",
        "    4. Projects output to mix information across heads.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.n_heads = config.n_heads\n",
        "        self.hidden_dim = config.hidden_dim\n",
        "        self.head_dim = config.hidden_dim // config.n_heads\n",
        "\n",
        "        # Linear projections for Query, Key, Value\n",
        "        self.key = nn.Linear(self.hidden_dim, self.head_dim * self.n_heads, bias=False)\n",
        "        self.query = nn.Linear(self.hidden_dim, self.head_dim * self.n_heads, bias=False)\n",
        "        self.value = nn.Linear(self.hidden_dim, self.head_dim * self.n_heads, bias=False)\n",
        "\n",
        "        # Output projection (\"o\"): mixes results from all heads back into n_embd\n",
        "        self.proj = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cos_sin: torch.Tensor) -> torch.Tensor:\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        # 1. Projects input to Q, K, V.\n",
        "        # reshape to (B, T, n_heads, head_dim)\n",
        "        k = self.key(x).view(B, T, self.n_heads, self.head_dim)\n",
        "        q = self.query(x).view(B, T, self.n_heads, self.head_dim)\n",
        "        v = self.value(x).view(B, T, self.n_heads, self.head_dim)\n",
        "\n",
        "        # 2. Applies RoPE to Q, K for position info.\n",
        "        cos, sin = cos_sin\n",
        "        k, q = apply_rotatory_positional_encoding(k, cos, sin), apply_rotatory_positional_encoding(q, cos, sin)\n",
        "\n",
        "        # 3. Computes attention scores (Q @ K) to see how much each token cares about others.\n",
        "        q, k = norm(q), norm(k) # QK norm\n",
        "\n",
        "        # make head be batch dim, i.e. (B, T, n_heads, head_dim) -> (B, n_heads, T, head_dim)\n",
        "        # We are making the n_heads into a batch dimension so pytorch treats it as batches and\n",
        "        # applies the attention function on each head separately in parallel\n",
        "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "\n",
        "        # Re-assemble the heads side by side and project back to residual stream\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "\n",
        "        # 4. Projects output to mix information across heads.\n",
        "        y = self.proj(y)\n",
        "        return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "21bcf98f",
      "metadata": {
        "id": "21bcf98f"
      },
      "outputs": [],
      "source": [
        "# attn = MultiHeadAttention(config)\n",
        "# attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ed627ed",
      "metadata": {
        "id": "4ed627ed"
      },
      "outputs": [],
      "source": [
        "# for param in attn.parameters():\n",
        "#     print(type(param), param.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cbe7e4bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbe7e4bb",
        "outputId": "a6b7aa68-540a-4d5f-d6af-10233c520bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1b48b87d",
      "metadata": {
        "id": "1b48b87d"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# summary(attn, input_size=(1, config.sequence_len, config.hidden_dim), dtypes=[torch.float32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bc2fc9c8",
      "metadata": {
        "id": "bc2fc9c8"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Feed Forward Network (MLP).\n",
        "    Processes each token independently (no mixing between tokens).\n",
        "    Structure: Expand -> ReLU^2 -> Contract\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.proj_up = nn.Linear(config.hidden_dim, config.hidden_dim * config.mlp_ratio, bias=False)\n",
        "        self.proj_down = nn.Linear(config.hidden_dim * config.mlp_ratio, config.hidden_dim, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.proj_up(x)\n",
        "        x = F.relu(x).square()\n",
        "        # TODO: Check if swiglu is better for 3 x hidden_dim -\n",
        "        # gelu and silu are alternatives but difference seems marginal so sticking with relu^2\n",
        "        x = self.proj_down(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6bebf83f",
      "metadata": {
        "id": "6bebf83f"
      },
      "outputs": [],
      "source": [
        "# ff = FeedForward(config)\n",
        "# ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6291466b",
      "metadata": {
        "id": "6291466b"
      },
      "outputs": [],
      "source": [
        "# summary(ff, input_size=(1, config.sequence_len, config.hidden_dim), dtypes=[torch.float32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f4eed103",
      "metadata": {
        "id": "f4eed103"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single Transformer Block.\n",
        "    Contains:\n",
        "    1. Attention (Communication)\n",
        "    2. MLP (Computation)\n",
        "    Both use Residual Connections (x + ...) and Pre-Norm.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "        self.ff = FeedForward(config)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cos_sin: torch.Tensor) -> torch.Tensor:\n",
        "        # Attention with residual connection\n",
        "        x = x + self.attn(norm(x), cos_sin)\n",
        "        # MLP with residual connection\n",
        "        x = x + self.ff(norm(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7c4ae3c3",
      "metadata": {
        "id": "7c4ae3c3"
      },
      "outputs": [],
      "source": [
        "# block = TransformerBlock(GPTConfig())\n",
        "# block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fe299056",
      "metadata": {
        "id": "fe299056"
      },
      "outputs": [],
      "source": [
        "# summary(block, input_size=(1, config.sequence_len, config.hidden_dim), dtypes=[torch.float32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694a4e76",
      "metadata": {
        "id": "694a4e76"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "    \"\"\"\n",
        "    The full GPT model.\n",
        "    Contains:\n",
        "    1. Token Embedding\n",
        "    2. Transformer Blocks (stacked)\n",
        "    3. Final Normalization\n",
        "    4. LM Head - Tied weights with token embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, config: GPTConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding = nn.Embedding(config.vocab_size, config.hidden_dim)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
        "        self.lm_head = nn.Linear(config.hidden_dim, config.vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.token_embedding.weight\n",
        "\n",
        "        self.rotary_seq_len = config.sequence_len * 10 # 10X over-compute\n",
        "        # Why 10x? This provides a generous buffer for inference/generation, allowing the model\n",
        "        # to generate sequences longer than its training length without recomputing embeddings.\n",
        "        # Note: While the embeddings support 10x length, the model's quality degrades beyond ~1.5-2x\n",
        "        # the training length due to unseen attention patterns. This buffer is for convenience,\n",
        "        # not an expectation of good performance at 10x length. Memory cost is negligible.\n",
        "\n",
        "        head_dim = config.hidden_dim // config.n_heads\n",
        "        cos, sin = self._precompute_rotary_embeddings(self.rotary_seq_len, head_dim)\n",
        "        self.register_buffer(\"cos\", cos, persistent=False) # persistent=False means it's not saved to the checkpoint\n",
        "        self.register_buffer(\"sin\", sin, persistent=False)\n",
        "\n",
        "    def forward(self, idx, targets=None, loss_reduction=\"mean\") -> torch.Tensor:\n",
        "        T = idx.shape[1]\n",
        "        cos_sin = self.cos[:, :T], self.sin[:, :T] # truncate cache to current sequence length\n",
        "        x = self.token_embedding(idx)\n",
        "        x = norm(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x, cos_sin)\n",
        "        x = norm(x)\n",
        "\n",
        "        softcap = 15 # smoothly cap the logits to the range [-softcap, softcap]\n",
        "        logits = self.lm_head(x)\n",
        "        logits = logits.float() # switch to fp32 for logit softcap and loss computation\n",
        "        logits = softcap * torch.tanh(logits / softcap) # squash the logits\n",
        "\n",
        "        if targets is not None:\n",
        "            # training: given the targets, compute and return the loss\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1, reduction=loss_reduction)\n",
        "            return loss\n",
        "        else:\n",
        "            # inference: just return the logits directly\n",
        "            return logits\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        Initialize the full model in this one function for maximum clarity.\n",
        "\n",
        "        embedding:     normal, std=1.0\n",
        "        for each block:\n",
        "            attn.c_q:        uniform, std=1/sqrt(n_embd)\n",
        "            attn.c_k:        uniform, std=1/sqrt(n_embd)\n",
        "            attn.c_v:        uniform, std=1/sqrt(n_embd)\n",
        "            attn.c_proj:     zeros\n",
        "            mlp.c_fc:        uniform, std=1/sqrt(n_embd)\n",
        "            mlp.c_proj:      zeros\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Explanation:\n",
        "        The initialization logic deviates from PyTorch defaults (Kaiming defaults) to improve training \n",
        "        stability and convergence for deep Transformers.\n",
        "        \n",
        "        Key Differences:\n",
        "        1. Zero Initialization for Output Projections (c_proj):\n",
        "           - Function: Sets the weights of the final linear layer in each block to zero.\n",
        "           - Why: This ensures that at initialization, the residual blocks contribute nothing to the \n",
        "             residual stream (y = x + 0). The model effectively starts as an identity function, allowing \n",
        "             unimpeded gradient flow from top to bottom. This prevents vanishing/exploding gradients \n",
        "             and provides a stable starting point for the model to gradually learn features.\n",
        "\n",
        "        2. Zero Initialization for LM Head:\n",
        "           - Function: Sets the classifier weights to zero.\n",
        "           - Why: Ensures all logits are initially zero, leading to a uniform probability distribution (1/V) \n",
        "             for the next token. This minimizes the initial loss to exactly log(V) and prevents the model \n",
        "             from starting with random biases towards arbitrary tokens.\n",
        "\n",
        "        Custom initialization for Linear and Embedding layers.\n",
        "        \n",
        "        1. Controlled Variance (Linear Layers):\n",
        "           - Formula: std = 1 / sqrt(fan_in) * min(1, sqrt(fan_out / fan_in))\n",
        "           - Why: Standard Kaiming init often leads to activation variance that grows with depth in \n",
        "             Transformers. This custom initialization (ref: https://arxiv.org/pdf/2310.17813) stabilizes \n",
        "             activation variance across layers, specifically accounting for the network width.\n",
        "\n",
        "        2. Unit Variance (Embeddings):\n",
        "           - Function: Normal distribution with std=1.0.\n",
        "           - Why: Ensures strong initial signal strength before it enters the first normalization layer.\n",
        "        \"\"\"\n",
        "        # Embedding\n",
        "        torch.nn.init.normal_(self.token_embedding.weight, mean=0.0, std=1.0)\n",
        "\n",
        "        # Transformer blocks: uniform init with bound = sqrt(3) * std (same standard deviation as normal)\n",
        "        n_embd = self.config.hidden_dim\n",
        "        s = 3**0.5 * n_embd**-0.5 # sqrt(3) multiplier makes sure Uniform achieves the same std as Normal\n",
        "\n",
        "        # Zero out the output projections of the blocks\n",
        "        for block in self.blocks:\n",
        "            torch.nn.init.zeros_(block.ff.proj_down.weight)\n",
        "            torch.nn.init.zeros_(block.attn.proj.weight)\n",
        "            torch.nn.init.uniform_(block.attn.query.weight, -s, s) # weights use Uniform to avoid outliers\n",
        "            torch.nn.init.uniform_(block.attn.key.weight, -s, s)\n",
        "            torch.nn.init.uniform_(block.attn.value.weight, -s, s)\n",
        "            torch.nn.init.uniform_(block.mlp.c_fc.weight, -s, s)\n",
        "\n",
        "        # init the rotary embeddings\n",
        "        head_dim = self.config.hidden_dim // self.config.n_heads\n",
        "        cos, sin = self._precompute_rotary_embeddings(self.rotary_seq_len, head_dim)\n",
        "        self.cos, self.sin = cos, sin\n",
        "\n",
        "        # Cast the embeddings from fp32 to bf16: optim can tolerate it and it saves memory: both in the model and the activations\n",
        "        if self.token_embedding.weight.device.type == \"cuda\":\n",
        "            self.token_embedding.to(dtype=torch.bfloat16)\n",
        "\n",
        "    def _precompute_rotary_embeddings(self, seq_len, head_dim, base=10000, device=None):\n",
        "        # autodetect the device from model embeddings\n",
        "        if device is None:\n",
        "            device = self.token_embedding.weight.device\n",
        "        # stride the channels\n",
        "        channel_range = torch.arange(0, head_dim, 2, dtype=torch.float32, device=device)\n",
        "        inv_freq = 1.0 / (base ** (channel_range / head_dim))\n",
        "        # stride the time steps\n",
        "        t = torch.arange(seq_len, dtype=torch.float32, device=device)\n",
        "        # calculate the rotation frequencies at each (time, channel) pair\n",
        "        freqs = torch.outer(t, inv_freq)\n",
        "        cos, sin = freqs.cos(), freqs.sin()\n",
        "        cos, sin = cos.bfloat16(), sin.bfloat16() # keep them in bfloat16\n",
        "        cos, sin = cos[None, :, None, :], sin[None, :, None, :] # add batch and head dims for later broadcasting\n",
        "        return cos, sin\n",
        "\n",
        "    def setup_optimizers(self, embedding_lr=0.2, matrix_lr=0.02, weight_decay=0.0):\n",
        "        \"\"\"\n",
        "        Sets up the optimizers.\n",
        "        Uses AdamW for embeddings/head and Muon for internal linear layers.\n",
        "\n",
        "        Detailed Explanation of Hybrid Strategy:\n",
        "        ----------------------------------------\n",
        "        We use two different optimizers because different parts of the Transformer have different\n",
        "        geometric properties and optimization landscapes.\n",
        "\n",
        "        1. Muon (for internal 2D matrices):\n",
        "           - Applied to: Attention projections (c_q, c_k, c_v, c_proj) and MLP weights (c_fc, c_proj).\n",
        "           - Mechanism: Muon forces weight *updates* to be orthogonal. In linear algebra, orthogonal\n",
        "             transformations (like rotation or reflection) preserve the magnitude (norm) of the vector\n",
        "             they act on.\n",
        "           - Benefit: Deep networks suffer from vanishing/exploding gradients because signals get\n",
        "             scaled up or down at every layer. By forcing updates to be orthogonal, Muon ensures\n",
        "             signals propagate through the network without exploding in magnitude, allowing for\n",
        "             much faster and more stable training of deep layers.\n",
        "\n",
        "        2. AdamW (for embeddings & head):\n",
        "           - Applied to: Token embeddings (wte) and the final output head (lm_head).\n",
        "           - Reason: These parameters are not dense 2D matrices in the same sense (embeddings are\n",
        "             lookup tables). The concept of \"orthogonal updates\" is mathematically ill-defined or\n",
        "             harmful for vectors/lookups. AdamW is ideal here as it adapts learning rates per-parameter\n",
        "             based on update frequency (handling the sparse nature of token updates).\n",
        "\n",
        "        Do they conflict?\n",
        "        No. Both optimizers step in directions derived from the same global loss gradient, so they\n",
        "        optimize the same function. The risk is learning speed mismatch (one part learning faster\n",
        "        than the other), which we handle by manually scaling the AdamW learning rate below.\n",
        "        \"\"\"\n",
        "        model_dim = self.config.hidden_dim\n",
        "        # ddp, rank, local_rank, world_size = get_dist_info()\n",
        "        # Separate out all parameters into 3 groups (matrix, embedding, lm_head)\n",
        "        matrix_params = list(self.blocks.parameters())\n",
        "        embedding_params = list(self.token_embedding.parameters())\n",
        "        assert len(list(self.parameters())) == len(matrix_params) + len(embedding_params)\n",
        "\n",
        "        # Create the AdamW optimizer for the embedding\n",
        "        # Scale the LR for the AdamW parameters by ∝1/√dmodel (having tuned the LRs for 768 dim model)\n",
        "        dmodel_lr_scale = (model_dim / 768) ** -0.5\n",
        "        # if rank == 0:\n",
        "        print(f\"Scaling the LR for the AdamW parameters ∝1/√({model_dim}/768) = {dmodel_lr_scale:.6f}\")\n",
        "        adam_groups = [\n",
        "            dict(params=embedding_params, lr=embedding_lr * dmodel_lr_scale),\n",
        "        ]\n",
        "        adamw_kwargs = dict(betas=(0.8, 0.95), eps=1e-10, weight_decay=weight_decay)\n",
        "        AdamWFactory = partial(torch.optim.AdamW, fused=True)\n",
        "        adamw_optimizer = AdamWFactory(adam_groups, **adamw_kwargs)\n",
        "\n",
        "        # Create the Muon optimizer for the linear layers\n",
        "        muon_kwargs = dict(lr=matrix_lr, momentum=0.95)\n",
        "        muon_optimizer = Muon(matrix_params, **muon_kwargs)\n",
        "\n",
        "        # Combine the two optimizers into one list\n",
        "        optimizers = [adamw_optimizer, muon_optimizer]\n",
        "        for opt in optimizers:\n",
        "            for group in opt.param_groups:\n",
        "                group[\"initial_lr\"] = group[\"lr\"]\n",
        "        return optimizers\n",
        "\n",
        "    def estimate_flops(self):\n",
        "        \"\"\" Return the estimated FLOPs per token for the model. Ref: https://arxiv.org/abs/2204.02311 \"\"\"\n",
        "        nparams = sum(p.numel() for p in self.parameters())\n",
        "        nparams_embedding = self.token_embedding.weight.numel()\n",
        "        l, h, q, t = self.config.n_layer, self.config.n_head, self.config.hidden_dim // self.config.n_head, self.config.sequence_len\n",
        "        num_flops_per_token = 6 * (nparams - nparams_embedding) + 12 * l * h * q * t\n",
        "        return num_flops_per_token\n",
        "    \n",
        "    def get_device(self):\n",
        "        return self.token_embedding.weight.device\n",
        "    \n",
        "    @torch.inference_mode()\n",
        "    def generate(self, tokens, max_tokens, temperature=1.0, top_k=None, seed=42):\n",
        "        \"\"\"\n",
        "        Naive autoregressive streaming inference.\n",
        "        To make it super simple, let's assume:\n",
        "        - batch size is 1\n",
        "        - ids and the yielded tokens are simple Python lists and ints\n",
        "        \"\"\"\n",
        "        assert isinstance(tokens, list)\n",
        "        device = self.get_device()\n",
        "        rng = None\n",
        "        if temperature > 0:\n",
        "            rng = torch.Generator(device=device)\n",
        "            rng.manual_seed(seed)\n",
        "        ids = torch.tensor([tokens], dtype=torch.long, device=device) # add batch dim\n",
        "        for _ in range(max_tokens):\n",
        "            logits = self.forward(ids) # (B, T, vocab_size)\n",
        "            logits = logits[:, -1, :] # (B, vocab_size)\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            if temperature > 0:\n",
        "                logits = logits / temperature\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                next_ids = torch.multinomial(probs, num_samples=1, generator=rng)\n",
        "            else:\n",
        "                next_ids = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            ids = torch.cat((ids, next_ids), dim=1)\n",
        "            token = next_ids.item()\n",
        "            yield token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6254fe9b",
      "metadata": {
        "id": "6254fe9b"
      },
      "outputs": [],
      "source": [
        "gpt = GPT(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "afb5f41f",
      "metadata": {
        "id": "afb5f41f"
      },
      "outputs": [],
      "source": [
        "gpt = gpt.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c6f25595",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6f25595",
        "outputId": "467e506e-c61f-4fad-a592-af0c08bb8ea4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "GPT                                      [1, 256, 32768]           --\n",
              "├─Embedding: 1-1                         [1, 256, 512]             16,777,216\n",
              "├─ModuleList: 1-2                        --                        --\n",
              "│    └─TransformerBlock: 2-1             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-1      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-2             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-2             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-3      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-4             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-3             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-5      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-6             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-4             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-7      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-8             [1, 256, 512]             1,572,864\n",
              "│    └─TransformerBlock: 2-5             [1, 256, 512]             --\n",
              "│    │    └─MultiHeadAttention: 3-9      [1, 256, 512]             1,048,576\n",
              "│    │    └─FeedForward: 3-10            [1, 256, 512]             1,572,864\n",
              "├─Linear: 1-3                            [1, 256, 32768]           16,777,216\n",
              "==========================================================================================\n",
              "Total params: 46,661,632\n",
              "Trainable params: 46,661,632\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 46.66\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 110.10\n",
              "Params size (MB): 186.65\n",
              "Estimated Total Size (MB): 296.75\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(gpt, input_size=(1, config.sequence_len), dtypes=[torch.long])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "47fa1992",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47fa1992",
        "outputId": "961fb310-70b1-4bd9-f8e3-43ce9905e386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual unique parameters: 29,884,416\n"
          ]
        }
      ],
      "source": [
        "# The weight tying is working correctly — torchinfo just doesn't detect shared parameters by default.\n",
        "# It counts each layer's parameters independently.\n",
        "\n",
        "# This counts UNIQUE parameters (correct count with tying)\n",
        "real_params = sum(p.numel() for p in gpt.parameters())\n",
        "print(f\"Actual unique parameters: {real_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "934e412b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "934e412b",
        "outputId": "0c972062-c2f6-4f1c-b830-cecda41cefac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Same object: True\n",
            "Same memory: True\n"
          ]
        }
      ],
      "source": [
        "# These should all be True\n",
        "print(\"Same object:\", gpt.lm_head.weight is gpt.token_embedding.weight)\n",
        "print(\"Same memory:\", gpt.lm_head.weight.data_ptr() == gpt.token_embedding.weight.data_ptr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "01093d00",
      "metadata": {
        "id": "01093d00"
      },
      "outputs": [],
      "source": [
        "gpt.init_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4e0192d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e0192d8",
        "outputId": "1183240b-ab01-42a5-8681-a00709a94295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Name                               | Type            | Dtype\n",
            "----------------------------------------------------------------------\n",
            "token_embedding.weight                   | Parameter       | torch.bfloat16\n",
            "blocks.0.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.0.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.0.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.0.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.0.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.0.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.1.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.1.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.1.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.1.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.1.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.1.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.2.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.2.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.2.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.2.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.2.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.2.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.3.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.3.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.3.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.3.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.3.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.3.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "blocks.4.attn.key.weight                 | Parameter       | torch.float32\n",
            "blocks.4.attn.query.weight               | Parameter       | torch.float32\n",
            "blocks.4.attn.value.weight               | Parameter       | torch.float32\n",
            "blocks.4.attn.proj.weight                | Parameter       | torch.float32\n",
            "blocks.4.ff.proj_up.weight               | Parameter       | torch.float32\n",
            "blocks.4.ff.proj_down.weight             | Parameter       | torch.float32\n",
            "cos                                      | Buffer          | torch.bfloat16\n",
            "sin                                      | Buffer          | torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "def check_model_dtypes(model):\n",
        "    print(f\"{'Layer Name':<40} | {'Type':<15} | {'Dtype'}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Check Parameters\n",
        "    for name, param in model.named_parameters():\n",
        "        print(f\"{name:<40} | Parameter       | {param.dtype}\")\n",
        "\n",
        "    # Check Buffers (like RoPE cos/sin)\n",
        "    for name, buf in model.named_buffers():\n",
        "        print(f\"{name:<40} | Buffer          | {buf.dtype}\")\n",
        "check_model_dtypes(gpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "993fe345",
      "metadata": {
        "id": "993fe345"
      },
      "outputs": [],
      "source": [
        "# # sample input for gpt model\n",
        "# sample_input = torch.ones((1, 1), dtype=torch.int64)\n",
        "# sample_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "dd36d2bb",
      "metadata": {
        "id": "dd36d2bb"
      },
      "outputs": [],
      "source": [
        "# gpt.eval()\n",
        "# with torch.no_grad(): # Good practice for inference to save memory\n",
        "#     op = gpt(sample_input)\n",
        "\n",
        "# print(f\"Output shape: {op.shape}\") # Should be (1, 1, vocab_size)\n",
        "# print(f\"Max logit: {op.max().item():.4f}\")\n",
        "# print(f\"Predicted token ID: {op.argmax().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e766a77b",
      "metadata": {
        "id": "e766a77b"
      },
      "source": [
        "Predicted token is always same as the input value. Why?\n",
        "1. Weight Tying: We have set self.lm_head.weight = self.token_embedding.weight.\n",
        "2. Zero-Init Blocks: init_weights function sets the output projection of every Transformer block to zero.\n",
        " - This means the blocks (Attention and MLP) contribute nothing to the residual stream at initialization.\n",
        " - The model effectively acts as an identity function for the embeddings: Embedding(token) -> Norm -> Logits.\n",
        "3. Self-Similarity: Since the output head uses the same weights as the embedding, it calculates the dot product of the token's embedding vector with all other embedding vectors.\n",
        " - A vector's dot product with itself ($v \\cdot v$) is almost always much higher than with other random vectors ($v \\cdot w$).\n",
        " - Therefore, the model assigns the highest probability to the token that was input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6b1f4c95",
      "metadata": {
        "id": "6b1f4c95"
      },
      "outputs": [],
      "source": [
        "# # loss\n",
        "# sample_input2 = torch.ones((1, 1), dtype=torch.int64)*100\n",
        "# sample_input2 = sample_input2.to(device_type)\n",
        "# print(f'loss when taget = input: {gpt(sample_input2, sample_input2)}')\n",
        "# print(f'loss when target != input: {gpt(sample_input2, sample_input2*2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "93cf34a5",
      "metadata": {
        "id": "93cf34a5"
      },
      "outputs": [],
      "source": [
        "# orig_model = gpt # original, uncompiled model, for saving raw model state_dict and for inference/evaluation (because the shapes may change shape)\n",
        "# torch.compile: optimizing the model execution graph (JIT compilation)\n",
        "gpt = torch.compile(gpt, dynamic=False) # the inputs to model will never change shape so dynamic=False is safe\n",
        "# num_params = sum(p.numel() for p in model.parameters())\n",
        "# print(f\"Number of parameters: {num_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dc1aa760",
      "metadata": {
        "id": "dc1aa760"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "\n",
        "@torch.compile\n",
        "def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:\n",
        "    \"\"\"\n",
        "    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\n",
        "    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\n",
        "    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at\n",
        "    zero even beyond the point where the iteration no longer converges all the way to one everywhere\n",
        "    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T\n",
        "    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model\n",
        "    performance at all relative to UV^T, where USV^T = G is the SVD.\n",
        "    \"\"\"\n",
        "    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng\n",
        "    a, b, c = (3.4445, -4.7750,  2.0315)\n",
        "    X = G.bfloat16()\n",
        "    if G.size(-2) > G.size(-1):\n",
        "        X = X.mT\n",
        "\n",
        "    # Ensure spectral norm is at most 1\n",
        "    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)\n",
        "    # Perform the NS iterations\n",
        "    for _ in range(steps):\n",
        "        A = X @ X.mT\n",
        "        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng\n",
        "        X = a * X + B @ X\n",
        "\n",
        "    if G.size(-2) > G.size(-1):\n",
        "        X = X.mT\n",
        "    return X\n",
        "\n",
        "\n",
        "class Muon(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Muon - MomentUm Orthogonalized by Newton-schulz\n",
        "\n",
        "    https://kellerjordan.github.io/posts/muon/\n",
        "\n",
        "    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-\n",
        "    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal\n",
        "    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has\n",
        "    the advantage that it can be stably run in bfloat16 on the GPU.\n",
        "\n",
        "    Some warnings:\n",
        "    - This optimizer should not be used for the embedding layer, the final fully connected layer,\n",
        "    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).\n",
        "    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.\n",
        "\n",
        "    Arguments:\n",
        "        lr: The learning rate used by the internal SGD.\n",
        "        momentum: The momentum used by the internal SGD.\n",
        "        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)\n",
        "        ns_steps: The number of Newton-Schulz iteration steps to use.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):\n",
        "        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)\n",
        "        params: list[Tensor] = [*params]\n",
        "        param_groups = []\n",
        "        for size in {p.numel() for p in params}:\n",
        "            group = dict(params=[p for p in params if p.numel() == size])\n",
        "            param_groups.append(group)\n",
        "        super().__init__(param_groups, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            params: list[Tensor] = group[\"params\"]\n",
        "            for p in params:\n",
        "                g = p.grad\n",
        "                assert g is not None\n",
        "                state = self.state[p]\n",
        "                if \"momentum_buffer\" not in state:\n",
        "                    state[\"momentum_buffer\"] = torch.zeros_like(g)\n",
        "                buf: Tensor = state[\"momentum_buffer\"]\n",
        "                buf.lerp_(g, 1 - group[\"momentum\"])\n",
        "                g = g.lerp_(buf, group[\"momentum\"]) if group[\"nesterov\"] else buf\n",
        "                g = zeropower_via_newtonschulz5(g, steps=group[\"ns_steps\"])\n",
        "                p.add_(g, alpha=-group[\"lr\"] * max(1, p.size(-2) / p.size(-1))**0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3600722b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3600722b",
        "outputId": "98c2b9e7-44f1-496c-921c-fe05bbd1a685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaling the LR for the AdamW parameters ∝1/√(512/768) = 1.224745\n"
          ]
        }
      ],
      "source": [
        "embedding_lr = 0.2\n",
        "weight_decay = 0.0\n",
        "matrix_lr = 0.02\n",
        "from functools import partial\n",
        "\n",
        "optimizers = gpt.setup_optimizers(embedding_lr=embedding_lr, matrix_lr=matrix_lr, weight_decay=weight_decay)\n",
        "adamw_optimizer, muon_optimizer = optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fb255ac3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb255ac3",
        "outputId": "67e33959-433e-4eb2-f300-9e1f6e865d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allocated: 0.09 GB\n",
            "Cached: 0.24 GB\n"
          ]
        }
      ],
      "source": [
        "# works on gpu\n",
        "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "7e67bd8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e67bd8d",
        "outputId": "24ee4e0e-9d50-46e9-921e-b2d6b87109ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved the first 51200.0 KB of '/content/reddit_shard_00000.txt' to 'reddit_small.txt'.\n"
          ]
        }
      ],
      "source": [
        "input_file_path = '/content/reddit_shard_00000.txt'\n",
        "output_file_path = 'reddit_small.txt'\n",
        "bytes_to_read = 1024*1024*50 # 50 MB\n",
        "\n",
        "try:\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as infile:\n",
        "        content = infile.read(bytes_to_read)\n",
        "\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "    print(f\"Successfully saved the first {bytes_to_read / 1024} KB of '{input_file_path}' to '{output_file_path}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{input_file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "M8hFEN6i0DqU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8hFEN6i0DqU",
        "outputId": "f647438e-3713-43c3-a0e0-04a29aadfccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The one feature the iPad is really missing. I don't care about the lack of camera. I never use the one on my MacBook, and even if I did the angle would be terrible on the iPad.\n",
            "\n",
            "I don't care if third party apps can't run in the background. I don't listen to streaming music.\n",
            "\n",
            "I don't care that the App Store is a closed system. I can jailbreak for myself and I think the closed system works better for most users.\n",
            "\n",
            "The one feature I want is User Accounts and a Guest Account. If this device is meant to be a coffee table computer, it needs to be able to accomadate multiple users.\n",
            "Dear Sydney Reddit'ers, Would you like any changes made to the style of this subreddit? I was going to subtly edit the style of the Sydney subreddit but then I found this post and realised that people have very strong opinions about how their reddit should look. \n",
            "\n",
            "\n",
            "\n",
            "So before I make any changes do you have any opinions or suggestions?\n",
            "I skipped bail, ran away, and never got caught. AM(A)A. Long/short story, I went to work in the United States in the last 90s and was busted in a major drug raid. I risked up to lifetime in jail if caught since I was associated with so many crimes; at the bare minimum, said my attorney, I was looking at 7 years in jail, and much more likely more than this.\n",
            "\n",
            "My attorney said I was in a lot of trouble. He was the first to bring it up. I did not want to lose 10, 15 or 25 years of my life in jail, especially at my age. Since I was not a United States citizen, I should simply skip bail and run away. And never come back.\n",
            "\n",
            "My bail was initially supposed to be $300,000 but my attorney managed to get the judge to set a final bail of $100,000. He explained I was a trustworthy person, lawfully employed, who never did anything wrong and never committed any crime. He portrayed me as someone trustworthy and intelligent who could take care of his responsibilities. The judge agreed and decided on a very low bail, especially for the crimes I was accused of. I still did not have so much money and had to hire a bondsman, who agreed to cover my bail for $15,000. It took three days to manage to get the money to pay both him and my attorney (I had to pay my attorney, or he would have revealed my plan to authorities).\n",
            "\n",
            "I got as much cash as I could, as quickly as I could, mostly pawning most of my stuff (even some stuff I was not done paying), and getting away with a simple bag. I had no passport (confiscated), but a few friends on the not-so-right side of the law. It costed me quite a bit, but I was able to take someone's identity long enough to make it back to a country next to mine, and then take a train to my country. I destroyed evidence and promptly reported to my government, got a new passport and, very quickly, a new job. I never came back to the United States or even thought about going back there.\n",
            "\n",
            "Last time I heard about the people who were arrested along with me, they were all convicted, and in jail. I consider myself very lucky, and happy. I've been living for over 10 years now happily and freely. It's crazy to think I could have spent this last decade in jail. I consider couldn't even imagine what my life would have looked like had I been convicted. It's crazy to spend so much of your life in jail, all due to a stupid mistake. I don't make excuses for my crime, but I do smile thinking about it. I've never been extraded/harassed in any way or shape (not even from the bondsman). AMAA.\n",
            "Here's an idea: Left 4 Dead Jurassic Park After the power to the park goes out and the dinosaurs break free, 4 survivors must make it from their broken down tour jeep to the chopper.\n",
            "Thought you might be able to drop some insight on me. I am a huge music fan, i really am open to anything under the sun. But if i am being totally honest my hands down favorite bands are Phish, String Cheese Incident, and so forth and so on.\n",
            "\n",
            "I was just trying to get some insight as to why (generally speaking) people don't give bands/music of this type a fair shake.\n",
            "Programmers, do you put your comments (before|after) the related code? Inspired by: \n",
            "\n",
            "In the several years I've been writing code, I have never seen someone write comments after code until that comment. The thought of doing that had never occurred to me either. \n",
            "\n",
            "On reading the comment's code snippet, it seemed to make more sense to me having the comment after the code. Ie, \"here's the code, now we'll explain\" instead of \"here's what's going on, now here's the code\".\n",
            "\n",
            "Do you put your comments before or after your lines/blocks of code?\n",
            "[TOMT] Animated movie (warning: very vague) The main character is female and it was animated, maybe Disney. I had the play-doh set of it in the mid 90s, but I think it's older.  \n",
            "The only scene I remember is some sort of chase scene on a train. Like I said, vague.\n",
            "\n",
            "**Solved**: Anastasia!\n",
            "Since we're on the topic of Australian Politics, and electoral systems... I was curious, can you cast a \"non-ballot\" here? And if you can, does it result in a forced reform/ dissolve of current political parties?\n",
            "\n",
            "Edit: \"Casting your vote\" was wrong, (shame), apparently I was looking for \"Donkey vote\", and in finding that, my first question was ultimately answered.\n",
            "\n",
            "Edit: The term I was looking for was \"casting a non-vote\".\n",
            "Had a couple questions about diet I am trying to cut down on the chub I've gained. The chub mostly accumulated in my lower stomach. My friend recommended that I do a fruit diet and lots of cardio. Are there better ways to help the chub go away? I don't want to do anything as extreme as the master cleanse.\n",
            "How sure are we that there were never any intelligent dinosaurs? I'm posting this under a throwaway account so my friends don't learn how retarded I am by posing this question.\n",
            "\n",
            "I was thinking the other day about how humans are responsible (either directly through hunting or indirectly through climate change/deforestation) for the extinction of a whole lot of species. If we keep growing at this rate, we'll have issues of overpopulation and maybe even a mass extinction, no? And intelligent humans have only been around for far less than a million years.\n",
            "\n",
            "Secondly, 65 million years is a really, really long time. How long will it take for all remnants of human civilization to be erased from the earth? Thousands of years? Maybe a few million, at most? The World Without Us says that \"After 500 years all that would be left would be aluminum dishwasher parts, stainless steel cookware, and plastic handles.\" How long until these legacies are also destroyed?\n",
            "\n",
            "Third, we're still discovering new species of dinosaur on a pretty regular basis, aren't we? And if an \"intelligent\" dinosaur only existed for a short period of time before reaching overpopulation and going extinct, there would be pretty slim odds of fossilization, no? \n",
            "\n",
            "Finally, I'm not discussing a civilization that is exploring space and building computers. But could dinosaurs have existed that engaged in primitive agriculture or herding practices? Maybe even had a spoken language?\n",
            "I'm confused, is Obama for offshore drilling or not? It seemed during his SOTU address he was for offshore drilling but repeatedly during his campaign he bashed Bush and McCain for their pro-offshore drilling stance...I've done a little of my own research and found his clip where he was saying no to offshore drilling  and I've got this quote from his SOTU address: \n",
            "&gt;It means making tough decisions about opening new offshore areas for oil and gas development. It means continued investment in advanced biofuels and clean coal technologies.\n",
            "\n",
            "But I was hoping some people more knowledgeable than myself could help me find some answers.  Thanks!\n",
            "Why didn't TSA stop me for a lighter? I'm flying out of Atlanta. I'm sitting in the smoking bar and just realized I have a lighter in my purse. Why didn't they confiscate that?  Is it ok now?  I've thrown a lot of lighters away needlessly I guess.\n",
            "Can anyone suggest a desktop book reader for Mac that works similar to Stanza on the iPhone? Stanza on the iPhone is brilliant.  The interface is beautiful and I LOVE the in app access to so many free books in the public domain.  Unfortunately I find the desktop version extremely lacking.  Can anyone advise on a good program for Mac that is similar to Stanza on the iPhone?  Thanks.\n",
            "DAE hate when women wear shirts with witty sayings on them? I mean, *I* don't want to look at your boobs for 30 seconds and start chuckling, but it's like you've *forced me*, woman!\n",
            "Why don't more text based websites consist primarily of darker backgrounds with light fonts? It may seem like a silly question but given that most of us Westerners spend a significant amount of our days staring at glowing rectangles, it would be much more comfortable on the eyes and seem less mentally fatiguing in the long run.  My email is set this way and I wish I had done this a long time ago...\n",
            "VLC doesn't look \"Mac like\"? Check out Blackpearl. These UI mods]( are pretty classy and I'm sure not everyone has seen them. The [Transmission Blackpearl is by far my favorite.\n",
            "Can someone please explain to me the appeal of 80s splatter films (Evil Dead, Braindead/Dead Alive, Bad Taste, etc.)? I'm really trying to appreciate this genre of film but I can't understand the appeal. They're not scary, they're not funny, they just feel awkward and weird. They can be fun at times but generally I just can't get into them. What am I missing?\n",
            "Who lives in a compassionate state? I was wondering for those of you who live in medical mj states how legislation has changed, if at all, regarding employee drug testing for patients who have obtained a prescription for mj?\n",
            "Hello reddit. This is a fake account. Thank you for keeping me alive I have an account here. I enjoy the laughs, arguments, being corrected when wrong.\n",
            "\n",
            "The past years have been devastating to me. I am fairly isolated for numerous reasons. It includes mental health, though for me this has only enhanced questioning. I have to question myself too.\n",
            "\n",
            "I don't need no friends. It's a good idea for me and for others. But reddit has given me something real till a time I may join the world again. If it doesn't, this place has been something outside my bubble. I have learned and felt a real touch to my th\n"
          ]
        }
      ],
      "source": [
        "with open('reddit_small.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    print(text[:10240])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "ThdLPYcP0Gyk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThdLPYcP0Gyk",
        "outputId": "00ebcdcb-f177-41ab-bec2-0abbdbda5b04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23043723"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "1aQd4Sms0R-v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aQd4Sms0R-v",
        "outputId": "b8093a7d-25d9-448f-aa1d-16bfdb69ef85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Encoding 'rustbpe'>\n",
            "[13726, 111, 1170]\n"
          ]
        }
      ],
      "source": [
        "# import tiktoken\n",
        "# enc = tiktoken.get_encoding('gpt2')\n",
        "# tokenizer\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "\n",
        "with open(\"/content/tokenizer.pkl\", \"rb\") as f:\n",
        "    enc = pickle.load(f)\n",
        "print(enc)\n",
        "tokens = enc.encode(\"hello world\")\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "vu5o_dxK0oiA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu5o_dxK0oiA",
        "outputId": "036d3611-3bef-4ede-d21f-fbd300872882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5699090\n"
          ]
        }
      ],
      "source": [
        "input_tokens = enc.encode(text)\n",
        "print(len(input_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "AzUgFYvOEHJc",
      "metadata": {
        "id": "AzUgFYvOEHJc"
      },
      "outputs": [],
      "source": [
        "B = 32\n",
        "\n",
        "start = 0\n",
        "\n",
        "def load_next_batch():\n",
        "    global start\n",
        "    end = (start + B*config.sequence_len + 1) % len(input_tokens)\n",
        "    if end < start:\n",
        "        start = 0\n",
        "        end = B*config.sequence_len + 1\n",
        "    buf = torch.tensor(input_tokens[start:end])\n",
        "    start = end\n",
        "\n",
        "    x = buf[:-1].view(B, config.sequence_len)\n",
        "    y = buf[1:].view(B, config.sequence_len)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def get_gpu_stats():\n",
        "    print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "sFtqfz7EWBY5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFtqfz7EWBY5",
        "outputId": "f270343f-c936-401b-9960-52949a1b94b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "\u001b[41mThe\u001b[0m\u001b[42m one\u001b[0m\u001b[43m feature\u001b[0m\u001b[44m the\u001b[0m\u001b[41m iPad\u001b[0m\u001b[42m is\u001b[0m\u001b[43m really\u001b[0m\u001b[44m missing\u001b[0m\u001b[41m.\u001b[0m\u001b[42m I\u001b[0m\u001b[43m don\u001b[0m\u001b[44m't\u001b[0m\u001b[41m care\u001b[0m\u001b[42m about\u001b[0m\u001b[43m the\u001b[0m\u001b[44m lack\u001b[0m\u001b[41m of\u001b[0m\u001b[42m camera\u001b[0m\u001b[43m.\u001b[0m\u001b[44m I\u001b[0m\u001b[41m never\u001b[0m\u001b[42m use\u001b[0m\u001b[43m the\u001b[0m\u001b[44m one\u001b[0m\u001b[41m on\u001b[0m\u001b[42m my\u001b[0m\u001b[43m Mac\u001b[0m\u001b[44mBook\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m even\u001b[0m\u001b[44m if\u001b[0m\u001b[41m I\u001b[0m\u001b[42m did\u001b[0m\u001b[43m the\u001b[0m\u001b[44m angle\u001b[0m\u001b[41m would\u001b[0m\u001b[42m be\u001b[0m\u001b[43m terrible\u001b[0m\u001b[44m on\u001b[0m\u001b[41m the\u001b[0m\u001b[42m iPad\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mI\u001b[0m\u001b[43m don\u001b[0m\u001b[44m't\u001b[0m\u001b[41m care\u001b[0m\u001b[42m if\u001b[0m\u001b[43m third\u001b[0m\u001b[44m party\u001b[0m\u001b[41m apps\u001b[0m\u001b[42m can\u001b[0m\u001b[43m't\u001b[0m\u001b[44m run\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m background\u001b[0m\u001b[44m.\u001b[0m\u001b[41m I\u001b[0m\u001b[42m don\u001b[0m\u001b[43m't\u001b[0m\u001b[44m listen\u001b[0m\u001b[41m to\u001b[0m\u001b[42m streaming\u001b[0m\u001b[43m music\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43mI\u001b[0m\u001b[44m don\u001b[0m\u001b[41m't\u001b[0m\u001b[42m care\u001b[0m\u001b[43m that\u001b[0m\u001b[44m the\u001b[0m\u001b[41m App\u001b[0m\u001b[42m Store\u001b[0m\u001b[43m is\u001b[0m\u001b[44m a\u001b[0m\u001b[41m closed\u001b[0m\u001b[42m system\u001b[0m\u001b[43m.\u001b[0m\u001b[44m I\u001b[0m\u001b[41m can\u001b[0m\u001b[42m jail\u001b[0m\u001b[43mbreak\u001b[0m\u001b[44m for\u001b[0m\u001b[41m myself\u001b[0m\u001b[42m and\u001b[0m\u001b[43m I\u001b[0m\u001b[44m think\u001b[0m\u001b[41m the\u001b[0m\u001b[42m closed\u001b[0m\u001b[43m system\u001b[0m\u001b[44m works\u001b[0m\u001b[41m better\u001b[0m\u001b[42m for\u001b[0m\u001b[43m most\u001b[0m\u001b[44m users\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mThe\u001b[0m\u001b[41m one\u001b[0m\u001b[42m feature\u001b[0m\u001b[43m I\u001b[0m\u001b[44m want\u001b[0m\u001b[41m is\u001b[0m\u001b[42m Us\u001b[0m\u001b[43mer\u001b[0m\u001b[44m Account\u001b[0m\u001b[41ms\u001b[0m\u001b[42m and\u001b[0m\u001b[43m a\u001b[0m\u001b[44m Guest\u001b[0m\u001b[41m Account\u001b[0m\u001b[42m.\u001b[0m\u001b[43m If\u001b[0m\u001b[44m this\u001b[0m\u001b[41m device\u001b[0m\u001b[42m is\u001b[0m\u001b[43m meant\u001b[0m\u001b[44m to\u001b[0m\u001b[41m be\u001b[0m\u001b[42m a\u001b[0m\u001b[43m coffee\u001b[0m\u001b[44m table\u001b[0m\u001b[41m computer\u001b[0m\u001b[42m,\u001b[0m\u001b[43m it\u001b[0m\u001b[44m needs\u001b[0m\u001b[41m to\u001b[0m\u001b[42m be\u001b[0m\u001b[43m able\u001b[0m\u001b[44m to\u001b[0m\u001b[41m acc\u001b[0m\u001b[42mom\u001b[0m\u001b[43mad\u001b[0m\u001b[44mate\u001b[0m\u001b[41m multiple\u001b[0m\u001b[42m users\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mDear\u001b[0m\u001b[42m Sydney\u001b[0m\u001b[43m Reddit\u001b[0m\u001b[44m'\u001b[0m\u001b[41mers\u001b[0m\u001b[42m,\u001b[0m\u001b[43m Would\u001b[0m\u001b[44m you\u001b[0m\u001b[41m like\u001b[0m\u001b[42m any\u001b[0m\u001b[43m changes\u001b[0m\u001b[44m made\u001b[0m\u001b[41m to\u001b[0m\u001b[42m the\u001b[0m\u001b[43m style\u001b[0m\u001b[44m of\u001b[0m\u001b[41m this\u001b[0m\u001b[42m subreddit\u001b[0m\u001b[43m?\u001b[0m\u001b[44m I\u001b[0m\u001b[41m was\u001b[0m\u001b[42m going\u001b[0m\u001b[43m to\u001b[0m\u001b[44m subt\u001b[0m\u001b[41mly\u001b[0m\u001b[42m edit\u001b[0m\u001b[43m the\u001b[0m\u001b[44m style\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Sydney\u001b[0m\u001b[44m subreddit\u001b[0m\u001b[41m but\u001b[0m\u001b[42m then\u001b[0m\u001b[43m I\u001b[0m\u001b[44m found\u001b[0m\u001b[41m this\u001b[0m\u001b[42m post\u001b[0m\u001b[43m and\u001b[0m\u001b[44m realised\u001b[0m\u001b[41m that\u001b[0m\u001b[42m people\u001b[0m\u001b[43m have\u001b[0m\u001b[44m very\u001b[0m\u001b[41m strong\u001b[0m\u001b[42m opinions\u001b[0m\u001b[43m about\u001b[0m\u001b[44m how\u001b[0m\u001b[41m their\u001b[0m\u001b[42m reddit\u001b[0m\u001b[43m should\u001b[0m\u001b[44m look\u001b[0m\u001b[41m.\u001b[0m\u001b[42m \u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43mSo\u001b[0m\u001b[44m before\u001b[0m\u001b[41m I\u001b[0m\u001b[42m make\u001b[0m\u001b[43m any\u001b[0m\u001b[44m changes\u001b[0m\u001b[41m do\u001b[0m\u001b[42m you\u001b[0m\u001b[43m have\u001b[0m\u001b[44m any\u001b[0m\u001b[41m opinions\u001b[0m\u001b[42m or\u001b[0m\u001b[43m suggestions\u001b[0m\u001b[44m?\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mI\u001b[0m\u001b[43m sk\u001b[0m\u001b[44mipped\u001b[0m\u001b[41m bail\u001b[0m\u001b[42m,\u001b[0m\u001b[43m ran\u001b[0m\u001b[44m away\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m never\u001b[0m\u001b[44m got\u001b[0m\u001b[41m caught\u001b[0m\u001b[42m.\u001b[0m\u001b[43m AM\u001b[0m\u001b[44m(\u001b[0m\u001b[41mA\u001b[0m\u001b[42m)\u001b[0m\u001b[43mA\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Long\u001b[0m\u001b[42m/\u001b[0m\u001b[43mshort\u001b[0m\u001b[44m story\u001b[0m\u001b[41m,\u001b[0m\u001b[42m I\u001b[0m\u001b[43m went\u001b[0m\u001b[44m to\u001b[0m\u001b[41m work\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m last\u001b[0m\u001b[41m \u001b[0m\u001b[42m90\u001b[0m\u001b[43ms\u001b[0m\u001b[44m and\u001b[0m\n",
            "--------------------------------------------------\n",
            "\u001b[41m one\u001b[0m\u001b[42m feature\u001b[0m\u001b[43m the\u001b[0m\u001b[44m iPad\u001b[0m\u001b[41m is\u001b[0m\u001b[42m really\u001b[0m\u001b[43m missing\u001b[0m\u001b[44m.\u001b[0m\u001b[41m I\u001b[0m\u001b[42m don\u001b[0m\u001b[43m't\u001b[0m\u001b[44m care\u001b[0m\u001b[41m about\u001b[0m\u001b[42m the\u001b[0m\u001b[43m lack\u001b[0m\u001b[44m of\u001b[0m\u001b[41m camera\u001b[0m\u001b[42m.\u001b[0m\u001b[43m I\u001b[0m\u001b[44m never\u001b[0m\u001b[41m use\u001b[0m\u001b[42m the\u001b[0m\u001b[43m one\u001b[0m\u001b[44m on\u001b[0m\u001b[41m my\u001b[0m\u001b[42m Mac\u001b[0m\u001b[43mBook\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m even\u001b[0m\u001b[43m if\u001b[0m\u001b[44m I\u001b[0m\u001b[41m did\u001b[0m\u001b[42m the\u001b[0m\u001b[43m angle\u001b[0m\u001b[44m would\u001b[0m\u001b[41m be\u001b[0m\u001b[42m terrible\u001b[0m\u001b[43m on\u001b[0m\u001b[44m the\u001b[0m\u001b[41m iPad\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mI\u001b[0m\u001b[42m don\u001b[0m\u001b[43m't\u001b[0m\u001b[44m care\u001b[0m\u001b[41m if\u001b[0m\u001b[42m third\u001b[0m\u001b[43m party\u001b[0m\u001b[44m apps\u001b[0m\u001b[41m can\u001b[0m\u001b[42m't\u001b[0m\u001b[43m run\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m background\u001b[0m\u001b[43m.\u001b[0m\u001b[44m I\u001b[0m\u001b[41m don\u001b[0m\u001b[42m't\u001b[0m\u001b[43m listen\u001b[0m\u001b[44m to\u001b[0m\u001b[41m streaming\u001b[0m\u001b[42m music\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mI\u001b[0m\u001b[43m don\u001b[0m\u001b[44m't\u001b[0m\u001b[41m care\u001b[0m\u001b[42m that\u001b[0m\u001b[43m the\u001b[0m\u001b[44m App\u001b[0m\u001b[41m Store\u001b[0m\u001b[42m is\u001b[0m\u001b[43m a\u001b[0m\u001b[44m closed\u001b[0m\u001b[41m system\u001b[0m\u001b[42m.\u001b[0m\u001b[43m I\u001b[0m\u001b[44m can\u001b[0m\u001b[41m jail\u001b[0m\u001b[42mbreak\u001b[0m\u001b[43m for\u001b[0m\u001b[44m myself\u001b[0m\u001b[41m and\u001b[0m\u001b[42m I\u001b[0m\u001b[43m think\u001b[0m\u001b[44m the\u001b[0m\u001b[41m closed\u001b[0m\u001b[42m system\u001b[0m\u001b[43m works\u001b[0m\u001b[44m better\u001b[0m\u001b[41m for\u001b[0m\u001b[42m most\u001b[0m\u001b[43m users\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43mThe\u001b[0m\u001b[44m one\u001b[0m\u001b[41m feature\u001b[0m\u001b[42m I\u001b[0m\u001b[43m want\u001b[0m\u001b[44m is\u001b[0m\u001b[41m Us\u001b[0m\u001b[42mer\u001b[0m\u001b[43m Account\u001b[0m\u001b[44ms\u001b[0m\u001b[41m and\u001b[0m\u001b[42m a\u001b[0m\u001b[43m Guest\u001b[0m\u001b[44m Account\u001b[0m\u001b[41m.\u001b[0m\u001b[42m If\u001b[0m\u001b[43m this\u001b[0m\u001b[44m device\u001b[0m\u001b[41m is\u001b[0m\u001b[42m meant\u001b[0m\u001b[43m to\u001b[0m\u001b[44m be\u001b[0m\u001b[41m a\u001b[0m\u001b[42m coffee\u001b[0m\u001b[43m table\u001b[0m\u001b[44m computer\u001b[0m\u001b[41m,\u001b[0m\u001b[42m it\u001b[0m\u001b[43m needs\u001b[0m\u001b[44m to\u001b[0m\u001b[41m be\u001b[0m\u001b[42m able\u001b[0m\u001b[43m to\u001b[0m\u001b[44m acc\u001b[0m\u001b[41mom\u001b[0m\u001b[42mad\u001b[0m\u001b[43mate\u001b[0m\u001b[44m multiple\u001b[0m\u001b[41m users\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44mDear\u001b[0m\u001b[41m Sydney\u001b[0m\u001b[42m Reddit\u001b[0m\u001b[43m'\u001b[0m\u001b[44mers\u001b[0m\u001b[41m,\u001b[0m\u001b[42m Would\u001b[0m\u001b[43m you\u001b[0m\u001b[44m like\u001b[0m\u001b[41m any\u001b[0m\u001b[42m changes\u001b[0m\u001b[43m made\u001b[0m\u001b[44m to\u001b[0m\u001b[41m the\u001b[0m\u001b[42m style\u001b[0m\u001b[43m of\u001b[0m\u001b[44m this\u001b[0m\u001b[41m subreddit\u001b[0m\u001b[42m?\u001b[0m\u001b[43m I\u001b[0m\u001b[44m was\u001b[0m\u001b[41m going\u001b[0m\u001b[42m to\u001b[0m\u001b[43m subt\u001b[0m\u001b[44mly\u001b[0m\u001b[41m edit\u001b[0m\u001b[42m the\u001b[0m\u001b[43m style\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Sydney\u001b[0m\u001b[43m subreddit\u001b[0m\u001b[44m but\u001b[0m\u001b[41m then\u001b[0m\u001b[42m I\u001b[0m\u001b[43m found\u001b[0m\u001b[44m this\u001b[0m\u001b[41m post\u001b[0m\u001b[42m and\u001b[0m\u001b[43m realised\u001b[0m\u001b[44m that\u001b[0m\u001b[41m people\u001b[0m\u001b[42m have\u001b[0m\u001b[43m very\u001b[0m\u001b[44m strong\u001b[0m\u001b[41m opinions\u001b[0m\u001b[42m about\u001b[0m\u001b[43m how\u001b[0m\u001b[44m their\u001b[0m\u001b[41m reddit\u001b[0m\u001b[42m should\u001b[0m\u001b[43m look\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSo\u001b[0m\u001b[43m before\u001b[0m\u001b[44m I\u001b[0m\u001b[41m make\u001b[0m\u001b[42m any\u001b[0m\u001b[43m changes\u001b[0m\u001b[44m do\u001b[0m\u001b[41m you\u001b[0m\u001b[42m have\u001b[0m\u001b[43m any\u001b[0m\u001b[44m opinions\u001b[0m\u001b[41m or\u001b[0m\u001b[42m suggestions\u001b[0m\u001b[43m?\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41mI\u001b[0m\u001b[42m sk\u001b[0m\u001b[43mipped\u001b[0m\u001b[44m bail\u001b[0m\u001b[41m,\u001b[0m\u001b[42m ran\u001b[0m\u001b[43m away\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m never\u001b[0m\u001b[43m got\u001b[0m\u001b[44m caught\u001b[0m\u001b[41m.\u001b[0m\u001b[42m AM\u001b[0m\u001b[43m(\u001b[0m\u001b[44mA\u001b[0m\u001b[41m)\u001b[0m\u001b[42mA\u001b[0m\u001b[43m.\u001b[0m\u001b[44m Long\u001b[0m\u001b[41m/\u001b[0m\u001b[42mshort\u001b[0m\u001b[43m story\u001b[0m\u001b[44m,\u001b[0m\u001b[41m I\u001b[0m\u001b[42m went\u001b[0m\u001b[43m to\u001b[0m\u001b[44m work\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m last\u001b[0m\u001b[44m \u001b[0m\u001b[41m90\u001b[0m\u001b[42ms\u001b[0m\u001b[43m and\u001b[0m\u001b[44m was\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def tiktokenize_tokens(tokens):\n",
        "  for i, token in enumerate(tokens):\n",
        "    print(f\"\\033[{i%4+41}m{enc.decode([token])}\\033[0m\", end=\"\")\n",
        "  print()\n",
        "\n",
        "x_val, y_val = load_next_batch()\n",
        "x_val = x_val.to(device_type)\n",
        "y_val = y_val.to(device_type)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "tiktokenize_tokens(x_val[0])\n",
        "print(\"-\"*50)\n",
        "tiktokenize_tokens(y_val[0])\n",
        "\n",
        "start = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "eYduD3PuI_uJ",
      "metadata": {
        "id": "eYduD3PuI_uJ"
      },
      "outputs": [],
      "source": [
        "autocast_ctx = torch.amp.autocast(device_type=device_type, dtype=torch.bfloat16) if device_type == \"cuda\" else nullcontext()\n",
        "\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yel2Jim82DTT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yel2Jim82DTT",
        "outputId": "b4158c98-426a-4a9b-dd76-309a1956a2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0, validation loss: 6.024102687835693, average time over last 10 steps = 0.0023022890090942383\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 10, validation loss: 6.1195573806762695, average time over last 10 steps = 0.8296464443206787\n",
            "step 20, validation loss: 6.17494010925293, average time over last 10 steps = 0.8212828874588013\n",
            "step 30, validation loss: 5.7937846183776855, average time over last 10 steps = 0.838221263885498\n",
            "step 40, validation loss: 5.8871636390686035, average time over last 10 steps = 0.8483931303024292\n",
            "step 50, validation loss: 5.8090996742248535, average time over last 10 steps = 0.8373467922210693\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m is\u001b[0m\u001b[44m a\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m is\u001b[0m\u001b[43m a\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m work\u001b[0m\u001b[41m is\u001b[0m\u001b[42m a\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 60, validation loss: 5.9071125984191895, average time over last 10 steps = 0.8420436382293701\n",
            "step 70, validation loss: 5.938328742980957, average time over last 10 steps = 0.8272908449172973\n",
            "step 80, validation loss: 6.213301658630371, average time over last 10 steps = 0.8052340030670166\n",
            "step 90, validation loss: 6.259651184082031, average time over last 10 steps = 0.8134978771209717\n",
            "step 100, validation loss: 6.267325401306152, average time over last 10 steps = 0.8149991273880005\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m work\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m05\u001b[0m\u001b[42m:\u001b[0m\u001b[43m00\u001b[0m\u001b[44m1\u001b[0m\u001b[41m:\u001b[0m\u001b[42m00\u001b[0m\u001b[43m1\u001b[0m\u001b[44m And\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m said\u001b[0m\u001b[44m unto\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m,\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m05\u001b[0m\u001b[42m:\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 110, validation loss: 6.277763366699219, average time over last 10 steps = 0.8318932056427002\n",
            "step 120, validation loss: 6.200129985809326, average time over last 10 steps = 0.8192293643951416\n",
            "step 130, validation loss: 6.165148735046387, average time over last 10 steps = 0.8185601472854614\n",
            "step 140, validation loss: 6.285186290740967, average time over last 10 steps = 0.8258763074874877\n",
            "step 150, validation loss: 6.265898704528809, average time over last 10 steps = 0.8242875576019287\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m work\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m work\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m work\u001b[0m\u001b[42m of\u001b[0m\u001b[43m the\u001b[0m\u001b[44m work\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m19\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 160, validation loss: 6.324590682983398, average time over last 10 steps = 0.8419863462448121\n",
            "step 170, validation loss: 6.340104103088379, average time over last 10 steps = 0.8199108600616455\n",
            "step 180, validation loss: 6.313141822814941, average time over last 10 steps = 0.820814061164856\n",
            "step 190, validation loss: 6.275043964385986, average time over last 10 steps = 0.8221884489059448\n",
            "step 200, validation loss: 6.217690467834473, average time over last 10 steps = 0.8169847726821899\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m work\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m42\u001b[0m\u001b[43m:\u001b[0m\u001b[44m00\u001b[0m\u001b[41m9\u001b[0m\u001b[42m:\u001b[0m\u001b[43m01\u001b[0m\u001b[44m0\u001b[0m\u001b[41m And\u001b[0m\u001b[42m when\u001b[0m\u001b[43m he\u001b[0m\u001b[44m had\u001b[0m\u001b[41m made\u001b[0m\u001b[42m a\u001b[0m\u001b[43m man\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m said\u001b[0m\u001b[43m unto\u001b[0m\u001b[44m them\u001b[0m\u001b[41m,\u001b[0m\u001b[42m I\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 210, validation loss: 6.169133186340332, average time over last 10 steps = 0.8317729473114014\n",
            "step 220, validation loss: 6.11911678314209, average time over last 10 steps = 0.8172884941101074\n",
            "step 230, validation loss: 5.905963897705078, average time over last 10 steps = 0.8173805713653565\n",
            "step 240, validation loss: 5.853220462799072, average time over last 10 steps = 0.8176664352416992\n",
            "step 250, validation loss: 5.660872936248779, average time over last 10 steps = 0.8183138132095337\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 260, validation loss: 5.694972991943359, average time over last 10 steps = 0.8377765893936158\n",
            "step 270, validation loss: 5.859288215637207, average time over last 10 steps = 0.8177712202072144\n",
            "step 280, validation loss: 5.835318565368652, average time over last 10 steps = 0.8178046226501465\n",
            "step 290, validation loss: 5.9623942375183105, average time over last 10 steps = 0.8244972467422486\n",
            "step 300, validation loss: 5.85647439956665, average time over last 10 steps = 0.8225504398345947\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m user\u001b[0m\u001b[44m's\u001b[0m\u001b[41m name\u001b[0m\u001b[42m is\u001b[0m\u001b[43m a\u001b[0m\u001b[44m program\u001b[0m\u001b[41m to\u001b[0m\u001b[42m be\u001b[0m\u001b[43m used\u001b[0m\u001b[44m to\u001b[0m\u001b[41m be\u001b[0m\u001b[42m used\u001b[0m\u001b[43m to\u001b[0m\u001b[44m be\u001b[0m\u001b[41m used\u001b[0m\u001b[42m to\u001b[0m\u001b[43m be\u001b[0m\u001b[44m used\u001b[0m\u001b[41m to\u001b[0m\u001b[42m be\u001b[0m\u001b[43m used\u001b[0m\u001b[44m to\u001b[0m\u001b[41m be\u001b[0m\u001b[42m used\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 310, validation loss: 5.837465763092041, average time over last 10 steps = 0.8375165462493896\n",
            "step 320, validation loss: 5.819427013397217, average time over last 10 steps = 0.819750714302063\n",
            "step 330, validation loss: 5.823200225830078, average time over last 10 steps = 0.8179173231124878\n",
            "step 340, validation loss: 5.876502990722656, average time over last 10 steps = 0.8199963808059693\n",
            "step 350, validation loss: 5.877439022064209, average time over last 10 steps = 0.822245192527771\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 360, validation loss: 5.790401458740234, average time over last 10 steps = 0.8365801334381103\n",
            "step 370, validation loss: 5.811558723449707, average time over last 10 steps = 0.8219081401824951\n",
            "step 380, validation loss: 5.875578880310059, average time over last 10 steps = 0.821065878868103\n",
            "step 390, validation loss: 5.624248504638672, average time over last 10 steps = 0.8197784423828125\n",
            "step 400, validation loss: 5.730856895446777, average time over last 10 steps = 0.820811414718628\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m0\u001b[0m\u001b[41m (\u001b[0m\u001b[42mC\u001b[0m\u001b[43m /\u001b[0m\u001b[44mT\u001b[0m\u001b[41mimes\u001b[0m\u001b[42m-Roman\u001b[0m\u001b[43m /\u001b[0m\u001b[44mf\u001b[0m\u001b[41mont\u001b[0m\u001b[42m40\u001b[0m\u001b[43m AN\u001b[0m\u001b[44mSI\u001b[0m\u001b[41mF\u001b[0m\u001b[42mont\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 410, validation loss: 5.757386684417725, average time over last 10 steps = 0.835214900970459\n",
            "step 420, validation loss: 5.7821760177612305, average time over last 10 steps = 0.8195681810379029\n",
            "step 430, validation loss: 5.803806304931641, average time over last 10 steps = 0.8174566268920899\n",
            "step 440, validation loss: 5.695775032043457, average time over last 10 steps = 0.8170732736587525\n",
            "step 450, validation loss: 5.725234508514404, average time over last 10 steps = 0.820599365234375\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m or\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m or\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 460, validation loss: 5.651461601257324, average time over last 10 steps = 0.8323263645172119\n",
            "step 470, validation loss: 5.829340934753418, average time over last 10 steps = 0.8174927711486817\n",
            "step 480, validation loss: 5.844601631164551, average time over last 10 steps = 0.8204100131988525\n",
            "step 490, validation loss: 5.864450931549072, average time over last 10 steps = 0.819876742362976\n",
            "step 500, validation loss: 5.892992973327637, average time over last 10 steps = 0.8193923234939575\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 510, validation loss: 5.9502105712890625, average time over last 10 steps = 0.8391433000564575\n",
            "step 520, validation loss: 5.962847709655762, average time over last 10 steps = 0.8151784420013428\n",
            "step 530, validation loss: 5.991154670715332, average time over last 10 steps = 0.8210467338562012\n",
            "step 540, validation loss: 8.506333351135254, average time over last 10 steps = 0.8199627161026001\n",
            "step 550, validation loss: 9.725687980651855, average time over last 10 steps = 0.8144012212753295\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m38\u001b[0m\u001b[44m92\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\u001b[43m \u001b[0m\u001b[44m38\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\u001b[43m92\u001b[0m\u001b[44m \u001b[0m\u001b[41m38\u001b[0m\u001b[42m92\u001b[0m\u001b[43m92\u001b[0m\u001b[44m92\u001b[0m\u001b[41m92\u001b[0m\u001b[42m \u001b[0m\u001b[43m38\u001b[0m\u001b[44m92\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\u001b[43m \u001b[0m\u001b[44m38\u001b[0m\u001b[41m92\u001b[0m\u001b[42m92\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 560, validation loss: 10.082049369812012, average time over last 10 steps = 0.8262614965438843\n",
            "step 570, validation loss: 10.485931396484375, average time over last 10 steps = 0.8176478862762451\n",
            "step 580, validation loss: 10.345940589904785, average time over last 10 steps = 0.8175805568695068\n",
            "step 590, validation loss: 10.489385604858398, average time over last 10 steps = 0.816024899482727\n",
            "step 600, validation loss: 10.634145736694336, average time over last 10 steps = 0.8184903621673584\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m20\u001b[0m\u001b[44m20\u001b[0m\u001b[41m20\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m91\u001b[0m\u001b[43m91\u001b[0m\u001b[44m91\u001b[0m\u001b[41m91\u001b[0m\u001b[42m \u001b[0m\u001b[43m19\u001b[0m\u001b[44m91\u001b[0m\u001b[41m91\u001b[0m\u001b[42m91\u001b[0m\u001b[43m91\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m91\u001b[0m\u001b[43m91\u001b[0m\u001b[44m91\u001b[0m\u001b[41m91\u001b[0m\u001b[42m \u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 610, validation loss: 10.713346481323242, average time over last 10 steps = 0.8387495517730713\n",
            "step 620, validation loss: 10.72623062133789, average time over last 10 steps = 0.8153129816055298\n",
            "step 630, validation loss: 6.626347064971924, average time over last 10 steps = 0.8162482023239136\n",
            "step 640, validation loss: 6.164364814758301, average time over last 10 steps = 0.8207346677780152\n",
            "step 650, validation loss: 5.783856391906738, average time over last 10 steps = 0.8195324897766113\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 660, validation loss: 5.785619735717773, average time over last 10 steps = 0.8346967220306396\n",
            "step 670, validation loss: 5.657232284545898, average time over last 10 steps = 0.8215094566345215\n",
            "step 680, validation loss: 5.6370344161987305, average time over last 10 steps = 0.8188746929168701\n",
            "step 690, validation loss: 5.564116477966309, average time over last 10 steps = 0.8215549707412719\n",
            "step 700, validation loss: 5.5412492752075195, average time over last 10 steps = 0.8175608873367309\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 710, validation loss: 6.26772403717041, average time over last 10 steps = 0.8319935321807861\n",
            "step 720, validation loss: 5.978111743927002, average time over last 10 steps = 0.8217746257781983\n",
            "step 730, validation loss: 8.012216567993164, average time over last 10 steps = 0.8122478008270264\n",
            "step 740, validation loss: 9.775409698486328, average time over last 10 steps = 0.8101706743240357\n",
            "step 750, validation loss: 10.240896224975586, average time over last 10 steps = 0.8121178865432739\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\u001b[43m57\u001b[0m\u001b[44m \u001b[0m\u001b[41m57\u001b[0m\u001b[42m \u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 760, validation loss: 8.993864059448242, average time over last 10 steps = 0.8356042861938476\n",
            "step 770, validation loss: 9.027339935302734, average time over last 10 steps = 0.8171735763549804\n",
            "step 780, validation loss: 6.194745063781738, average time over last 10 steps = 0.8202389717102051\n",
            "step 790, validation loss: 5.908310413360596, average time over last 10 steps = 0.8246711492538452\n",
            "step 800, validation loss: 5.7287516593933105, average time over last 10 steps = 0.8232528448104859\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 810, validation loss: 6.054421901702881, average time over last 10 steps = 0.8268224477767945\n",
            "step 820, validation loss: 5.858434677124023, average time over last 10 steps = 0.8164382696151733\n",
            "step 830, validation loss: 5.854859352111816, average time over last 10 steps = 0.8220471382141114\n",
            "step 840, validation loss: 5.700778007507324, average time over last 10 steps = 0.8219289064407349\n",
            "step 850, validation loss: 5.732512950897217, average time over last 10 steps = 0.8224381685256958\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mThe\u001b[0m\u001b[43m Foundation\u001b[0m\u001b[44m’s\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m you\u001b[0m\u001b[44m are\u001b[0m\u001b[41m located\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 860, validation loss: 5.778020858764648, average time over last 10 steps = 0.8345464706420899\n",
            "step 870, validation loss: 5.690155982971191, average time over last 10 steps = 0.8224225044250488\n",
            "step 880, validation loss: 5.724200248718262, average time over last 10 steps = 0.821495532989502\n",
            "step 890, validation loss: 5.650038242340088, average time over last 10 steps = 0.8198154449462891\n",
            "step 900, validation loss: 5.624883651733398, average time over last 10 steps = 0.8218269109725952\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 910, validation loss: 5.604562282562256, average time over last 10 steps = 0.8381437063217163\n",
            "step 920, validation loss: 5.7614850997924805, average time over last 10 steps = 0.8182414531707763\n",
            "step 930, validation loss: 5.90634298324585, average time over last 10 steps = 0.8189434289932251\n",
            "step 940, validation loss: 5.826498985290527, average time over last 10 steps = 0.8170700311660767\n",
            "step 950, validation loss: 5.846360683441162, average time over last 10 steps = 0.8186549186706543\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 960, validation loss: 5.684191703796387, average time over last 10 steps = 0.8345660448074341\n",
            "step 970, validation loss: 5.742852210998535, average time over last 10 steps = 0.8204695463180542\n",
            "step 980, validation loss: 5.6167426109313965, average time over last 10 steps = 0.821454668045044\n",
            "step 990, validation loss: 5.637219429016113, average time over last 10 steps = 0.8198864459991455\n",
            "step 1000, validation loss: 5.585240364074707, average time over last 10 steps = 0.8213371992111206\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1010, validation loss: 5.582864284515381, average time over last 10 steps = 0.8366617441177369\n",
            "step 1020, validation loss: 5.566638946533203, average time over last 10 steps = 0.8202749013900756\n",
            "step 1030, validation loss: 5.523058891296387, average time over last 10 steps = 0.8250838041305542\n",
            "step 1040, validation loss: 5.528639793395996, average time over last 10 steps = 0.8225548028945923\n",
            "step 1050, validation loss: 5.5532965660095215, average time over last 10 steps = 0.8204146146774292\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1060, validation loss: 5.518769264221191, average time over last 10 steps = 0.8344964742660522\n",
            "step 1070, validation loss: 5.489145755767822, average time over last 10 steps = 0.8200648546218872\n",
            "step 1080, validation loss: 5.528295516967773, average time over last 10 steps = 0.8205774545669555\n",
            "step 1090, validation loss: 5.639066696166992, average time over last 10 steps = 0.8205316543579102\n",
            "step 1100, validation loss: 5.698869705200195, average time over last 10 steps = 0.8222255229949951\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1110, validation loss: 5.743199825286865, average time over last 10 steps = 0.8373348951339722\n",
            "step 1120, validation loss: 5.754611968994141, average time over last 10 steps = 0.8239229917526245\n",
            "step 1130, validation loss: 5.777327537536621, average time over last 10 steps = 0.8243869543075562\n",
            "step 1140, validation loss: 5.795767784118652, average time over last 10 steps = 0.8172047138214111\n",
            "step 1150, validation loss: 5.805895805358887, average time over last 10 steps = 0.8200936555862427\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1160, validation loss: 5.941144943237305, average time over last 10 steps = 0.833069109916687\n",
            "step 1170, validation loss: 6.327024936676025, average time over last 10 steps = 0.817087721824646\n",
            "step 1180, validation loss: 6.435285568237305, average time over last 10 steps = 0.8191255807876587\n",
            "step 1190, validation loss: 6.463505744934082, average time over last 10 steps = 0.8179639339447021\n",
            "step 1200, validation loss: 6.487067222595215, average time over last 10 steps = 0.8162934303283691\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m.\u001b[0m\u001b[44m \u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m   \u001b[0m\u001b[43m \u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m%\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\u001b[43m79\u001b[0m\u001b[44m   \u001b[0m\u001b[41m \u001b[0m\u001b[42m0\u001b[0m\u001b[43m.\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m00\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1210, validation loss: 6.508044242858887, average time over last 10 steps = 0.8315102100372315\n",
            "step 1220, validation loss: 6.132296085357666, average time over last 10 steps = 0.8187109231948853\n",
            "step 1230, validation loss: 6.580850124359131, average time over last 10 steps = 0.8162546157836914\n",
            "step 1240, validation loss: 6.755958080291748, average time over last 10 steps = 0.8179999589920044\n",
            "step 1250, validation loss: 6.86682653427124, average time over last 10 steps = 0.8188406229019165\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m terms\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m terms\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1260, validation loss: 5.793595314025879, average time over last 10 steps = 0.8307613134384155\n",
            "step 1270, validation loss: 5.758490085601807, average time over last 10 steps = 0.8204538106918335\n",
            "step 1280, validation loss: 5.484800338745117, average time over last 10 steps = 0.8186621904373169\n",
            "step 1290, validation loss: 5.063593864440918, average time over last 10 steps = 0.8170713663101197\n",
            "step 1300, validation loss: 5.360307693481445, average time over last 10 steps = 0.8167834043502807\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1310, validation loss: 5.488428115844727, average time over last 10 steps = 0.8325886726379395\n",
            "step 1320, validation loss: 5.522707462310791, average time over last 10 steps = 0.8176400899887085\n",
            "step 1330, validation loss: 5.563495635986328, average time over last 10 steps = 0.8181406021118164\n",
            "step 1340, validation loss: 5.556849479675293, average time over last 10 steps = 0.818489670753479\n",
            "step 1350, validation loss: 5.566920757293701, average time over last 10 steps = 0.8177310228347778\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m God\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m the\u001b[0m\u001b[42m children\u001b[0m\u001b[43m of\u001b[0m\u001b[44m Israel\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m the\u001b[0m\u001b[44m children\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Israel\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m the\u001b[0m\u001b[42m children\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1360, validation loss: 5.611201763153076, average time over last 10 steps = 0.8334648370742798\n",
            "step 1370, validation loss: 5.662576675415039, average time over last 10 steps = 0.8206609964370728\n",
            "step 1380, validation loss: 5.634964466094971, average time over last 10 steps = 0.8165798425674439\n",
            "step 1390, validation loss: 5.654552936553955, average time over last 10 steps = 0.8207524299621582\n",
            "step 1400, validation loss: 5.627071857452393, average time over last 10 steps = 0.819098711013794\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m as\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m License\u001b[0m\u001b[41m as\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m as\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1410, validation loss: 5.582999229431152, average time over last 10 steps = 0.8331455230712891\n",
            "step 1420, validation loss: 5.585062503814697, average time over last 10 steps = 0.8187525510787964\n",
            "step 1430, validation loss: 5.375321865081787, average time over last 10 steps = 0.8181010007858276\n",
            "step 1440, validation loss: 5.3708696365356445, average time over last 10 steps = 0.8173707246780395\n",
            "step 1450, validation loss: 5.440679550170898, average time over last 10 steps = 0.817169189453125\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1460, validation loss: 5.4637861251831055, average time over last 10 steps = 0.8353597402572632\n",
            "step 1470, validation loss: 5.467081546783447, average time over last 10 steps = 0.8204970121383667\n",
            "step 1480, validation loss: 5.506750106811523, average time over last 10 steps = 0.8188482522964478\n",
            "step 1490, validation loss: 5.501911163330078, average time over last 10 steps = 0.8185965776443481\n",
            "step 1500, validation loss: 5.492332935333252, average time over last 10 steps = 0.8165811061859131\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1510, validation loss: 5.379566192626953, average time over last 10 steps = 0.8356541156768799\n",
            "step 1520, validation loss: 5.362983703613281, average time over last 10 steps = 0.8197465896606445\n",
            "step 1530, validation loss: 5.305593013763428, average time over last 10 steps = 0.8182208776473999\n",
            "step 1540, validation loss: 5.270211219787598, average time over last 10 steps = 0.8199959039688111\n",
            "step 1550, validation loss: 5.214201927185059, average time over last 10 steps = 0.8202949523925781\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1560, validation loss: 5.3945112228393555, average time over last 10 steps = 0.8425408124923706\n",
            "step 1570, validation loss: 5.40844202041626, average time over last 10 steps = 0.8217880964279175\n",
            "step 1580, validation loss: 5.401155948638916, average time over last 10 steps = 0.8216301441192627\n",
            "step 1590, validation loss: 5.272826671600342, average time over last 10 steps = 0.8196141481399536\n",
            "step 1600, validation loss: 5.252547264099121, average time over last 10 steps = 0.8228217601776123\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1610, validation loss: 5.2195587158203125, average time over last 10 steps = 0.8355799674987793\n",
            "step 1620, validation loss: 5.214841365814209, average time over last 10 steps = 0.8167067289352417\n",
            "step 1630, validation loss: 5.541810989379883, average time over last 10 steps = 0.8196093559265136\n",
            "step 1640, validation loss: 5.274866104125977, average time over last 10 steps = 0.8208331346511841\n",
            "step 1650, validation loss: 5.411862373352051, average time over last 10 steps = 0.81736159324646\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1660, validation loss: 5.594394683837891, average time over last 10 steps = 0.836340856552124\n",
            "step 1670, validation loss: 5.553990364074707, average time over last 10 steps = 0.8224505424499512\n",
            "step 1680, validation loss: 5.569445610046387, average time over last 10 steps = 0.8179158926010132\n",
            "step 1690, validation loss: 5.652068138122559, average time over last 10 steps = 0.8170965909957886\n",
            "step 1700, validation loss: 5.631214141845703, average time over last 10 steps = 0.8181466817855835\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m,\u001b[0m\u001b[44m you\u001b[0m\u001b[41m paid\u001b[0m\u001b[42m for\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m,\u001b[0m\u001b[42m you\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1710, validation loss: 5.2053022384643555, average time over last 10 steps = 0.8374562501907349\n",
            "step 1720, validation loss: 5.252326011657715, average time over last 10 steps = 0.8194322347640991\n",
            "step 1730, validation loss: 5.340530872344971, average time over last 10 steps = 0.8185316324234009\n",
            "step 1740, validation loss: 5.393317222595215, average time over last 10 steps = 0.8166288614273072\n",
            "step 1750, validation loss: 5.392930507659912, average time over last 10 steps = 0.81797354221344\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1760, validation loss: 5.41698694229126, average time over last 10 steps = 0.835619854927063\n",
            "step 1770, validation loss: 5.440778732299805, average time over last 10 steps = 0.8215121984481811\n",
            "step 1780, validation loss: 5.4418816566467285, average time over last 10 steps = 0.8208369016647339\n",
            "step 1790, validation loss: 5.469735145568848, average time over last 10 steps = 0.8210899353027343\n",
            "step 1800, validation loss: 5.545999050140381, average time over last 10 steps = 0.818882417678833\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1810, validation loss: 5.265484809875488, average time over last 10 steps = 0.8344829082489014\n",
            "step 1820, validation loss: 5.228918075561523, average time over last 10 steps = 0.8187145471572876\n",
            "step 1830, validation loss: 5.194683074951172, average time over last 10 steps = 0.8194126605987548\n",
            "step 1840, validation loss: 5.251046180725098, average time over last 10 steps = 0.8183056592941285\n",
            "step 1850, validation loss: 5.43758487701416, average time over last 10 steps = 0.8199437379837036\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1860, validation loss: 5.574708938598633, average time over last 10 steps = 0.8424856185913085\n",
            "step 1870, validation loss: 5.552081108093262, average time over last 10 steps = 0.8191031694412232\n",
            "step 1880, validation loss: 5.5993452072143555, average time over last 10 steps = 0.820086407661438\n",
            "step 1890, validation loss: 5.5919623374938965, average time over last 10 steps = 0.8219776391983032\n",
            "step 1900, validation loss: 5.579150199890137, average time over last 10 steps = 0.8201216936111451\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m,\u001b[0m\u001b[42m and\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1910, validation loss: 5.551065444946289, average time over last 10 steps = 0.8362797737121582\n",
            "step 1920, validation loss: 5.6476216316223145, average time over last 10 steps = 0.821066164970398\n",
            "step 1930, validation loss: 5.6238627433776855, average time over last 10 steps = 0.8193091630935669\n",
            "step 1940, validation loss: 5.667879104614258, average time over last 10 steps = 0.8215690612792969\n",
            "step 1950, validation loss: 5.671261787414551, average time over last 10 steps = 0.8191360235214233\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 1960, validation loss: 5.694904327392578, average time over last 10 steps = 0.8395719051361084\n",
            "step 1970, validation loss: 5.659710884094238, average time over last 10 steps = 0.815667200088501\n",
            "step 1980, validation loss: 5.618035316467285, average time over last 10 steps = 0.8198651552200318\n",
            "step 1990, validation loss: 5.536045074462891, average time over last 10 steps = 0.8195224523544311\n",
            "step 2000, validation loss: 5.465114593505859, average time over last 10 steps = 0.8178315162658691\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m If\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2010, validation loss: 5.333744049072266, average time over last 10 steps = 0.8333280563354493\n",
            "step 2020, validation loss: 5.247952461242676, average time over last 10 steps = 0.8188053369522095\n",
            "step 2030, validation loss: 5.1903228759765625, average time over last 10 steps = 0.816428828239441\n",
            "step 2040, validation loss: 5.202431678771973, average time over last 10 steps = 0.8170116186141968\n",
            "step 2050, validation loss: 5.231071949005127, average time over last 10 steps = 0.8194036722183228\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2060, validation loss: 5.375676155090332, average time over last 10 steps = 0.830428671836853\n",
            "step 2070, validation loss: 5.35640287399292, average time over last 10 steps = 0.8179023742675782\n",
            "step 2080, validation loss: 5.353512763977051, average time over last 10 steps = 0.8186239957809448\n",
            "step 2090, validation loss: 5.3207550048828125, average time over last 10 steps = 0.8184240579605102\n",
            "step 2100, validation loss: 5.35435676574707, average time over last 10 steps = 0.818054461479187\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m based\u001b[0m\u001b[41m on\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2110, validation loss: 5.3665571212768555, average time over last 10 steps = 0.8321063041687011\n",
            "step 2120, validation loss: 5.403404235839844, average time over last 10 steps = 0.8154648780822754\n",
            "step 2130, validation loss: 5.385547637939453, average time over last 10 steps = 0.819629454612732\n",
            "step 2140, validation loss: 5.343398571014404, average time over last 10 steps = 0.8188628673553466\n",
            "step 2150, validation loss: 5.382684707641602, average time over last 10 steps = 0.8202960968017579\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m,\u001b[0m\u001b[41m you\u001b[0m\u001b[42m can\u001b[0m\u001b[43m do\u001b[0m\u001b[44m with\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m you\u001b[0m\u001b[41m can\u001b[0m\u001b[42m do\u001b[0m\u001b[43m with\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2160, validation loss: 5.403958797454834, average time over last 10 steps = 0.8330190181732178\n",
            "step 2170, validation loss: 5.218347549438477, average time over last 10 steps = 0.8232885837554932\n",
            "step 2180, validation loss: 5.284811019897461, average time over last 10 steps = 0.8191172122955322\n",
            "step 2190, validation loss: 5.266315460205078, average time over last 10 steps = 0.8205677986145019\n",
            "step 2200, validation loss: 5.267714023590088, average time over last 10 steps = 0.8216898441314697\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m8\u001b[0m\u001b[43m.\u001b[0m\u001b[44m If\u001b[0m\u001b[41m you\u001b[0m\u001b[42m are\u001b[0m\u001b[43m located\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2210, validation loss: 5.297929763793945, average time over last 10 steps = 0.8456097364425659\n",
            "step 2220, validation loss: 5.2216291427612305, average time over last 10 steps = 0.8210183382034302\n",
            "step 2230, validation loss: 5.25284481048584, average time over last 10 steps = 0.8207526206970215\n",
            "step 2240, validation loss: 5.288784503936768, average time over last 10 steps = 0.8203664302825928\n",
            "step 2250, validation loss: 5.346899032592773, average time over last 10 steps = 0.8198331832885742\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2260, validation loss: 5.413386821746826, average time over last 10 steps = 0.8340667486190796\n",
            "step 2270, validation loss: 5.411416530609131, average time over last 10 steps = 0.8207722902297974\n",
            "step 2280, validation loss: 5.434157371520996, average time over last 10 steps = 0.8216445446014404\n",
            "step 2290, validation loss: 5.454849720001221, average time over last 10 steps = 0.8226524591445923\n",
            "step 2300, validation loss: 5.464158535003662, average time over last 10 steps = 0.8178014516830444\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2310, validation loss: 5.362888336181641, average time over last 10 steps = 0.8332040309906006\n",
            "step 2320, validation loss: 5.700160980224609, average time over last 10 steps = 0.8167083024978637\n",
            "step 2330, validation loss: 5.955768585205078, average time over last 10 steps = 0.8175347805023193\n",
            "step 2340, validation loss: 6.05708122253418, average time over last 10 steps = 0.8164632320404053\n",
            "step 2350, validation loss: 6.1000800132751465, average time over last 10 steps = 0.815306282043457\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2360, validation loss: 6.120967864990234, average time over last 10 steps = 0.8344074964523316\n",
            "step 2370, validation loss: 6.132110118865967, average time over last 10 steps = 0.8170061588287354\n",
            "step 2380, validation loss: 6.139022350311279, average time over last 10 steps = 0.8164040565490722\n",
            "step 2390, validation loss: 6.145716667175293, average time over last 10 steps = 0.8149852514266968\n",
            "step 2400, validation loss: 6.151135444641113, average time over last 10 steps = 0.8140417337417603\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m \u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m \u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m \u001b[0m\u001b[44m50\u001b[0m\u001b[41m50\u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m50\u001b[0m\u001b[41m \u001b[0m\u001b[42m50\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2410, validation loss: 5.476408958435059, average time over last 10 steps = 0.8330727577209472\n",
            "step 2420, validation loss: 5.353397369384766, average time over last 10 steps = 0.8204766273498535\n",
            "step 2430, validation loss: 5.254688262939453, average time over last 10 steps = 0.818273377418518\n",
            "step 2440, validation loss: 5.289935111999512, average time over last 10 steps = 0.822408652305603\n",
            "step 2450, validation loss: 5.196014881134033, average time over last 10 steps = 0.8211259365081787\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2460, validation loss: 5.221175193786621, average time over last 10 steps = 0.8349323272705078\n",
            "step 2470, validation loss: 5.1575164794921875, average time over last 10 steps = 0.8187979459762573\n",
            "step 2480, validation loss: 5.173078536987305, average time over last 10 steps = 0.8189699649810791\n",
            "step 2490, validation loss: 5.183897972106934, average time over last 10 steps = 0.8180872917175293\n",
            "step 2500, validation loss: 5.18778133392334, average time over last 10 steps = 0.8181450366973877\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2510, validation loss: 5.305978775024414, average time over last 10 steps = 0.8272583246231079\n",
            "step 2520, validation loss: 5.439653396606445, average time over last 10 steps = 0.8126130342483521\n",
            "step 2530, validation loss: 5.531460762023926, average time over last 10 steps = 0.8067820072174072\n",
            "step 2540, validation loss: 5.559813976287842, average time over last 10 steps = 0.8146098136901856\n",
            "step 2550, validation loss: 5.4126386642456055, average time over last 10 steps = 0.8187283277511597\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m.\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2560, validation loss: 5.3225555419921875, average time over last 10 steps = 0.8361407518386841\n",
            "step 2570, validation loss: 5.272750377655029, average time over last 10 steps = 0.819452953338623\n",
            "step 2580, validation loss: 5.320997714996338, average time over last 10 steps = 0.8188616037368774\n",
            "step 2590, validation loss: 5.509289741516113, average time over last 10 steps = 0.813286542892456\n",
            "step 2600, validation loss: 5.402092933654785, average time over last 10 steps = 0.8207459211349487\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\u001b[43m \u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42mSection\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2610, validation loss: 5.259662628173828, average time over last 10 steps = 0.8371423959732056\n",
            "step 2620, validation loss: 5.205160140991211, average time over last 10 steps = 0.819325304031372\n",
            "step 2630, validation loss: 5.23978853225708, average time over last 10 steps = 0.8200413703918457\n",
            "step 2640, validation loss: 5.208001136779785, average time over last 10 steps = 0.8195994377136231\n",
            "step 2650, validation loss: 5.274066925048828, average time over last 10 steps = 0.8215693235397339\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2660, validation loss: 5.258874893188477, average time over last 10 steps = 0.8355875015258789\n",
            "step 2670, validation loss: 5.196277618408203, average time over last 10 steps = 0.8204571723937988\n",
            "step 2680, validation loss: 5.179675102233887, average time over last 10 steps = 0.8230595588684082\n",
            "step 2690, validation loss: 5.164453029632568, average time over last 10 steps = 0.8184857845306397\n",
            "step 2700, validation loss: 5.373897552490234, average time over last 10 steps = 0.8177862644195557\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2710, validation loss: 5.399137496948242, average time over last 10 steps = 0.8337522745132446\n",
            "step 2720, validation loss: 5.384289741516113, average time over last 10 steps = 0.8200108051300049\n",
            "step 2730, validation loss: 5.386088848114014, average time over last 10 steps = 0.8176727771759034\n",
            "step 2740, validation loss: 5.253535747528076, average time over last 10 steps = 0.8194024801254273\n",
            "step 2750, validation loss: 5.3192596435546875, average time over last 10 steps = 0.8194183349609375\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m,\u001b[0m\u001b[41m or\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2760, validation loss: 5.257493495941162, average time over last 10 steps = 0.8354279518127441\n",
            "step 2770, validation loss: 5.193537712097168, average time over last 10 steps = 0.820146918296814\n",
            "step 2780, validation loss: 5.203105926513672, average time over last 10 steps = 0.820747685432434\n",
            "step 2790, validation loss: 5.20850944519043, average time over last 10 steps = 0.8240711212158203\n",
            "step 2800, validation loss: 5.165727615356445, average time over last 10 steps = 0.8218502759933471\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2810, validation loss: 5.1867170333862305, average time over last 10 steps = 0.8339752435684205\n",
            "step 2820, validation loss: 5.18481969833374, average time over last 10 steps = 0.8196565389633179\n",
            "step 2830, validation loss: 5.203917503356934, average time over last 10 steps = 0.8162472248077393\n",
            "step 2840, validation loss: 5.156701564788818, average time over last 10 steps = 0.8175369024276733\n",
            "step 2850, validation loss: 5.158380508422852, average time over last 10 steps = 0.8189965486526489\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2860, validation loss: 5.247537612915039, average time over last 10 steps = 0.8345747232437134\n",
            "step 2870, validation loss: 5.303951740264893, average time over last 10 steps = 0.8171207189559937\n",
            "step 2880, validation loss: 5.368274688720703, average time over last 10 steps = 0.8195877552032471\n",
            "step 2890, validation loss: 5.385313034057617, average time over last 10 steps = 0.8161436080932617\n",
            "step 2900, validation loss: 5.3891496658325195, average time over last 10 steps = 0.8174968004226685\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2910, validation loss: 5.404877662658691, average time over last 10 steps = 0.8333601236343384\n",
            "step 2920, validation loss: 5.414946556091309, average time over last 10 steps = 0.8178393602371216\n",
            "step 2930, validation loss: 5.435819625854492, average time over last 10 steps = 0.8173234224319458\n",
            "step 2940, validation loss: 5.570307731628418, average time over last 10 steps = 0.8197147369384765\n",
            "step 2950, validation loss: 5.815670013427734, average time over last 10 steps = 0.8170559167861938\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m00\u001b[0m\u001b[44m%\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\u001b[43m93\u001b[0m\u001b[44m   \u001b[0m\u001b[41m \u001b[0m\u001b[42m0\u001b[0m\u001b[43m.\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m00\u001b[0m\u001b[43m   \u001b[0m\u001b[44m \u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 2960, validation loss: 5.886375427246094, average time over last 10 steps = 0.8352414131164551\n",
            "step 2970, validation loss: 6.093250274658203, average time over last 10 steps = 0.8181771993637085\n",
            "step 2980, validation loss: 6.03275203704834, average time over last 10 steps = 0.8198572158813476\n",
            "step 2990, validation loss: 5.503974914550781, average time over last 10 steps = 0.8182614803314209\n",
            "step 3000, validation loss: 6.196558952331543, average time over last 10 steps = 0.8170418977737427\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m any\u001b[0m\u001b[42m other\u001b[0m\u001b[43m than\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m any\u001b[0m\u001b[44m other\u001b[0m\u001b[41m terms\u001b[0m\u001b[42m of\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3010, validation loss: 6.426998138427734, average time over last 10 steps = 0.8333780527114868\n",
            "step 3020, validation loss: 6.258671760559082, average time over last 10 steps = 0.8170264959335327\n",
            "step 3030, validation loss: 5.913238525390625, average time over last 10 steps = 0.8181366682052612\n",
            "step 3040, validation loss: 5.342403411865234, average time over last 10 steps = 0.8177024602890015\n",
            "step 3050, validation loss: 5.340741157531738, average time over last 10 steps = 0.8203032970428467\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m works\u001b[0m\u001b[43m in\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3060, validation loss: 4.918810844421387, average time over last 10 steps = 0.8340243339538574\n",
            "step 3070, validation loss: 4.827877998352051, average time over last 10 steps = 0.8175088882446289\n",
            "step 3080, validation loss: 5.169578552246094, average time over last 10 steps = 0.8197976350784302\n",
            "step 3090, validation loss: 5.2382659912109375, average time over last 10 steps = 0.8179476261138916\n",
            "step 3100, validation loss: 5.284278869628906, average time over last 10 steps = 0.818268609046936\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m children\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m children\u001b[0m\u001b[42m of\u001b[0m\u001b[43m Israel\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m children\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m children\u001b[0m\u001b[42m of\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3110, validation loss: 5.3301310539245605, average time over last 10 steps = 0.8342218637466431\n",
            "step 3120, validation loss: 5.301016807556152, average time over last 10 steps = 0.8189741611480713\n",
            "step 3130, validation loss: 5.29665994644165, average time over last 10 steps = 0.8207029581069947\n",
            "step 3140, validation loss: 5.406132221221924, average time over last 10 steps = 0.8225949287414551\n",
            "step 3150, validation loss: 5.390827655792236, average time over last 10 steps = 0.8197708845138549\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3160, validation loss: 5.363302230834961, average time over last 10 steps = 0.8393942356109619\n",
            "step 3170, validation loss: 5.36931848526001, average time over last 10 steps = 0.819656229019165\n",
            "step 3180, validation loss: 5.370354175567627, average time over last 10 steps = 0.8185571432113647\n",
            "step 3190, validation loss: 5.310869216918945, average time over last 10 steps = 0.8182689428329468\n",
            "step 3200, validation loss: 5.187933444976807, average time over last 10 steps = 0.8197712421417236\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m:\u001b[0m\u001b[43m1\u001b[0m\u001b[44m And\u001b[0m\u001b[41m when\u001b[0m\u001b[42m the\u001b[0m\u001b[43m works\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m License\u001b[0m\u001b[42m as\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3210, validation loss: 4.977025985717773, average time over last 10 steps = 0.8330884218215943\n",
            "step 3220, validation loss: 4.974509239196777, average time over last 10 steps = 0.8172090291976929\n",
            "step 3230, validation loss: 5.0370192527771, average time over last 10 steps = 0.817003583908081\n",
            "step 3240, validation loss: 5.038086891174316, average time over last 10 steps = 0.8183366298675537\n",
            "step 3250, validation loss: 5.0598602294921875, average time over last 10 steps = 0.817401647567749\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3260, validation loss: 5.095611572265625, average time over last 10 steps = 0.8305432796478271\n",
            "step 3270, validation loss: 5.091052055358887, average time over last 10 steps = 0.8186082601547241\n",
            "step 3280, validation loss: 4.974369049072266, average time over last 10 steps = 0.8164983987808228\n",
            "step 3290, validation loss: 4.998106002807617, average time over last 10 steps = 0.8183119535446167\n",
            "step 3300, validation loss: 4.963557720184326, average time over last 10 steps = 0.818405556678772\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m including\u001b[0m\u001b[42m legal\u001b[0m\u001b[43m fees\u001b[0m\u001b[44m to\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m (\u001b[0m\u001b[41mc\u001b[0m\u001b[42m.i\u001b[0m\u001b[43m.f\u001b[0m\u001b[44m.,\u001b[0m\u001b[41m \u001b[0m\u001b[42m19\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3310, validation loss: 4.974104881286621, average time over last 10 steps = 0.8370420217514039\n",
            "step 3320, validation loss: 4.920985221862793, average time over last 10 steps = 0.8175536394119263\n",
            "step 3330, validation loss: 4.984203815460205, average time over last 10 steps = 0.816291356086731\n",
            "step 3340, validation loss: 5.0844316482543945, average time over last 10 steps = 0.8173354387283325\n",
            "step 3350, validation loss: 5.061925888061523, average time over last 10 steps = 0.8176537275314331\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m including\u001b[0m\u001b[44m legal\u001b[0m\u001b[41m fees\u001b[0m\u001b[42m to\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3360, validation loss: 5.102402210235596, average time over last 10 steps = 0.8343645572662354\n",
            "step 3370, validation loss: 4.959033966064453, average time over last 10 steps = 0.8175651550292968\n",
            "step 3380, validation loss: 4.927326679229736, average time over last 10 steps = 0.8189541578292847\n",
            "step 3390, validation loss: 4.946597099304199, average time over last 10 steps = 0.8166552305221557\n",
            "step 3400, validation loss: 5.011869430541992, average time over last 10 steps = 0.8194355487823486\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3410, validation loss: 5.281163692474365, average time over last 10 steps = 0.8316126585006713\n",
            "step 3420, validation loss: 4.9023847579956055, average time over last 10 steps = 0.816936445236206\n",
            "step 3430, validation loss: 5.060836315155029, average time over last 10 steps = 0.8171381473541259\n",
            "step 3440, validation loss: 5.157101631164551, average time over last 10 steps = 0.8172352313995361\n",
            "step 3450, validation loss: 5.212174415588379, average time over last 10 steps = 0.818409776687622\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m8\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m8\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m8\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3460, validation loss: 5.228368759155273, average time over last 10 steps = 0.8380274772644043\n",
            "step 3470, validation loss: 5.228828430175781, average time over last 10 steps = 0.8211495876312256\n",
            "step 3480, validation loss: 4.976435661315918, average time over last 10 steps = 0.8181197643280029\n",
            "step 3490, validation loss: 4.913153648376465, average time over last 10 steps = 0.8168954133987427\n",
            "step 3500, validation loss: 5.013087749481201, average time over last 10 steps = 0.8197868824005127\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3510, validation loss: 5.087911605834961, average time over last 10 steps = 0.8358469724655151\n",
            "step 3520, validation loss: 5.1222991943359375, average time over last 10 steps = 0.8192390680313111\n",
            "step 3530, validation loss: 5.1422319412231445, average time over last 10 steps = 0.8201030492782593\n",
            "step 3540, validation loss: 5.148352146148682, average time over last 10 steps = 0.8178910493850708\n",
            "step 3550, validation loss: 5.171754360198975, average time over last 10 steps = 0.8173990488052368\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\n",
            "Allocated: 5.16 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3560, validation loss: 5.153852939605713, average time over last 10 steps = 0.8337522268295288\n",
            "step 3570, validation loss: 5.0383710861206055, average time over last 10 steps = 0.8175605773925781\n",
            "step 3580, validation loss: 5.317078590393066, average time over last 10 steps = 0.817280387878418\n",
            "step 3590, validation loss: 4.951458930969238, average time over last 10 steps = 0.8170310258865356\n",
            "step 3600, validation loss: 4.93257999420166, average time over last 10 steps = 0.8172910928726196\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m work\u001b[0m\u001b[41m in\u001b[0m\u001b[42m any\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3610, validation loss: 4.932371139526367, average time over last 10 steps = 0.8322682619094849\n",
            "step 3620, validation loss: 5.011502742767334, average time over last 10 steps = 0.8193115711212158\n",
            "step 3630, validation loss: 5.209064960479736, average time over last 10 steps = 0.8167091846466065\n",
            "step 3640, validation loss: 5.31571102142334, average time over last 10 steps = 0.8170129060745239\n",
            "step 3650, validation loss: 5.308131694793701, average time over last 10 steps = 0.8182460069656372\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.F\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.F\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3660, validation loss: 5.362669467926025, average time over last 10 steps = 0.8311264276504516\n",
            "step 3670, validation loss: 5.328639030456543, average time over last 10 steps = 0.8172183752059936\n",
            "step 3680, validation loss: 5.3304243087768555, average time over last 10 steps = 0.8194242477416992\n",
            "step 3690, validation loss: 5.2686309814453125, average time over last 10 steps = 0.8157721996307373\n",
            "step 3700, validation loss: 5.355538368225098, average time over last 10 steps = 0.8185297966003418\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m8\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m:\u001b[0m\u001b[42m00\u001b[0m\u001b[43m8\u001b[0m\u001b[44m:\u001b[0m\u001b[41m00\u001b[0m\u001b[42m8\u001b[0m\u001b[43m I\u001b[0m\u001b[44m am\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3710, validation loss: 5.332887649536133, average time over last 10 steps = 0.8312497615814209\n",
            "step 3720, validation loss: 5.324615478515625, average time over last 10 steps = 0.8162714719772339\n",
            "step 3730, validation loss: 5.327448844909668, average time over last 10 steps = 0.8180524110794067\n",
            "step 3740, validation loss: 5.345383644104004, average time over last 10 steps = 0.8183971166610717\n",
            "step 3750, validation loss: 5.324902534484863, average time over last 10 steps = 0.8164808511734009\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m:\u001b[0m\u001b[44m00\u001b[0m\u001b[41m1\u001b[0m\u001b[42m:\u001b[0m\u001b[43m00\u001b[0m\u001b[44m1\u001b[0m\u001b[41m And\u001b[0m\u001b[42m when\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m License\u001b[0m\u001b[44m when\u001b[0m\u001b[41m the\u001b[0m\u001b[42m Project\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3760, validation loss: 5.295654296875, average time over last 10 steps = 0.8331257104873657\n",
            "step 3770, validation loss: 5.124076843261719, average time over last 10 steps = 0.8178579568862915\n",
            "step 3780, validation loss: 5.059718608856201, average time over last 10 steps = 0.817749810218811\n",
            "step 3790, validation loss: 4.956387519836426, average time over last 10 steps = 0.818551778793335\n",
            "step 3800, validation loss: 4.958043575286865, average time over last 10 steps = 0.8179788589477539\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.F\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.F\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.F\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3810, validation loss: 4.9485764503479, average time over last 10 steps = 0.8309757709503174\n",
            "step 3820, validation loss: 4.920001983642578, average time over last 10 steps = 0.8177746772766114\n",
            "step 3830, validation loss: 4.969728946685791, average time over last 10 steps = 0.8214064121246338\n",
            "step 3840, validation loss: 5.0889177322387695, average time over last 10 steps = 0.8185899019241333\n",
            "step 3850, validation loss: 5.088662147521973, average time over last 10 steps = 0.8176713466644288\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m are\u001b[0m\u001b[42m not\u001b[0m\u001b[43m accepted\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m United\u001b[0m\u001b[43m States\u001b[0m\u001b[44m,\u001b[0m\u001b[41m but\u001b[0m\u001b[42m not\u001b[0m\u001b[43m protected\u001b[0m\u001b[44m by\u001b[0m\u001b[41m U\u001b[0m\u001b[42m.S\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3860, validation loss: 5.017473220825195, average time over last 10 steps = 0.8350079536437989\n",
            "step 3870, validation loss: 5.078733921051025, average time over last 10 steps = 0.8166695833206177\n",
            "step 3880, validation loss: 5.0850138664245605, average time over last 10 steps = 0.8177025794982911\n",
            "step 3890, validation loss: 5.096153259277344, average time over last 10 steps = 0.8208272457122803\n",
            "step 3900, validation loss: 5.078437328338623, average time over last 10 steps = 0.8168246030807496\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m work\u001b[0m\u001b[44m or\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m or\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m or\u001b[0m\u001b[43m any\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3910, validation loss: 5.093780040740967, average time over last 10 steps = 0.8333857536315918\n",
            "step 3920, validation loss: 5.065431118011475, average time over last 10 steps = 0.8217523097991943\n",
            "step 3930, validation loss: 5.1220293045043945, average time over last 10 steps = 0.8159979104995727\n",
            "step 3940, validation loss: 4.988332748413086, average time over last 10 steps = 0.8182296276092529\n",
            "step 3950, validation loss: 4.954158782958984, average time over last 10 steps = 0.8191774129867554\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m you\u001b[0m\u001b[43m must\u001b[0m\u001b[44m,\u001b[0m\u001b[41m do\u001b[0m\u001b[42m not\u001b[0m\u001b[43m agree\u001b[0m\u001b[44m to\u001b[0m\u001b[41m the\u001b[0m\u001b[42m terms\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m United\u001b[0m\u001b[42m States\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 3960, validation loss: 4.957050323486328, average time over last 10 steps = 0.8328772068023682\n",
            "step 3970, validation loss: 4.95144510269165, average time over last 10 steps = 0.8173146724700928\n",
            "step 3980, validation loss: 4.9828715324401855, average time over last 10 steps = 0.8176223754882812\n",
            "step 3990, validation loss: 5.005643844604492, average time over last 10 steps = 0.816858172416687\n",
            "step 4000, validation loss: 4.941884517669678, average time over last 10 steps = 0.8174205541610717\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m accordance\u001b[0m\u001b[42m with\u001b[0m\u001b[43m the\u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m in\u001b[0m\u001b[42m accordance\u001b[0m\u001b[43m with\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4010, validation loss: 4.971771240234375, average time over last 10 steps = 0.8318655252456665\n",
            "step 4020, validation loss: 5.072455883026123, average time over last 10 steps = 0.817380404472351\n",
            "step 4030, validation loss: 5.079419136047363, average time over last 10 steps = 0.8181536674499512\n",
            "step 4040, validation loss: 5.112264633178711, average time over last 10 steps = 0.81868417263031\n",
            "step 4050, validation loss: 5.117144584655762, average time over last 10 steps = 0.8185133695602417\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m any\u001b[0m\u001b[43m of\u001b[0m\u001b[44m the\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m including\u001b[0m\u001b[44m legal\u001b[0m\u001b[41m fees\u001b[0m\u001b[42m to\u001b[0m\u001b[43m and\u001b[0m\u001b[44m (\u001b[0m\u001b[41mnon\u001b[0m\u001b[42m-US\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4060, validation loss: 5.124337196350098, average time over last 10 steps = 0.8341306924819947\n",
            "step 4070, validation loss: 5.137903213500977, average time over last 10 steps = 0.8169549703598022\n",
            "step 4080, validation loss: 5.128199577331543, average time over last 10 steps = 0.8164456605911254\n",
            "step 4090, validation loss: 5.045633316040039, average time over last 10 steps = 0.8170602083206177\n",
            "step 4100, validation loss: 5.256174087524414, average time over last 10 steps = 0.8141196489334106\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m20\u001b[0m\u001b[44m67\u001b[0m\u001b[41m67\u001b[0m\u001b[42m67\u001b[0m\u001b[43m \u001b[0m\u001b[44m30\u001b[0m\u001b[41m00\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m \u001b[0m\u001b[42m50\u001b[0m\u001b[43m50\u001b[0m\u001b[44m49\u001b[0m\u001b[41m49\u001b[0m\u001b[42m49\u001b[0m\u001b[43m \u001b[0m\u001b[44m12\u001b[0m\u001b[41m59\u001b[0m\u001b[42m49\u001b[0m\u001b[43m49\u001b[0m\u001b[44m49\u001b[0m\u001b[41m \u001b[0m\u001b[42m12\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4110, validation loss: 5.451045036315918, average time over last 10 steps = 0.8312833786010743\n",
            "step 4120, validation loss: 5.601281642913818, average time over last 10 steps = 0.8100386619567871\n",
            "step 4130, validation loss: 5.668724536895752, average time over last 10 steps = 0.8128432035446167\n",
            "step 4140, validation loss: 5.701027870178223, average time over last 10 steps = 0.8109819650650024\n",
            "step 4150, validation loss: 5.710933208465576, average time over last 10 steps = 0.811535382270813\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m20\u001b[0m\u001b[44m67\u001b[0m\u001b[41m67\u001b[0m\u001b[42m67\u001b[0m\u001b[43m \u001b[0m\u001b[44m20\u001b[0m\u001b[41m67\u001b[0m\u001b[42m67\u001b[0m\u001b[43m67\u001b[0m\u001b[44m67\u001b[0m\u001b[41m \u001b[0m\u001b[42m20\u001b[0m\u001b[43m20\u001b[0m\u001b[44m20\u001b[0m\u001b[41m20\u001b[0m\u001b[42m67\u001b[0m\u001b[43m \u001b[0m\u001b[44m17\u001b[0m\u001b[41m17\u001b[0m\u001b[42m17\u001b[0m\u001b[43m17\u001b[0m\u001b[44m17\u001b[0m\u001b[41m \u001b[0m\u001b[42m17\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4160, validation loss: 5.715185165405273, average time over last 10 steps = 0.8260100364685059\n",
            "step 4170, validation loss: 5.725979328155518, average time over last 10 steps = 0.8129620313644409\n",
            "step 4180, validation loss: 5.300201892852783, average time over last 10 steps = 0.8138370037078857\n",
            "step 4190, validation loss: 5.140252590179443, average time over last 10 steps = 0.8182390451431274\n",
            "step 4200, validation loss: 5.010202884674072, average time over last 10 steps = 0.8227951526641846\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m,\u001b[0m\u001b[43m you\u001b[0m\u001b[44m must\u001b[0m\u001b[41m,\u001b[0m\u001b[42m you\u001b[0m\u001b[43m must\u001b[0m\u001b[44m,\u001b[0m\u001b[41m if\u001b[0m\u001b[42m you\u001b[0m\u001b[43m are\u001b[0m\u001b[44m located\u001b[0m\u001b[41m before\u001b[0m\u001b[42m using\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4210, validation loss: 5.018918037414551, average time over last 10 steps = 0.8333924770355224\n",
            "step 4220, validation loss: 5.00636100769043, average time over last 10 steps = 0.8209997415542603\n",
            "step 4230, validation loss: 4.974940299987793, average time over last 10 steps = 0.8197835445404053\n",
            "step 4240, validation loss: 4.9901580810546875, average time over last 10 steps = 0.8167455434799195\n",
            "step 4250, validation loss: 4.928256511688232, average time over last 10 steps = 0.8171699285507202\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4260, validation loss: 4.953821659088135, average time over last 10 steps = 0.8349521875381469\n",
            "step 4270, validation loss: 4.929906368255615, average time over last 10 steps = 0.8162991523742675\n",
            "step 4280, validation loss: 5.01629638671875, average time over last 10 steps = 0.813915467262268\n",
            "step 4290, validation loss: 5.5127410888671875, average time over last 10 steps = 0.810203242301941\n",
            "step 4300, validation loss: 5.862133979797363, average time over last 10 steps = 0.8114214420318604\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m \u001b[0m\u001b[43m43\u001b[0m\u001b[44m43\u001b[0m\u001b[41m \u001b[0m\u001b[42m43\u001b[0m\u001b[43m43\u001b[0m\u001b[44m \u001b[0m\u001b[41m47\u001b[0m\u001b[42m47\u001b[0m\u001b[43m \u001b[0m\u001b[44m43\u001b[0m\u001b[41m43\u001b[0m\u001b[42m \u001b[0m\u001b[43m43\u001b[0m\u001b[44m43\u001b[0m\u001b[41m \u001b[0m\u001b[42m43\u001b[0m\u001b[43m \u001b[0m\u001b[44m43\u001b[0m\u001b[41m \u001b[0m\u001b[42m43\u001b[0m\u001b[43m43\u001b[0m\u001b[44m \u001b[0m\u001b[41m43\u001b[0m\u001b[42m43\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4310, validation loss: 6.207114219665527, average time over last 10 steps = 0.8241227149963379\n",
            "step 4320, validation loss: 5.64212703704834, average time over last 10 steps = 0.8142355918884278\n",
            "step 4330, validation loss: 5.289117336273193, average time over last 10 steps = 0.8179103612899781\n",
            "step 4340, validation loss: 5.204453945159912, average time over last 10 steps = 0.8191351175308228\n",
            "step 4350, validation loss: 5.053005218505859, average time over last 10 steps = 0.8162766933441162\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m terms\u001b[0m\u001b[43m of\u001b[0m\u001b[44m this\u001b[0m\u001b[41m work\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m work\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m any\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4360, validation loss: 5.103891372680664, average time over last 10 steps = 0.8282131671905517\n",
            "step 4370, validation loss: 5.109236717224121, average time over last 10 steps = 0.8098062753677369\n",
            "step 4380, validation loss: 5.037840843200684, average time over last 10 steps = 0.8191206216812134\n",
            "step 4390, validation loss: 4.9526262283325195, average time over last 10 steps = 0.8187635898590088\n",
            "step 4400, validation loss: 4.983442306518555, average time over last 10 steps = 0.816330099105835\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m in\u001b[0m\u001b[41m the\u001b[0m\u001b[42m United\u001b[0m\u001b[43m States\u001b[0m\u001b[44m.\u001b[0m\u001b[41m Project\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m™\u001b[0m\u001b[44m electronic\u001b[0m\u001b[41m works\u001b[0m\u001b[42m in\u001b[0m\u001b[43m the\u001b[0m\u001b[44m United\u001b[0m\u001b[41m States\u001b[0m\u001b[42m.\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4410, validation loss: 5.012979507446289, average time over last 10 steps = 0.8332478284835816\n",
            "step 4420, validation loss: 5.037189483642578, average time over last 10 steps = 0.8187083005905151\n",
            "step 4430, validation loss: 5.148440361022949, average time over last 10 steps = 0.8160221815109253\n",
            "step 4440, validation loss: 5.005144119262695, average time over last 10 steps = 0.8189987182617188\n",
            "step 4450, validation loss: 4.990790843963623, average time over last 10 steps = 0.8209697723388671\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m,\u001b[0m\u001b[41m in\u001b[0m\u001b[42m the\u001b[0m\u001b[43m United\u001b[0m\u001b[44m States\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4460, validation loss: 4.948293685913086, average time over last 10 steps = 0.832893681526184\n",
            "step 4470, validation loss: 4.986748218536377, average time over last 10 steps = 0.8197884559631348\n",
            "step 4480, validation loss: 5.138838291168213, average time over last 10 steps = 0.8204572439193726\n",
            "step 4490, validation loss: 5.175476551055908, average time over last 10 steps = 0.8180638074874877\n",
            "step 4500, validation loss: 5.15285587310791, average time over last 10 steps = 0.819834566116333\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m \u001b[0m\u001b[44m Project\u001b[0m\u001b[41m Gutenberg\u001b[0m\u001b[42m™\u001b[0m\u001b[43m electronic\u001b[0m\u001b[44m works\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m \u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m \u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4510, validation loss: 5.103106498718262, average time over last 10 steps = 0.8367667436599732\n",
            "step 4520, validation loss: 5.065990447998047, average time over last 10 steps = 0.8168182611465454\n",
            "step 4530, validation loss: 5.035915374755859, average time over last 10 steps = 0.8176807880401611\n",
            "step 4540, validation loss: 5.015637397766113, average time over last 10 steps = 0.8176611661911011\n",
            "step 4550, validation loss: 4.961582660675049, average time over last 10 steps = 0.8209359645843506\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m If\u001b[0m\u001b[43m you\u001b[0m\u001b[44m do\u001b[0m\u001b[41m not\u001b[0m\u001b[42m agree\u001b[0m\u001b[43m to\u001b[0m\u001b[44m,\u001b[0m\u001b[41m you\u001b[0m\u001b[42m must\u001b[0m\u001b[43m,\u001b[0m\u001b[44m do\u001b[0m\u001b[41m not\u001b[0m\u001b[42m agree\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4560, validation loss: 4.976654529571533, average time over last 10 steps = 0.8342585802078247\n",
            "step 4570, validation loss: 4.978618621826172, average time over last 10 steps = 0.8192708969116211\n",
            "step 4580, validation loss: 4.943048477172852, average time over last 10 steps = 0.8203904390335083\n",
            "step 4590, validation loss: 4.973529815673828, average time over last 10 steps = 0.8178879261016846\n",
            "step 4600, validation loss: 4.971278667449951, average time over last 10 steps = 0.820944857597351\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.E\u001b[0m\u001b[41m.\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4610, validation loss: 4.973095893859863, average time over last 10 steps = 0.8314060211181641\n",
            "step 4620, validation loss: 4.953221321105957, average time over last 10 steps = 0.8171254873275757\n",
            "step 4630, validation loss: 4.927063941955566, average time over last 10 steps = 0.8190541982650756\n",
            "step 4640, validation loss: 5.032873153686523, average time over last 10 steps = 0.8175575971603394\n",
            "step 4650, validation loss: 5.091490268707275, average time over last 10 steps = 0.8169324159622192\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4660, validation loss: 5.119013786315918, average time over last 10 steps = 0.8324687957763672\n",
            "step 4670, validation loss: 5.133035659790039, average time over last 10 steps = 0.817126202583313\n",
            "step 4680, validation loss: 5.142886161804199, average time over last 10 steps = 0.81753089427948\n",
            "step 4690, validation loss: 5.1605682373046875, average time over last 10 steps = 0.81829993724823\n",
            "step 4700, validation loss: 5.179582118988037, average time over last 10 steps = 0.8172440767288208\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m electronic\u001b[0m\u001b[43m works\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.E\u001b[0m\u001b[43m.\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m electronic\u001b[0m\u001b[42m work\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m any\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m™\u001b[0m\u001b[41m License\u001b[0m\u001b[42m must\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4710, validation loss: 5.219923973083496, average time over last 10 steps = 0.8335327863693237\n",
            "step 4720, validation loss: 5.277814865112305, average time over last 10 steps = 0.8176703929901123\n",
            "step 4730, validation loss: 5.388391017913818, average time over last 10 steps = 0.8167015552520752\n",
            "step 4740, validation loss: 5.418181419372559, average time over last 10 steps = 0.8168662786483765\n",
            "step 4750, validation loss: 5.439157485961914, average time over last 10 steps = 0.8193769216537475\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.\u001b[0m\u001b[42m00\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m   \u001b[0m\u001b[43m \u001b[0m\u001b[44m4\u001b[0m\u001b[41m%\u001b[0m\u001b[42m Est\u001b[0m\u001b[43m.\u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m93\u001b[0m\u001b[43m  \u001b[0m\u001b[44m \u001b[0m\u001b[41m19\u001b[0m\u001b[42m.\u001b[0m\u001b[43m00\u001b[0m\u001b[44m00\u001b[0m\u001b[41m00\u001b[0m\u001b[42m   \u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4760, validation loss: 5.422653675079346, average time over last 10 steps = 0.8405360221862793\n",
            "step 4770, validation loss: 5.175199508666992, average time over last 10 steps = 0.817507529258728\n",
            "step 4780, validation loss: 5.69397497177124, average time over last 10 steps = 0.8205554246902466\n",
            "step 4790, validation loss: 5.780699253082275, average time over last 10 steps = 0.8147503852844238\n",
            "step 4800, validation loss: 5.815398216247559, average time over last 10 steps = 0.8173633575439453\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m84\u001b[0m\u001b[41m11\u001b[0m\u001b[42m.\u001b[0m\u001b[43m10\u001b[0m\u001b[44m.\u001b[0m\u001b[41m00\u001b[0m\u001b[42m A\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m84\u001b[0m\u001b[41m12\u001b[0m\u001b[42m.\u001b[0m\u001b[43m10\u001b[0m\u001b[44m.\u001b[0m\u001b[41m00\u001b[0m\u001b[42m A\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m84\u001b[0m\u001b[41m84\u001b[0m\u001b[42m.\u001b[0m\u001b[43m90\u001b[0m\u001b[44m.\u001b[0m\u001b[41m00\u001b[0m\u001b[42m A\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4810, validation loss: 5.0774993896484375, average time over last 10 steps = 0.8319115161895752\n",
            "step 4820, validation loss: 5.0291972160339355, average time over last 10 steps = 0.8166697978973388\n",
            "step 4830, validation loss: 5.023346900939941, average time over last 10 steps = 0.8176826000213623\n",
            "step 4840, validation loss: 4.5386271476745605, average time over last 10 steps = 0.8174148321151733\n",
            "step 4850, validation loss: 4.7116193771362305, average time over last 10 steps = 0.8174466609954834\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m Project\u001b[0m\u001b[44m Gutenberg\u001b[0m\u001b[41m™\u001b[0m\u001b[42m License\u001b[0m\u001b[43m included\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m1\u001b[0m\u001b[41m.E\u001b[0m\u001b[42m.\u001b[0m\u001b[43m1\u001b[0m\u001b[44m.\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m1\u001b[0m\u001b[43m.E\u001b[0m\u001b[44m.\u001b[0m\u001b[41m1\u001b[0m\u001b[42m.\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4860, validation loss: 4.950217247009277, average time over last 10 steps = 0.8309845924377441\n",
            "step 4870, validation loss: 4.973875045776367, average time over last 10 steps = 0.8175827503204346\n",
            "step 4880, validation loss: 5.075793266296387, average time over last 10 steps = 0.8171236038208007\n",
            "step 4890, validation loss: 5.048326015472412, average time over last 10 steps = 0.8171704530715942\n",
            "step 4900, validation loss: 5.045876979827881, average time over last 10 steps = 0.8192315816879272\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m God\u001b[0m\u001b[43m of\u001b[0m\u001b[44m Israel\u001b[0m\u001b[41m,\u001b[0m\u001b[42m the\u001b[0m\u001b[43m children\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m the\u001b[0m\u001b[44m children\u001b[0m\u001b[41m of\u001b[0m\u001b[42m Israel\u001b[0m\u001b[43m,\u001b[0m\u001b[44m the\u001b[0m\u001b[41m children\u001b[0m\u001b[42m of\u001b[0m\u001b[43m Israel\u001b[0m\u001b[44m,\u001b[0m\u001b[41m the\u001b[0m\u001b[42m children\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4910, validation loss: 5.061458587646484, average time over last 10 steps = 0.8338188886642456\n",
            "step 4920, validation loss: 5.147325038909912, average time over last 10 steps = 0.816918921470642\n",
            "step 4930, validation loss: 5.184009552001953, average time over last 10 steps = 0.8186743974685669\n",
            "step 4940, validation loss: 5.1301164627075195, average time over last 10 steps = 0.8186764717102051\n",
            "step 4950, validation loss: 5.154748916625977, average time over last 10 steps = 0.8170047998428345\n",
            "\u001b[41mThe\u001b[0m\u001b[42m Project\u001b[0m\u001b[43m Gutenberg\u001b[0m\u001b[44m eBook\u001b[0m\u001b[41m of\u001b[0m\u001b[42m the\u001b[0m\u001b[43m LORD\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m God\u001b[0m\u001b[44m of\u001b[0m\u001b[41m Israel\u001b[0m\u001b[42m,\u001b[0m\u001b[43m and\u001b[0m\u001b[44m the\u001b[0m\u001b[41m people\u001b[0m\u001b[42m of\u001b[0m\u001b[43m Israel\u001b[0m\u001b[44m,\u001b[0m\u001b[41m and\u001b[0m\u001b[42m the\u001b[0m\u001b[43m people\u001b[0m\u001b[44m of\u001b[0m\u001b[41m the\u001b[0m\u001b[42m LORD\u001b[0m\u001b[43m,\u001b[0m\u001b[44m and\u001b[0m\u001b[41m the\u001b[0m\u001b[42m people\u001b[0m\n",
            "Allocated: 5.15 GB\n",
            "Cached: 12.61 GB\n",
            "\n",
            "step 4960, validation loss: 5.146257400512695, average time over last 10 steps = 0.8341023921966553\n",
            "step 4970, validation loss: 5.079036712646484, average time over last 10 steps = 0.8182807683944702\n",
            "step 4980, validation loss: 4.822497367858887, average time over last 10 steps = 0.8193175077438355\n",
            "step 4990, validation loss: 4.666287422180176, average time over last 10 steps = 0.8182462453842163\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# test if this makes it faster --> No\n",
        "# torch.backends.cudnn.conv.fp32_precision = 'tf32'\n",
        "# torch.backends.cuda.matmul.fp32_precision = 'ieee'\n",
        "\n",
        "def training_loop(iter=500):\n",
        "\n",
        "  # validation set\n",
        "  sample = enc.encode(\"The Project Gutenberg eBook of\")\n",
        "  buf = torch.tensor(sample)\n",
        "  x_sample_base = buf.view(1, -1)\n",
        "  x_sample_base = x_sample_base.to(device_type)\n",
        "\n",
        "  # train\n",
        "  t0 = time.time()\n",
        "  for i in range(iter):\n",
        "    optimizer.zero_grad()\n",
        "    x, y = load_next_batch()\n",
        "    x = x.to(device_type)\n",
        "    y = y.to(device_type)\n",
        "\n",
        "    with autocast_ctx:\n",
        "        loss = gpt(x, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 10 == 0:\n",
        "        t1 = time.time()\n",
        "        gpt.eval()\n",
        "        with autocast_ctx:\n",
        "          val_loss = gpt(x_val, y_val)\n",
        "        gpt.train()\n",
        "\n",
        "        print(f\"step {i}, validation loss: {val_loss.item()}, loss: {loss} average time over last 10 steps = {(t1-t0)/10}\")\n",
        "        t0 = t1\n",
        "\n",
        "        if i%100 == 0:\n",
        "\n",
        "            gpt.eval()\n",
        "            x_sample = x_sample_base\n",
        "            for _ in range(25):\n",
        "                with torch.no_grad(): # Good practice for inference to save memory\n",
        "                    with autocast_ctx:\n",
        "                        op = gpt(x_sample)\n",
        "                    op = op[:,-1,:]\n",
        "\n",
        "                    next_ids = torch.argmax(op, dim=-1, keepdim=True)\n",
        "                    x_sample = torch.cat((x_sample, next_ids), dim=1)\n",
        "                    next_token = next_ids.item()\n",
        "                    # print(f\"{enc.decode([next_token])}\", end = \"\")\n",
        "                    # print(\"\\n\", x_sample.shape)\n",
        "            tiktokenize_tokens(x_sample[0])\n",
        "            gpt.train()\n",
        "\n",
        "            get_gpu_stats()\n",
        "\n",
        "\n",
        "training_loop(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "xBqtyUh4cOjT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBqtyUh4cOjT",
        "outputId": "6984965b-54e6-4b66-c879-b11bf2c3abd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\u001b[42m\u0000\u001b[0m\u001b[43m\u0000\u001b[0m\u001b[44m\u0000\u001b[0m\u001b[41m\u0000\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def test_model_generations(sample_text = \"The Project Gutenberg eBook of\", len_gen = 10):\n",
        "  sample = enc.encode(sample_text)\n",
        "  buf = torch.tensor(sample)\n",
        "  sample = buf.view(1, -1).to(device_type)\n",
        "\n",
        "  for _ in range(len_gen):\n",
        "    with torch.no_grad(): # Good practice for inference to save memory\n",
        "        with autocast_ctx:\n",
        "            op = gpt(sample)\n",
        "        op = op[:,-1,:]\n",
        "\n",
        "        next_ids = torch.argmax(op, dim=-1, keepdim=True)\n",
        "        sample = torch.cat((sample, next_ids), dim=1)\n",
        "        next_token = next_ids.item()\n",
        "  tiktokenize_tokens(sample[0])\n",
        "  print()\n",
        "\n",
        "test_model_generations(sample_text=\"Project Gutenberg is\", len_gen=25)\n",
        "test_model_generations(sample_text=\"He was the main\", len_gen=50)\n",
        "test_model_generations(sample_text=\"The place is well known for its\", len_gen=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "-mzeMcq1erd-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mzeMcq1erd-",
        "outputId": "ce834d24-54e3-4ac8-bf0b-56462809438d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52428800 0\n"
          ]
        }
      ],
      "source": [
        "print(len(text), start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "WUWTMC2YmUSN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUWTMC2YmUSN",
        "outputId": "197435d5-7979-4d44-be28-0d8e556a9f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "u6rnII2ep85M",
      "metadata": {
        "id": "u6rnII2ep85M"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the filename with timestamp\n",
        "filename = f\"gpt_weights_{timestamp}.pth\"\n",
        "\n",
        "# save gpt model weights to drive\n",
        "torch.save(gpt.state_dict(), f'/content/drive/MyDrive/{filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbV3d4hIcbjt",
      "metadata": {
        "id": "bbV3d4hIcbjt"
      },
      "source": [
        "## Multi optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ejIzoLez2rrT",
      "metadata": {
        "id": "ejIzoLez2rrT"
      },
      "outputs": [],
      "source": [
        "embedding_lr = 0.2 # learning rate for the embedding parameters (Adam)\n",
        "unembedding_lr = 0.004 # learning rate for the unembedding parameters (Adam)\n",
        "weight_decay = 0.0 # weight decay for the embedding/unembedding parameters (Adam)\n",
        "matrix_lr = 0.02 # learning rate for the matrix parameters (Muon) - Muon needs different LR scaling than Adam\n",
        "\n",
        "grad_clip = 1.0 # gradient clipping value (0.0 = disabled): prevents gradient explosions\n",
        "warmup_ratio = 0.0 # ratio of iterations for LR warmup: start slow then ramp up\n",
        "warmdown_ratio = 0.2 # ratio of iterations for LR warmdown: cosine decay at the end\n",
        "final_lr_frac = 0.0 # final LR is this fraction of the initial LR\n",
        "resume_from_step = -1 # resume training from this step of the optimization (-1 = disable)\n",
        "num_iterations = 10000 # explicit number of steps of the optimization (-1 = disable)\n",
        "\n",
        "# Learning rate scheduler (Warmup -> Constant -> Warmdown/Cos Decay)\n",
        "def get_lr_multiplier(it):\n",
        "    warmup_iters = round(warmup_ratio * num_iterations)\n",
        "    warmdown_iters = round(warmdown_ratio * num_iterations)\n",
        "    if it < warmup_iters:\n",
        "        return (it + 1) / warmup_iters\n",
        "    elif it <= num_iterations - warmdown_iters:\n",
        "        return 1.0\n",
        "    else:\n",
        "        progress = (num_iterations - it) / warmdown_iters\n",
        "        return progress * 1.0 + (1 - progress) * final_lr_frac\n",
        "\n",
        "\n",
        "def get_muon_momentum(it):\n",
        "    frac = min(it / 300, 1)\n",
        "    momentum = (1 - frac) * 0.85 + frac * 0.95\n",
        "    return momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "ptOvqBMB2roe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptOvqBMB2roe",
        "outputId": "d4691262-8c28-4354-e1de-4deae03b5f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0, validation loss: 17.582365036010742, loss: 17.37175178527832 average time over last 10 steps = 0.08408477306365966\n",
            "Allocated: 6.82 GB\n",
            "Cached: 11.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 10, validation loss: 17.541671752929688, loss: 18.423965454101562 average time over last 10 steps = 0.9741799354553222\n",
            "step 20, validation loss: 17.39910125732422, loss: 17.971744537353516 average time over last 10 steps = 0.8357672452926636\n",
            "step 30, validation loss: 17.340587615966797, loss: 17.702272415161133 average time over last 10 steps = 0.858755373954773\n",
            "step 40, validation loss: 17.257001876831055, loss: 17.313095092773438 average time over last 10 steps = 0.852777624130249\n",
            "step 50, validation loss: 17.221885681152344, loss: 17.515886306762695 average time over last 10 steps = 0.8503881931304932\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 60, validation loss: 17.150001525878906, loss: 18.404415130615234 average time over last 10 steps = 0.9122424602508545\n",
            "step 70, validation loss: 17.073097229003906, loss: 17.782983779907227 average time over last 10 steps = 0.8447561264038086\n",
            "step 80, validation loss: 16.989233016967773, loss: 16.647172927856445 average time over last 10 steps = 0.8461983919143676\n",
            "step 90, validation loss: 16.856163024902344, loss: 17.27655792236328 average time over last 10 steps = 0.8500261783599854\n",
            "step 100, validation loss: 16.82102394104004, loss: 17.484758377075195 average time over last 10 steps = 0.8549765825271607\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 110, validation loss: 16.769092559814453, loss: 16.941545486450195 average time over last 10 steps = 0.9223552227020264\n",
            "step 120, validation loss: 16.711631774902344, loss: 16.933921813964844 average time over last 10 steps = 0.8623121500015258\n",
            "step 130, validation loss: 16.730247497558594, loss: 16.600872039794922 average time over last 10 steps = 0.8657533407211304\n",
            "step 140, validation loss: 16.708751678466797, loss: 16.57734489440918 average time over last 10 steps = 0.8651787281036377\n",
            "step 150, validation loss: 16.65511703491211, loss: 16.49407196044922 average time over last 10 steps = 0.8659832239151001\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 160, validation loss: 16.559146881103516, loss: 16.428939819335938 average time over last 10 steps = 0.9363703250885009\n",
            "step 170, validation loss: 16.563583374023438, loss: 19.166048049926758 average time over last 10 steps = 0.8721149444580079\n",
            "step 180, validation loss: 16.545974731445312, loss: 16.84322738647461 average time over last 10 steps = 0.8844343662261963\n",
            "step 190, validation loss: 16.49286651611328, loss: 16.423341751098633 average time over last 10 steps = 0.8883223533630371\n",
            "step 200, validation loss: 16.462615966796875, loss: 15.920412063598633 average time over last 10 steps = 0.8890741348266602\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 210, validation loss: 16.45170783996582, loss: 15.909135818481445 average time over last 10 steps = 0.9679719924926757\n",
            "step 220, validation loss: 16.438886642456055, loss: 15.966594696044922 average time over last 10 steps = 0.8816825866699218\n",
            "step 230, validation loss: 16.426761627197266, loss: 17.002260208129883 average time over last 10 steps = 0.880132508277893\n",
            "step 240, validation loss: 16.444656372070312, loss: 16.838666915893555 average time over last 10 steps = 0.8782694339752197\n",
            "step 250, validation loss: 16.39065933227539, loss: 16.442214965820312 average time over last 10 steps = 0.8793081283569336\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 260, validation loss: 16.403980255126953, loss: 17.237964630126953 average time over last 10 steps = 0.9441309928894043\n",
            "step 270, validation loss: 16.347124099731445, loss: 16.087690353393555 average time over last 10 steps = 0.881915807723999\n",
            "step 280, validation loss: 16.302345275878906, loss: 16.091907501220703 average time over last 10 steps = 0.8850342035293579\n",
            "step 290, validation loss: 16.28191375732422, loss: 15.7073974609375 average time over last 10 steps = 0.884350848197937\n",
            "step 300, validation loss: 16.271167755126953, loss: 16.385969161987305 average time over last 10 steps = 0.8849852800369262\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 310, validation loss: 16.279932022094727, loss: 15.732316970825195 average time over last 10 steps = 0.9469756603240966\n",
            "step 320, validation loss: 16.235675811767578, loss: 15.917119979858398 average time over last 10 steps = 0.8833413362503052\n",
            "step 330, validation loss: 16.210796356201172, loss: 16.054058074951172 average time over last 10 steps = 0.881732726097107\n",
            "step 340, validation loss: 16.199064254760742, loss: 16.10508155822754 average time over last 10 steps = 0.880367636680603\n",
            "step 350, validation loss: 16.185157775878906, loss: 16.90439224243164 average time over last 10 steps = 0.8804081201553344\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 360, validation loss: 16.113483428955078, loss: 16.069164276123047 average time over last 10 steps = 0.9611503839492798\n",
            "step 370, validation loss: 16.00651741027832, loss: 16.70330238342285 average time over last 10 steps = 0.8814153432846069\n",
            "step 380, validation loss: 16.001028060913086, loss: 16.343215942382812 average time over last 10 steps = 0.8825724363327027\n",
            "step 390, validation loss: 15.987231254577637, loss: 15.53432846069336 average time over last 10 steps = 0.8819415330886841\n",
            "step 400, validation loss: 16.02185821533203, loss: 16.38301658630371 average time over last 10 steps = 0.8813150882720947\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 410, validation loss: 16.011341094970703, loss: 16.286602020263672 average time over last 10 steps = 0.9456736803054809\n",
            "step 420, validation loss: 16.001100540161133, loss: 16.63016128540039 average time over last 10 steps = 0.8820767879486084\n",
            "step 430, validation loss: 15.98093032836914, loss: 15.902884483337402 average time over last 10 steps = 0.8809980154037476\n",
            "step 440, validation loss: 16.006805419921875, loss: 16.128379821777344 average time over last 10 steps = 0.8805111885070801\n",
            "step 450, validation loss: 16.025697708129883, loss: 16.000816345214844 average time over last 10 steps = 0.8814717292785644\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 460, validation loss: 15.99821662902832, loss: 15.855340003967285 average time over last 10 steps = 0.945544695854187\n",
            "step 470, validation loss: 15.989570617675781, loss: 16.06743621826172 average time over last 10 steps = 0.8802817821502685\n",
            "step 480, validation loss: 16.00421142578125, loss: 15.995813369750977 average time over last 10 steps = 0.884427547454834\n",
            "step 490, validation loss: 15.917110443115234, loss: 16.06722640991211 average time over last 10 steps = 0.8839469432830811\n",
            "step 500, validation loss: 15.885492324829102, loss: 15.483945846557617 average time over last 10 steps = 0.8859121561050415\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 510, validation loss: 15.891965866088867, loss: 15.705511093139648 average time over last 10 steps = 0.9511791706085205\n",
            "step 520, validation loss: 15.864767074584961, loss: 15.749067306518555 average time over last 10 steps = 0.8846396923065185\n",
            "step 530, validation loss: 15.868173599243164, loss: 15.698932647705078 average time over last 10 steps = 0.8849377632141113\n",
            "step 540, validation loss: 15.882381439208984, loss: 15.288233757019043 average time over last 10 steps = 0.8864924192428589\n",
            "step 550, validation loss: 15.892528533935547, loss: 16.150238037109375 average time over last 10 steps = 0.8868508815765381\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 560, validation loss: 15.87460708618164, loss: 15.692938804626465 average time over last 10 steps = 0.9713543891906739\n",
            "step 570, validation loss: 15.858816146850586, loss: 15.954665184020996 average time over last 10 steps = 0.8862983465194703\n",
            "step 580, validation loss: 15.837568283081055, loss: 15.704870223999023 average time over last 10 steps = 0.8877038717269897\n",
            "step 590, validation loss: 15.838642120361328, loss: 15.565256118774414 average time over last 10 steps = 0.8881003618240356\n",
            "step 600, validation loss: 15.829551696777344, loss: 15.421521186828613 average time over last 10 steps = 0.8876099348068237\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 610, validation loss: 15.8140869140625, loss: 15.37579345703125 average time over last 10 steps = 0.9543458700180054\n",
            "step 620, validation loss: 15.809074401855469, loss: 15.948707580566406 average time over last 10 steps = 0.8880604028701782\n",
            "step 630, validation loss: 15.796613693237305, loss: 15.599760055541992 average time over last 10 steps = 0.8874159812927246\n",
            "step 640, validation loss: 15.814803123474121, loss: 14.955890655517578 average time over last 10 steps = 0.8884922742843628\n",
            "step 650, validation loss: 15.804977416992188, loss: 15.51655101776123 average time over last 10 steps = 0.8882872343063355\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 660, validation loss: 15.871726989746094, loss: 15.460623741149902 average time over last 10 steps = 0.9509905576705933\n",
            "step 670, validation loss: 15.860997200012207, loss: 15.742668151855469 average time over last 10 steps = 0.8845791101455689\n",
            "step 680, validation loss: 15.874975204467773, loss: 15.732762336730957 average time over last 10 steps = 0.8839327335357666\n",
            "step 690, validation loss: 15.865220069885254, loss: 15.444042205810547 average time over last 10 steps = 0.8840421915054322\n",
            "step 700, validation loss: 15.820799827575684, loss: 16.440204620361328 average time over last 10 steps = 0.8841709136962891\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 710, validation loss: 15.857200622558594, loss: 16.424142837524414 average time over last 10 steps = 0.9662633895874023\n",
            "step 720, validation loss: 15.8654203414917, loss: 15.824562072753906 average time over last 10 steps = 0.8838629484176636\n",
            "step 730, validation loss: 15.906389236450195, loss: 15.526662826538086 average time over last 10 steps = 0.8833220481872559\n",
            "step 740, validation loss: 15.902582168579102, loss: 16.021141052246094 average time over last 10 steps = 0.8821544885635376\n",
            "step 750, validation loss: 15.875524520874023, loss: 15.571662902832031 average time over last 10 steps = 0.8827510356903077\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 760, validation loss: 15.795772552490234, loss: 15.691192626953125 average time over last 10 steps = 0.9469352483749389\n",
            "step 770, validation loss: 15.777114868164062, loss: 16.5965576171875 average time over last 10 steps = 0.8834088325500489\n",
            "step 780, validation loss: 15.799375534057617, loss: 15.760200500488281 average time over last 10 steps = 0.8847378969192505\n",
            "step 790, validation loss: 15.82082748413086, loss: 15.700922012329102 average time over last 10 steps = 0.8860079050064087\n",
            "step 800, validation loss: 15.825923919677734, loss: 16.623905181884766 average time over last 10 steps = 0.8868701696395874\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 810, validation loss: 15.830939292907715, loss: 15.77762222290039 average time over last 10 steps = 1.0371976852416993\n",
            "step 820, validation loss: 15.763084411621094, loss: 15.72922134399414 average time over last 10 steps = 0.8862548351287842\n",
            "step 830, validation loss: 15.699825286865234, loss: 17.24860191345215 average time over last 10 steps = 0.8861298561096191\n",
            "step 840, validation loss: 15.68376350402832, loss: 15.379312515258789 average time over last 10 steps = 0.8868298292160034\n",
            "step 850, validation loss: 15.664338111877441, loss: 16.001476287841797 average time over last 10 steps = 0.8856707572937011\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 860, validation loss: 15.666261672973633, loss: 15.523725509643555 average time over last 10 steps = 0.9714301586151123\n",
            "step 870, validation loss: 15.666816711425781, loss: 15.138639450073242 average time over last 10 steps = 0.8840867519378662\n",
            "step 880, validation loss: 15.70193099975586, loss: 15.96353816986084 average time over last 10 steps = 0.8854988574981689\n",
            "step 890, validation loss: 15.710578918457031, loss: 15.407572746276855 average time over last 10 steps = 0.8852950096130371\n",
            "step 900, validation loss: 15.723688125610352, loss: 15.573831558227539 average time over last 10 steps = 0.8847174167633056\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 910, validation loss: 15.735832214355469, loss: 15.051025390625 average time over last 10 steps = 0.9479258060455322\n",
            "step 920, validation loss: 15.743040084838867, loss: 15.613635063171387 average time over last 10 steps = 0.8856155633926391\n",
            "step 930, validation loss: 15.702461242675781, loss: 16.095754623413086 average time over last 10 steps = 0.8847346544265747\n",
            "step 940, validation loss: 15.71017074584961, loss: 15.023613929748535 average time over last 10 steps = 0.8853182077407837\n",
            "step 950, validation loss: 15.718082427978516, loss: 14.955766677856445 average time over last 10 steps = 0.8837073564529419\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 960, validation loss: 15.681520462036133, loss: 15.867730140686035 average time over last 10 steps = 0.9488271236419678\n",
            "step 970, validation loss: 15.656221389770508, loss: 15.40757942199707 average time over last 10 steps = 0.8851863384246826\n",
            "step 980, validation loss: 15.654718399047852, loss: 15.53757095336914 average time over last 10 steps = 0.8846033811569214\n",
            "step 990, validation loss: 15.628623008728027, loss: 15.954419136047363 average time over last 10 steps = 0.8843668222427368\n",
            "step 1000, validation loss: 15.640273094177246, loss: 14.847914695739746 average time over last 10 steps = 0.8851535081863403\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: check if compile helps?? --> Got stuck for 6 minutes. I ran out of patience and interrupted\n",
        "# @torch.compile\n",
        "def training_loop_multi_optimizer(iter = 10):\n",
        "\n",
        "  x_val, y_val = load_next_batch()\n",
        "  x_val = x_val.to(device_type)\n",
        "  y_val = y_val.to(device_type)\n",
        "\n",
        "\n",
        "  model = gpt\n",
        "\n",
        "  iter+=1\n",
        "  t0 = time.time()\n",
        "  for i in range(iter): # Use 'i' as the loop counter\n",
        "    model.zero_grad(set_to_none=True) # Zero gradients at the beginning of the current iteration\n",
        "\n",
        "    x, y = load_next_batch()\n",
        "    x = x.to(device_type)\n",
        "    y = y.to(device_type)\n",
        "\n",
        "    with autocast_ctx:\n",
        "      loss = model(x, y) # Forward pass\n",
        "\n",
        "    loss.backward() # Backward pass\n",
        "\n",
        "    # Calculate learning rate and momentum based on current iteration 'i'\n",
        "    lrm = get_lr_multiplier(i+500)\n",
        "\n",
        "    for opt in optimizers:\n",
        "        for group in opt.param_groups:\n",
        "            group[\"lr\"] = group[\"initial_lr\"] * lrm\n",
        "\n",
        "    muon_momentum = get_muon_momentum(i+500)\n",
        "\n",
        "    # print(f\"muon_momentum: {muon_momentum}, lrm: {lrm}\")\n",
        "\n",
        "    for group in muon_optimizer.param_groups:\n",
        "        group[\"momentum\"] = muon_momentum\n",
        "\n",
        "    for opt in optimizers:\n",
        "        opt.step() # Update weights\n",
        "\n",
        "\n",
        "    # print(f\"step {i}, loss: {loss.item()}\")\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        t1 = time.time()\n",
        "        gpt.eval()\n",
        "        with autocast_ctx:\n",
        "          val_loss = gpt(x_val, y_val)\n",
        "        gpt.train()\n",
        "\n",
        "        print(f\"step {i}, validation loss: {val_loss.item()}, loss: {loss} average time over last 10 steps = {(t1-t0)/10}\")\n",
        "        t0 = t1\n",
        "\n",
        "    if i%50 == 0:\n",
        "      get_gpu_stats()\n",
        "\n",
        "      test_model_generations(sample_text=\"Project Gutenberg is\", len_gen=25)\n",
        "      test_model_generations(sample_text=\"He was the main\", len_gen=50)\n",
        "      test_model_generations(sample_text=\"The place is well known for its\", len_gen=25)\n",
        "\n",
        "\n",
        "training_loop_multi_optimizer(1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "5BLkdD4VN-ha",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BLkdD4VN-ha",
        "outputId": "b606c178-81fc-4370-8329-969d7908bea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0, validation loss: 15.820544242858887, loss: 15.656527519226074 average time over last 10 steps = 0.08732683658599853\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 10, validation loss: 15.809656143188477, loss: 16.383056640625 average time over last 10 steps = 0.9393217086791992\n",
            "step 20, validation loss: 15.773734092712402, loss: 15.096031188964844 average time over last 10 steps = 0.8975648403167724\n",
            "step 30, validation loss: 15.745615005493164, loss: 15.123495101928711 average time over last 10 steps = 0.9163335084915161\n",
            "step 40, validation loss: 15.753057479858398, loss: 15.032844543457031 average time over last 10 steps = 0.9248510122299194\n",
            "step 50, validation loss: 15.740970611572266, loss: 15.783660888671875 average time over last 10 steps = 0.9051161289215088\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 60, validation loss: 15.721607208251953, loss: 15.559486389160156 average time over last 10 steps = 0.9562551736831665\n",
            "step 70, validation loss: 15.719392776489258, loss: 15.556296348571777 average time over last 10 steps = 0.879550838470459\n",
            "step 80, validation loss: 15.715141296386719, loss: 15.761935234069824 average time over last 10 steps = 0.8785582780838013\n",
            "step 90, validation loss: 15.670846939086914, loss: 15.378144264221191 average time over last 10 steps = 0.8770996809005738\n",
            "step 100, validation loss: 15.650825500488281, loss: 15.967522621154785 average time over last 10 steps = 0.8795880079269409\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 110, validation loss: 15.639299392700195, loss: 15.020383834838867 average time over last 10 steps = 0.9528529405593872\n",
            "step 120, validation loss: 15.59977912902832, loss: 15.117701530456543 average time over last 10 steps = 0.8922833919525146\n",
            "step 130, validation loss: 15.604879379272461, loss: 15.42683219909668 average time over last 10 steps = 0.8955920219421387\n",
            "step 140, validation loss: 15.545653343200684, loss: 14.818144798278809 average time over last 10 steps = 0.897844386100769\n",
            "step 150, validation loss: 15.467852592468262, loss: 15.823802947998047 average time over last 10 steps = 0.8961972951889038\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 160, validation loss: 15.42551040649414, loss: 15.201383590698242 average time over last 10 steps = 0.9587266921997071\n",
            "step 170, validation loss: 15.405052185058594, loss: 15.462018013000488 average time over last 10 steps = 0.8891302108764648\n",
            "step 180, validation loss: 15.391046524047852, loss: 15.006462097167969 average time over last 10 steps = 0.8872265815734863\n",
            "step 190, validation loss: 15.340764045715332, loss: 15.41067123413086 average time over last 10 steps = 0.8878725290298461\n",
            "step 200, validation loss: 15.26809024810791, loss: 15.117361068725586 average time over last 10 steps = 0.8884720802307129\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 210, validation loss: 15.21830940246582, loss: 15.191720962524414 average time over last 10 steps = 0.9577506303787231\n",
            "step 220, validation loss: 15.170028686523438, loss: 15.527626037597656 average time over last 10 steps = 0.8925834417343139\n",
            "step 230, validation loss: 15.167200088500977, loss: 14.806181907653809 average time over last 10 steps = 0.8926788806915283\n",
            "step 240, validation loss: 15.14793872833252, loss: 15.067901611328125 average time over last 10 steps = 0.8940468788146972\n",
            "step 250, validation loss: 15.13884162902832, loss: 14.39124870300293 average time over last 10 steps = 0.8941868305206299\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 260, validation loss: 15.111371040344238, loss: 15.182792663574219 average time over last 10 steps = 0.9592689990997314\n",
            "step 270, validation loss: 15.054435729980469, loss: 14.812275886535645 average time over last 10 steps = 0.8920434713363647\n",
            "step 280, validation loss: 15.059996604919434, loss: 15.03952407836914 average time over last 10 steps = 0.8926882028579712\n",
            "step 290, validation loss: 15.033939361572266, loss: 15.483213424682617 average time over last 10 steps = 0.8924046039581299\n",
            "step 300, validation loss: 15.00593090057373, loss: 14.786773681640625 average time over last 10 steps = 0.8914484500885009\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 310, validation loss: 14.981882095336914, loss: 14.519004821777344 average time over last 10 steps = 0.971523642539978\n",
            "step 320, validation loss: 14.945806503295898, loss: 14.500104904174805 average time over last 10 steps = 0.8906745672225952\n",
            "step 330, validation loss: 14.933401107788086, loss: 15.33708381652832 average time over last 10 steps = 0.8907021284103394\n",
            "step 340, validation loss: 14.917110443115234, loss: 15.49691390991211 average time over last 10 steps = 0.8901722431182861\n",
            "step 350, validation loss: 14.889254570007324, loss: 13.76709270477295 average time over last 10 steps = 0.8902195453643799\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 360, validation loss: 14.846784591674805, loss: 14.592509269714355 average time over last 10 steps = 0.955892539024353\n",
            "step 370, validation loss: 14.799737930297852, loss: 14.904848098754883 average time over last 10 steps = 0.8903556585311889\n",
            "step 380, validation loss: 14.71558952331543, loss: 14.264078140258789 average time over last 10 steps = 0.8902331590652466\n",
            "step 390, validation loss: 14.604949951171875, loss: 14.774343490600586 average time over last 10 steps = 0.8900474786758423\n",
            "step 400, validation loss: 14.503702163696289, loss: 14.847187995910645 average time over last 10 steps = 0.8899762868881226\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 410, validation loss: 14.461519241333008, loss: 14.721333503723145 average time over last 10 steps = 0.978152060508728\n",
            "step 420, validation loss: 14.332465171813965, loss: 14.596325874328613 average time over last 10 steps = 0.8912418842315674\n",
            "step 430, validation loss: 14.31951904296875, loss: 14.440929412841797 average time over last 10 steps = 0.891049575805664\n",
            "step 440, validation loss: 14.239654541015625, loss: 13.7255859375 average time over last 10 steps = 0.8911859273910523\n",
            "step 450, validation loss: 14.109127044677734, loss: 13.972167015075684 average time over last 10 steps = 0.8920423269271851\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 460, validation loss: 14.091601371765137, loss: 14.152460098266602 average time over last 10 steps = 0.9926310062408448\n",
            "step 470, validation loss: 14.038918495178223, loss: 13.953058242797852 average time over last 10 steps = 0.893633246421814\n",
            "step 480, validation loss: 13.996206283569336, loss: 13.871316909790039 average time over last 10 steps = 0.8940823316574097\n",
            "step 490, validation loss: 13.89576244354248, loss: 13.943229675292969 average time over last 10 steps = 0.8924768447875977\n",
            "step 500, validation loss: 13.848491668701172, loss: 14.96148681640625 average time over last 10 steps = 0.8943197727203369\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 510, validation loss: 13.797921180725098, loss: 14.28143310546875 average time over last 10 steps = 0.9573999881744385\n",
            "step 520, validation loss: 13.750000953674316, loss: 13.716917991638184 average time over last 10 steps = 0.8939892292022705\n",
            "step 530, validation loss: 13.663838386535645, loss: 14.19028091430664 average time over last 10 steps = 0.8942405223846436\n",
            "step 540, validation loss: 13.593963623046875, loss: 13.754430770874023 average time over last 10 steps = 0.8934374332427979\n",
            "step 550, validation loss: 13.565990447998047, loss: 14.046571731567383 average time over last 10 steps = 0.8925755500793457\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 560, validation loss: 13.460260391235352, loss: 12.923848152160645 average time over last 10 steps = 0.9577923774719238\n",
            "step 570, validation loss: 13.378625869750977, loss: 13.516809463500977 average time over last 10 steps = 0.8928818464279175\n",
            "step 580, validation loss: 13.339237213134766, loss: 12.670721054077148 average time over last 10 steps = 0.8917888402938843\n",
            "step 590, validation loss: 13.246416091918945, loss: 12.604409217834473 average time over last 10 steps = 0.8905788660049438\n",
            "step 600, validation loss: 13.16077995300293, loss: 12.765052795410156 average time over last 10 steps = 0.8909619092941284\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 610, validation loss: 13.101358413696289, loss: 12.862525939941406 average time over last 10 steps = 0.9744118213653564\n",
            "step 620, validation loss: 13.061585426330566, loss: 12.307880401611328 average time over last 10 steps = 0.8909824609756469\n",
            "step 630, validation loss: 12.964529037475586, loss: 13.043567657470703 average time over last 10 steps = 0.8912937641143799\n",
            "step 640, validation loss: 12.891109466552734, loss: 12.684950828552246 average time over last 10 steps = 0.8902466297149658\n",
            "step 650, validation loss: 12.780793190002441, loss: 13.368701934814453 average time over last 10 steps = 0.88981773853302\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 660, validation loss: 12.764715194702148, loss: 12.559343338012695 average time over last 10 steps = 0.9568391561508178\n",
            "step 670, validation loss: 12.737682342529297, loss: 12.444009780883789 average time over last 10 steps = 0.8916849374771119\n",
            "step 680, validation loss: 12.717988014221191, loss: 12.547184944152832 average time over last 10 steps = 0.8930914163589477\n",
            "step 690, validation loss: 12.679951667785645, loss: 12.141609191894531 average time over last 10 steps = 0.8929422855377197\n",
            "step 700, validation loss: 12.387012481689453, loss: 12.654922485351562 average time over last 10 steps = 0.891751480102539\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 710, validation loss: 12.309062957763672, loss: 12.012516021728516 average time over last 10 steps = 0.9568013906478882\n",
            "step 720, validation loss: 12.283422470092773, loss: 12.704324722290039 average time over last 10 steps = 0.8923783540725708\n",
            "step 730, validation loss: 12.262463569641113, loss: 12.431708335876465 average time over last 10 steps = 0.8928615331649781\n",
            "step 740, validation loss: 12.255205154418945, loss: 12.01528549194336 average time over last 10 steps = 0.8914395093917846\n",
            "step 750, validation loss: 12.305691719055176, loss: 12.490251541137695 average time over last 10 steps = 0.8918359279632568\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 760, validation loss: 12.2599515914917, loss: 12.43838119506836 average time over last 10 steps = 0.9734382152557373\n",
            "step 770, validation loss: 12.283175468444824, loss: 12.720720291137695 average time over last 10 steps = 0.8923866510391235\n",
            "step 780, validation loss: 12.236892700195312, loss: 12.223320007324219 average time over last 10 steps = 0.8913730382919312\n",
            "step 790, validation loss: 12.212847709655762, loss: 12.089142799377441 average time over last 10 steps = 0.8921765804290771\n",
            "step 800, validation loss: 12.254130363464355, loss: 12.059063911437988 average time over last 10 steps = 0.8914139270782471\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "step 810, validation loss: 12.235000610351562, loss: 12.043173789978027 average time over last 10 steps = 0.9588110208511352\n",
            "step 820, validation loss: 12.19282341003418, loss: 11.951713562011719 average time over last 10 steps = 0.8915122270584106\n",
            "step 830, validation loss: 12.14405632019043, loss: 12.272767066955566 average time over last 10 steps = 0.8919720649719238\n",
            "step 840, validation loss: 12.199087142944336, loss: 12.037151336669922 average time over last 10 steps = 0.8911590576171875\n",
            "step 850, validation loss: 12.151554107666016, loss: 12.47172737121582 average time over last 10 steps = 0.8916667699813843\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 860, validation loss: 12.182866096496582, loss: 12.088253021240234 average time over last 10 steps = 0.9555992603302002\n",
            "step 870, validation loss: 12.153827667236328, loss: 12.501849174499512 average time over last 10 steps = 0.8920128822326661\n",
            "step 880, validation loss: 12.17138671875, loss: 12.039158821105957 average time over last 10 steps = 0.8913295984268188\n",
            "step 890, validation loss: 12.166790008544922, loss: 12.31407356262207 average time over last 10 steps = 0.8930047273635864\n",
            "step 900, validation loss: 12.153451919555664, loss: 11.676701545715332 average time over last 10 steps = 0.8908980846405029\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 910, validation loss: 12.116541862487793, loss: 12.357906341552734 average time over last 10 steps = 0.9770131826400756\n",
            "step 920, validation loss: 12.086986541748047, loss: 12.338838577270508 average time over last 10 steps = 0.8911919593811035\n",
            "step 930, validation loss: 12.131875991821289, loss: 12.46180534362793 average time over last 10 steps = 0.8904220819473266\n",
            "step 940, validation loss: 12.169554710388184, loss: 11.85145092010498 average time over last 10 steps = 0.8906250476837159\n",
            "step 950, validation loss: 12.194080352783203, loss: 12.188308715820312 average time over last 10 steps = 0.8899205446243286\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 960, validation loss: 12.20385456085205, loss: 12.10256576538086 average time over last 10 steps = 0.9563170194625854\n",
            "step 970, validation loss: 12.234764099121094, loss: 12.059211730957031 average time over last 10 steps = 0.8900823593139648\n",
            "step 980, validation loss: 12.225408554077148, loss: 11.640018463134766 average time over last 10 steps = 0.8917247295379639\n",
            "step 990, validation loss: 12.224178314208984, loss: 11.522851943969727 average time over last 10 steps = 0.891111159324646\n",
            "step 1000, validation loss: 12.18326187133789, loss: 11.790667533874512 average time over last 10 steps = 0.8911500453948975\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1010, validation loss: 12.194953918457031, loss: 12.106064796447754 average time over last 10 steps = 0.955732798576355\n",
            "step 1020, validation loss: 12.15966796875, loss: 12.015615463256836 average time over last 10 steps = 0.8896548986434937\n",
            "step 1030, validation loss: 12.184871673583984, loss: 12.154481887817383 average time over last 10 steps = 0.8895429372787476\n",
            "step 1040, validation loss: 12.191349983215332, loss: 12.783554077148438 average time over last 10 steps = 0.890540075302124\n",
            "step 1050, validation loss: 12.231374740600586, loss: 12.388788223266602 average time over last 10 steps = 0.8904992580413819\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1060, validation loss: 12.25986385345459, loss: 12.391788482666016 average time over last 10 steps = 0.9736749410629273\n",
            "step 1070, validation loss: 12.251486778259277, loss: 12.045372009277344 average time over last 10 steps = 0.8903373003005981\n",
            "step 1080, validation loss: 12.256280899047852, loss: 11.752469062805176 average time over last 10 steps = 0.8895375490188598\n",
            "step 1090, validation loss: 12.242618560791016, loss: 12.073413848876953 average time over last 10 steps = 0.8910379409790039\n",
            "step 1100, validation loss: 12.26636028289795, loss: 12.205150604248047 average time over last 10 steps = 0.8909230947494506\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1110, validation loss: 12.227699279785156, loss: 12.251686096191406 average time over last 10 steps = 0.9544893026351928\n",
            "step 1120, validation loss: 12.280946731567383, loss: 11.726194381713867 average time over last 10 steps = 0.8914427995681763\n",
            "step 1130, validation loss: 12.257925033569336, loss: 12.487728118896484 average time over last 10 steps = 0.8916719913482666\n",
            "step 1140, validation loss: 12.331048965454102, loss: 12.09412670135498 average time over last 10 steps = 0.8922366857528686\n",
            "step 1150, validation loss: 12.328824996948242, loss: 12.120668411254883 average time over last 10 steps = 0.8923187494277954\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1160, validation loss: 12.34280776977539, loss: 12.232671737670898 average time over last 10 steps = 0.9568181276321411\n",
            "step 1170, validation loss: 12.372709274291992, loss: 11.820351600646973 average time over last 10 steps = 0.8914227962493897\n",
            "step 1180, validation loss: 12.327341079711914, loss: 12.546660423278809 average time over last 10 steps = 0.8913514614105225\n",
            "step 1190, validation loss: 12.306468963623047, loss: 12.098203659057617 average time over last 10 steps = 0.891743803024292\n",
            "step 1200, validation loss: 12.341032028198242, loss: 12.304425239562988 average time over last 10 steps = 0.8914893388748169\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1210, validation loss: 12.283737182617188, loss: 12.294583320617676 average time over last 10 steps = 0.9624272584915161\n",
            "step 1220, validation loss: 12.291316986083984, loss: 11.802316665649414 average time over last 10 steps = 0.8893661499023438\n",
            "step 1230, validation loss: 12.329429626464844, loss: 12.255815505981445 average time over last 10 steps = 0.8902583360671997\n",
            "step 1240, validation loss: 12.335022926330566, loss: 11.735251426696777 average time over last 10 steps = 0.8896078586578369\n",
            "step 1250, validation loss: 12.430594444274902, loss: 11.901527404785156 average time over last 10 steps = 0.8901171445846557\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1260, validation loss: 12.423748016357422, loss: 12.694067001342773 average time over last 10 steps = 0.95539870262146\n",
            "step 1270, validation loss: 12.436018943786621, loss: 12.436447143554688 average time over last 10 steps = 0.8903923511505127\n",
            "step 1280, validation loss: 12.477012634277344, loss: 12.649121284484863 average time over last 10 steps = 0.8930278778076172\n",
            "step 1290, validation loss: 12.513936996459961, loss: 11.757362365722656 average time over last 10 steps = 0.8935652256011963\n",
            "step 1300, validation loss: 12.542905807495117, loss: 13.782031059265137 average time over last 10 steps = 0.8923632144927979\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1310, validation loss: 12.564977645874023, loss: 12.659805297851562 average time over last 10 steps = 0.9581379413604736\n",
            "step 1320, validation loss: 12.569618225097656, loss: 12.25373649597168 average time over last 10 steps = 0.8936314344406128\n",
            "step 1330, validation loss: 12.579068183898926, loss: 12.425378799438477 average time over last 10 steps = 0.8909267902374267\n",
            "step 1340, validation loss: 12.605484008789062, loss: 12.937378883361816 average time over last 10 steps = 0.8935040235519409\n",
            "step 1350, validation loss: 12.664003372192383, loss: 12.28329086303711 average time over last 10 steps = 0.891512107849121\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1360, validation loss: 12.631462097167969, loss: 12.274314880371094 average time over last 10 steps = 0.9561216831207275\n",
            "step 1370, validation loss: 12.635310173034668, loss: 12.397525787353516 average time over last 10 steps = 0.890112829208374\n",
            "step 1380, validation loss: 12.677124977111816, loss: 12.849112510681152 average time over last 10 steps = 0.889948058128357\n",
            "step 1390, validation loss: 12.566102981567383, loss: 12.658428192138672 average time over last 10 steps = 0.8901671648025513\n",
            "step 1400, validation loss: 12.562253952026367, loss: 12.527676582336426 average time over last 10 steps = 0.8916223049163818\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1410, validation loss: 12.565116882324219, loss: 11.976831436157227 average time over last 10 steps = 0.9758105993270874\n",
            "step 1420, validation loss: 12.608996391296387, loss: 12.295631408691406 average time over last 10 steps = 0.8917618513107299\n",
            "step 1430, validation loss: 12.613797187805176, loss: 12.025954246520996 average time over last 10 steps = 0.8996019840240479\n",
            "step 1440, validation loss: 12.627328872680664, loss: 12.573027610778809 average time over last 10 steps = 0.8939421653747559\n",
            "step 1450, validation loss: 12.693737030029297, loss: 12.656332015991211 average time over last 10 steps = 0.8935068130493165\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1460, validation loss: 12.73780632019043, loss: 12.716194152832031 average time over last 10 steps = 0.9585808515548706\n",
            "step 1470, validation loss: 12.734367370605469, loss: 12.86482048034668 average time over last 10 steps = 0.8931386470794678\n",
            "step 1480, validation loss: 12.72618293762207, loss: 12.539447784423828 average time over last 10 steps = 0.8925431489944458\n",
            "step 1490, validation loss: 12.675668716430664, loss: 13.086910247802734 average time over last 10 steps = 0.8927960872650147\n",
            "step 1500, validation loss: 12.74604606628418, loss: 12.243169784545898 average time over last 10 steps = 0.8924068927764892\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1510, validation loss: 12.720813751220703, loss: 12.405570983886719 average time over last 10 steps = 0.9582190752029419\n",
            "step 1520, validation loss: 12.744895935058594, loss: 12.768610954284668 average time over last 10 steps = 0.8927263259887696\n",
            "step 1530, validation loss: 12.752029418945312, loss: 12.244908332824707 average time over last 10 steps = 0.8904220342636109\n",
            "step 1540, validation loss: 12.784290313720703, loss: 12.941497802734375 average time over last 10 steps = 0.8909678936004639\n",
            "step 1550, validation loss: 12.784316062927246, loss: 12.579071044921875 average time over last 10 steps = 0.891316270828247\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1560, validation loss: 12.790977478027344, loss: 12.57055950164795 average time over last 10 steps = 0.9670550107955933\n",
            "step 1570, validation loss: 12.817354202270508, loss: 12.518318176269531 average time over last 10 steps = 0.8908012390136719\n",
            "step 1580, validation loss: 12.805182456970215, loss: 12.660314559936523 average time over last 10 steps = 0.889966344833374\n",
            "step 1590, validation loss: 12.796167373657227, loss: 12.625633239746094 average time over last 10 steps = 0.8918056964874268\n",
            "step 1600, validation loss: 12.799275398254395, loss: 12.37814998626709 average time over last 10 steps = 0.8918380022048951\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m#\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1610, validation loss: 12.78731918334961, loss: 13.26455307006836 average time over last 10 steps = 0.9567508220672607\n",
            "step 1620, validation loss: 12.771340370178223, loss: 12.405980110168457 average time over last 10 steps = 0.8908442258834839\n",
            "step 1630, validation loss: 12.805503845214844, loss: 12.701501846313477 average time over last 10 steps = 0.8926718950271606\n",
            "step 1640, validation loss: 12.811623573303223, loss: 12.347176551818848 average time over last 10 steps = 0.8932915687561035\n",
            "step 1650, validation loss: 12.82384204864502, loss: 12.668601989746094 average time over last 10 steps = 0.8932901859283447\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m#\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1660, validation loss: 12.815035820007324, loss: 12.542806625366211 average time over last 10 steps = 0.9589704513549805\n",
            "step 1670, validation loss: 12.856675148010254, loss: 12.687143325805664 average time over last 10 steps = 0.8919418096542359\n",
            "step 1680, validation loss: 12.878259658813477, loss: 13.266861915588379 average time over last 10 steps = 0.8918306350708007\n",
            "step 1690, validation loss: 12.893447875976562, loss: 12.682823181152344 average time over last 10 steps = 0.8949518203735352\n",
            "step 1700, validation loss: 12.896429061889648, loss: 12.492891311645508 average time over last 10 steps = 0.8932444095611572\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1710, validation loss: 12.892898559570312, loss: 12.162328720092773 average time over last 10 steps = 0.975712513923645\n",
            "step 1720, validation loss: 12.914979934692383, loss: 13.09191608428955 average time over last 10 steps = 0.8936481714248657\n",
            "step 1730, validation loss: 12.919607162475586, loss: 13.339738845825195 average time over last 10 steps = 0.8956737756729126\n",
            "step 1740, validation loss: 12.910501480102539, loss: 11.942770957946777 average time over last 10 steps = 0.8918293476104736\n",
            "step 1750, validation loss: 12.889281272888184, loss: 12.553214073181152 average time over last 10 steps = 0.8930323123931885\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m&\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1760, validation loss: 12.88058853149414, loss: 12.947080612182617 average time over last 10 steps = 0.9599906444549561\n",
            "step 1770, validation loss: 12.854423522949219, loss: 12.406839370727539 average time over last 10 steps = 0.8937766075134277\n",
            "step 1780, validation loss: 12.889662742614746, loss: 12.855752944946289 average time over last 10 steps = 0.8933415174484253\n",
            "step 1790, validation loss: 12.88913631439209, loss: 12.80807113647461 average time over last 10 steps = 0.8945853233337402\n",
            "step 1800, validation loss: 12.907676696777344, loss: 12.74989128112793 average time over last 10 steps = 0.8948726415634155\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m@\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1810, validation loss: 12.911258697509766, loss: 12.792289733886719 average time over last 10 steps = 0.9594050645828247\n",
            "step 1820, validation loss: 12.887277603149414, loss: 12.773733139038086 average time over last 10 steps = 0.8943005323410034\n",
            "step 1830, validation loss: 12.932896614074707, loss: 12.244579315185547 average time over last 10 steps = 0.8941384792327881\n",
            "step 1840, validation loss: 12.903253555297852, loss: 12.56556510925293 average time over last 10 steps = 0.8940759420394897\n",
            "step 1850, validation loss: 12.902128219604492, loss: 12.86032772064209 average time over last 10 steps = 0.8933451175689697\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1860, validation loss: 12.864956855773926, loss: 12.691356658935547 average time over last 10 steps = 0.9577907085418701\n",
            "step 1870, validation loss: 12.907041549682617, loss: 12.625612258911133 average time over last 10 steps = 0.8930204391479493\n",
            "step 1880, validation loss: 12.8582763671875, loss: 12.77713394165039 average time over last 10 steps = 0.894283127784729\n",
            "step 1890, validation loss: 12.812161445617676, loss: 13.4263916015625 average time over last 10 steps = 0.8930068254470825\n",
            "step 1900, validation loss: 12.80029296875, loss: 13.252264022827148 average time over last 10 steps = 0.8931549072265625\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1910, validation loss: 12.798524856567383, loss: 12.848297119140625 average time over last 10 steps = 0.9594984531402588\n",
            "step 1920, validation loss: 12.795232772827148, loss: 13.194429397583008 average time over last 10 steps = 0.8955411195755005\n",
            "step 1930, validation loss: 12.807645797729492, loss: 12.913583755493164 average time over last 10 steps = 0.8933537244796753\n",
            "step 1940, validation loss: 12.767414093017578, loss: 13.100969314575195 average time over last 10 steps = 0.895216989517212\n",
            "step 1950, validation loss: 12.775264739990234, loss: 12.232264518737793 average time over last 10 steps = 0.8953996419906616\n",
            "Allocated: 6.82 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1960, validation loss: 12.74741268157959, loss: 12.729705810546875 average time over last 10 steps = 0.9602553606033325\n",
            "step 1970, validation loss: 12.735977172851562, loss: 12.11794376373291 average time over last 10 steps = 0.8960253000259399\n",
            "step 1980, validation loss: 12.796350479125977, loss: 12.166800498962402 average time over last 10 steps = 0.8942986726760864\n",
            "step 1990, validation loss: 12.743013381958008, loss: 12.303424835205078 average time over last 10 steps = 0.8947361707687378\n",
            "step 2000, validation loss: 12.740524291992188, loss: 12.506715774536133 average time over last 10 steps = 0.8954350471496582\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_loop_multi_optimizer(2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "sZuP5CTlWPVD",
      "metadata": {
        "id": "sZuP5CTlWPVD"
      },
      "outputs": [],
      "source": [
        "# Get current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the filename with timestamp\n",
        "filename = f\"gpt_weights_{timestamp}.pth\"\n",
        "\n",
        "# save gpt model weights to drive\n",
        "torch.save(gpt.state_dict(), f'/content/drive/MyDrive/{filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "xzNNfXNw4O8v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzNNfXNw4O8v",
        "outputId": "91d2755e-5ec4-4f16-cb0f-4b194cefad6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.41 GB\n",
            "After\n",
            "Allocated: 3.64 GB\n",
            "Cached: 6.55 GB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import gc\n",
        "\n",
        "print(f\"before\\nAllocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "\n",
        "gc.collect()\n",
        "# clear cuda cache\n",
        "torch.cuda.empty_cache()\n",
        "# works on gpu\n",
        "print(f\"After\\nAllocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "hp_0CsH3GWUf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp_0CsH3GWUf",
        "outputId": "6f0d1043-e862-4b3d-b87e-1927f2094df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0, validation loss: 11.120105743408203, loss: 11.24026107788086 average time over last 10 steps = 0.08760862350463867\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 10, validation loss: 11.174046516418457, loss: 10.50890827178955 average time over last 10 steps = 0.9533025979995727\n",
            "step 20, validation loss: 11.161905288696289, loss: 11.279253959655762 average time over last 10 steps = 0.9092679023742676\n",
            "step 30, validation loss: 11.18229866027832, loss: 11.255881309509277 average time over last 10 steps = 0.9301250457763672\n",
            "step 40, validation loss: 11.221992492675781, loss: 10.748320579528809 average time over last 10 steps = 0.9184548616409302\n",
            "step 50, validation loss: 11.19753360748291, loss: 10.920358657836914 average time over last 10 steps = 0.9001552581787109\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 60, validation loss: 11.224199295043945, loss: 11.041377067565918 average time over last 10 steps = 0.9864138841629029\n",
            "step 70, validation loss: 11.230936050415039, loss: 10.948351860046387 average time over last 10 steps = 0.8827142715454102\n",
            "step 80, validation loss: 11.226024627685547, loss: 11.077827453613281 average time over last 10 steps = 0.8790231943130493\n",
            "step 90, validation loss: 11.206039428710938, loss: 11.311827659606934 average time over last 10 steps = 0.8805130243301391\n",
            "step 100, validation loss: 11.193504333496094, loss: 10.625128746032715 average time over last 10 steps = 0.8862040042877197\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 110, validation loss: 11.221549034118652, loss: 11.154467582702637 average time over last 10 steps = 0.9550117254257202\n",
            "step 120, validation loss: 11.185070991516113, loss: 10.995574951171875 average time over last 10 steps = 0.8984235048294067\n",
            "step 130, validation loss: 11.165312767028809, loss: 10.985836029052734 average time over last 10 steps = 0.9005699634552002\n",
            "step 140, validation loss: 11.194710731506348, loss: 10.774700164794922 average time over last 10 steps = 0.9003509044647217\n",
            "step 150, validation loss: 11.170248985290527, loss: 11.12603759765625 average time over last 10 steps = 0.8978275537490845\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 160, validation loss: 11.135141372680664, loss: 11.305997848510742 average time over last 10 steps = 0.9606960773468017\n",
            "step 170, validation loss: 11.190469741821289, loss: 10.429780006408691 average time over last 10 steps = 0.8923393249511719\n",
            "step 180, validation loss: 11.158734321594238, loss: 10.840030670166016 average time over last 10 steps = 0.8898828506469727\n",
            "step 190, validation loss: 11.168259620666504, loss: 11.362601280212402 average time over last 10 steps = 0.8893952608108521\n",
            "step 200, validation loss: 11.152734756469727, loss: 11.909194946289062 average time over last 10 steps = 0.8909868001937866\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 210, validation loss: 11.106521606445312, loss: 10.972761154174805 average time over last 10 steps = 0.9882023334503174\n",
            "step 220, validation loss: 11.103631973266602, loss: 10.741783142089844 average time over last 10 steps = 0.8941129207611084\n",
            "step 230, validation loss: 11.15416145324707, loss: 10.954263687133789 average time over last 10 steps = 0.8953722238540649\n",
            "step 240, validation loss: 11.138824462890625, loss: 11.029879570007324 average time over last 10 steps = 0.8948453187942504\n",
            "step 250, validation loss: 11.101675987243652, loss: 10.874696731567383 average time over last 10 steps = 0.8946120738983154\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m&\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 260, validation loss: 11.079885482788086, loss: 10.801230430603027 average time over last 10 steps = 0.9602296352386475\n",
            "step 270, validation loss: 11.12891960144043, loss: 10.668047904968262 average time over last 10 steps = 0.8924601793289184\n",
            "step 280, validation loss: 11.174650192260742, loss: 10.793107986450195 average time over last 10 steps = 0.8930206060409546\n",
            "step 290, validation loss: 11.172630310058594, loss: 11.36413288116455 average time over last 10 steps = 0.8912630796432495\n",
            "step 300, validation loss: 11.144659042358398, loss: 10.606319427490234 average time over last 10 steps = 0.8926045894622803\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 310, validation loss: 11.137285232543945, loss: 11.398797988891602 average time over last 10 steps = 0.9557832479476929\n",
            "step 320, validation loss: 11.145811080932617, loss: 11.366331100463867 average time over last 10 steps = 0.891176986694336\n",
            "step 330, validation loss: 11.144716262817383, loss: 11.341230392456055 average time over last 10 steps = 0.8913133859634399\n",
            "step 340, validation loss: 11.150899887084961, loss: 11.027992248535156 average time over last 10 steps = 0.8906470537185669\n",
            "step 350, validation loss: 11.163681030273438, loss: 11.293350219726562 average time over last 10 steps = 0.8914417266845703\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m$\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 360, validation loss: 11.139866828918457, loss: 11.560338973999023 average time over last 10 steps = 0.985961651802063\n",
            "step 370, validation loss: 11.11854362487793, loss: 10.849237442016602 average time over last 10 steps = 0.8920796394348145\n",
            "step 380, validation loss: 11.083442687988281, loss: 11.054415702819824 average time over last 10 steps = 0.8924045085906982\n",
            "step 390, validation loss: 11.103048324584961, loss: 11.317415237426758 average time over last 10 steps = 0.8930426359176635\n",
            "step 400, validation loss: 11.15953540802002, loss: 11.18134593963623 average time over last 10 steps = 0.8914464712142944\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m$\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 410, validation loss: 11.167149543762207, loss: 11.098777770996094 average time over last 10 steps = 0.9575826168060303\n",
            "step 420, validation loss: 11.16871452331543, loss: 11.004451751708984 average time over last 10 steps = 0.8931976318359375\n",
            "step 430, validation loss: 11.146378517150879, loss: 11.262166976928711 average time over last 10 steps = 0.8909433364868165\n",
            "step 440, validation loss: 11.170430183410645, loss: 10.969850540161133 average time over last 10 steps = 0.8912857294082641\n",
            "step 450, validation loss: 11.17837905883789, loss: 10.616948127746582 average time over last 10 steps = 0.8922250270843506\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m&\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 460, validation loss: 11.139213562011719, loss: 11.039758682250977 average time over last 10 steps = 0.954319953918457\n",
            "step 470, validation loss: 11.134942054748535, loss: 10.941370010375977 average time over last 10 steps = 0.8939313173294068\n",
            "step 480, validation loss: 11.11025333404541, loss: 11.597188949584961 average time over last 10 steps = 0.8923047780990601\n",
            "step 490, validation loss: 11.126564025878906, loss: 10.83504581451416 average time over last 10 steps = 0.892662787437439\n",
            "step 500, validation loss: 11.121525764465332, loss: 11.003423690795898 average time over last 10 steps = 0.8918774843215942\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 510, validation loss: 11.170147895812988, loss: 11.349594116210938 average time over last 10 steps = 0.9885377883911133\n",
            "step 520, validation loss: 11.141756057739258, loss: 11.491842269897461 average time over last 10 steps = 0.892053771018982\n",
            "step 530, validation loss: 11.127192497253418, loss: 10.910738945007324 average time over last 10 steps = 0.8928107976913452\n",
            "step 540, validation loss: 11.124670028686523, loss: 11.3460111618042 average time over last 10 steps = 0.8937151193618774\n",
            "step 550, validation loss: 11.142068862915039, loss: 12.145439147949219 average time over last 10 steps = 0.8927708148956299\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 560, validation loss: 11.1583251953125, loss: 11.649698257446289 average time over last 10 steps = 0.9585420608520507\n",
            "step 570, validation loss: 11.171659469604492, loss: 11.163385391235352 average time over last 10 steps = 0.8929498672485352\n",
            "step 580, validation loss: 11.171730995178223, loss: 10.97079086303711 average time over last 10 steps = 0.8929412841796875\n",
            "step 590, validation loss: 11.164970397949219, loss: 11.798628807067871 average time over last 10 steps = 0.8938133716583252\n",
            "step 600, validation loss: 11.138385772705078, loss: 11.358254432678223 average time over last 10 steps = 0.8935219526290894\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 610, validation loss: 11.152332305908203, loss: 11.093116760253906 average time over last 10 steps = 0.9565505743026733\n",
            "step 620, validation loss: 11.10567855834961, loss: 10.967485427856445 average time over last 10 steps = 0.8927409887313843\n",
            "step 630, validation loss: 11.147064208984375, loss: 11.10197639465332 average time over last 10 steps = 0.8906545639038086\n",
            "step 640, validation loss: 11.131195068359375, loss: 10.932634353637695 average time over last 10 steps = 0.890180516242981\n",
            "step 650, validation loss: 11.153098106384277, loss: 10.931089401245117 average time over last 10 steps = 0.8903709173202514\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 660, validation loss: 11.175148010253906, loss: 11.87327766418457 average time over last 10 steps = 0.9885312795639039\n",
            "step 670, validation loss: 11.21386432647705, loss: 11.19468879699707 average time over last 10 steps = 0.8912763357162475\n",
            "step 680, validation loss: 11.190910339355469, loss: 10.988494873046875 average time over last 10 steps = 0.8931225776672364\n",
            "step 690, validation loss: 11.122822761535645, loss: 10.506051063537598 average time over last 10 steps = 0.8924831628799439\n",
            "step 700, validation loss: 10.9822998046875, loss: 10.935629844665527 average time over last 10 steps = 0.8934957027435303\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 710, validation loss: 10.950871467590332, loss: 10.849849700927734 average time over last 10 steps = 0.9582503318786622\n",
            "step 720, validation loss: 10.950326919555664, loss: 11.52324390411377 average time over last 10 steps = 0.8925613164901733\n",
            "step 730, validation loss: 10.945680618286133, loss: 11.363039016723633 average time over last 10 steps = 0.8932045936584473\n",
            "step 740, validation loss: 10.966842651367188, loss: 11.091901779174805 average time over last 10 steps = 0.8916066408157348\n",
            "step 750, validation loss: 10.931260108947754, loss: 11.639535903930664 average time over last 10 steps = 0.89402174949646\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 760, validation loss: 10.943467140197754, loss: 10.856948852539062 average time over last 10 steps = 0.9570358514785766\n",
            "step 770, validation loss: 10.998443603515625, loss: 10.876309394836426 average time over last 10 steps = 0.8918946981430054\n",
            "step 780, validation loss: 11.009283065795898, loss: 10.64204216003418 average time over last 10 steps = 0.8936597347259522\n",
            "step 790, validation loss: 10.9749755859375, loss: 11.095571517944336 average time over last 10 steps = 0.8945398569107056\n",
            "step 800, validation loss: 10.976137161254883, loss: 10.729808807373047 average time over last 10 steps = 0.8943576812744141\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 810, validation loss: 11.033041000366211, loss: 10.871259689331055 average time over last 10 steps = 0.9861973047256469\n",
            "step 820, validation loss: 11.042155265808105, loss: 11.089706420898438 average time over last 10 steps = 0.8931859254837036\n",
            "step 830, validation loss: 11.046566009521484, loss: 10.839969635009766 average time over last 10 steps = 0.8921266078948975\n",
            "step 840, validation loss: 11.047355651855469, loss: 11.108159065246582 average time over last 10 steps = 0.8923684358596802\n",
            "step 850, validation loss: 11.063501358032227, loss: 10.923006057739258 average time over last 10 steps = 0.8928442478179932\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 860, validation loss: 11.042280197143555, loss: 11.489506721496582 average time over last 10 steps = 0.9589567184448242\n",
            "step 870, validation loss: 11.050037384033203, loss: 11.11008071899414 average time over last 10 steps = 0.8942222356796264\n",
            "step 880, validation loss: 11.110538482666016, loss: 10.673908233642578 average time over last 10 steps = 0.892652940750122\n",
            "step 890, validation loss: 11.05873966217041, loss: 11.441858291625977 average time over last 10 steps = 0.8937747240066528\n",
            "step 900, validation loss: 11.026384353637695, loss: 11.011348724365234 average time over last 10 steps = 0.8932254076004028\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 910, validation loss: 11.035694122314453, loss: 11.352161407470703 average time over last 10 steps = 0.9598038911819458\n",
            "step 920, validation loss: 11.066373825073242, loss: 11.008081436157227 average time over last 10 steps = 0.8924830913543701\n",
            "step 930, validation loss: 11.093238830566406, loss: 11.113235473632812 average time over last 10 steps = 0.8933250188827515\n",
            "step 940, validation loss: 11.084695816040039, loss: 11.039009094238281 average time over last 10 steps = 0.8928231954574585\n",
            "step 950, validation loss: 11.080525398254395, loss: 10.600902557373047 average time over last 10 steps = 0.8923681259155274\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 960, validation loss: 11.105474472045898, loss: 10.801704406738281 average time over last 10 steps = 0.9859163284301757\n",
            "step 970, validation loss: 11.088065147399902, loss: 11.017999649047852 average time over last 10 steps = 0.8918534994125367\n",
            "step 980, validation loss: 11.077627182006836, loss: 11.272222518920898 average time over last 10 steps = 0.8915672063827514\n",
            "step 990, validation loss: 11.06955337524414, loss: 10.61778736114502 average time over last 10 steps = 0.8928831815719604\n",
            "step 1000, validation loss: 11.06561279296875, loss: 10.89923095703125 average time over last 10 steps = 0.8921111822128296\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1010, validation loss: 11.056337356567383, loss: 10.937789916992188 average time over last 10 steps = 0.9576662063598633\n",
            "step 1020, validation loss: 11.068807601928711, loss: 10.87673568725586 average time over last 10 steps = 0.8946446895599365\n",
            "step 1030, validation loss: 11.10702896118164, loss: 10.230276107788086 average time over last 10 steps = 0.8937602043151855\n",
            "step 1040, validation loss: 11.158978462219238, loss: 11.239765167236328 average time over last 10 steps = 0.8951214551925659\n",
            "step 1050, validation loss: 11.175660133361816, loss: 10.768640518188477 average time over last 10 steps = 0.8944504499435425\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1060, validation loss: 11.171576499938965, loss: 10.867158889770508 average time over last 10 steps = 0.9611021518707276\n",
            "step 1070, validation loss: 11.185041427612305, loss: 10.884888648986816 average time over last 10 steps = 0.8947386741638184\n",
            "step 1080, validation loss: 11.183549880981445, loss: 10.671300888061523 average time over last 10 steps = 0.8936326026916503\n",
            "step 1090, validation loss: 11.130362510681152, loss: 10.793041229248047 average time over last 10 steps = 0.8934995174407959\n",
            "step 1100, validation loss: 11.121923446655273, loss: 10.627423286437988 average time over last 10 steps = 0.8934783220291138\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1110, validation loss: 11.152483940124512, loss: 11.018754959106445 average time over last 10 steps = 0.9903931140899658\n",
            "step 1120, validation loss: 11.132813453674316, loss: 10.722112655639648 average time over last 10 steps = 0.8944784164428711\n",
            "step 1130, validation loss: 11.181233406066895, loss: 10.464166641235352 average time over last 10 steps = 0.8942557811737061\n",
            "step 1140, validation loss: 11.203804016113281, loss: 10.747563362121582 average time over last 10 steps = 0.8941538572311402\n",
            "step 1150, validation loss: 11.2005615234375, loss: 10.656437873840332 average time over last 10 steps = 0.8945266723632812\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1160, validation loss: 11.138618469238281, loss: 11.07396411895752 average time over last 10 steps = 0.9601688623428345\n",
            "step 1170, validation loss: 11.15884780883789, loss: 10.959552764892578 average time over last 10 steps = 0.8924428462982178\n",
            "step 1180, validation loss: 11.174222946166992, loss: 10.789510726928711 average time over last 10 steps = 0.893232798576355\n",
            "step 1190, validation loss: 11.173904418945312, loss: 11.703088760375977 average time over last 10 steps = 0.8943110466003418\n",
            "step 1200, validation loss: 11.128876686096191, loss: 11.594215393066406 average time over last 10 steps = 0.89393310546875\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1210, validation loss: 11.089365005493164, loss: 11.093382835388184 average time over last 10 steps = 0.9573828697204589\n",
            "step 1220, validation loss: 11.075481414794922, loss: 10.739734649658203 average time over last 10 steps = 0.8930314302444458\n",
            "step 1230, validation loss: 11.107575416564941, loss: 11.098688125610352 average time over last 10 steps = 0.8921680927276612\n",
            "step 1240, validation loss: 11.124531745910645, loss: 10.842390060424805 average time over last 10 steps = 0.8924100399017334\n",
            "step 1250, validation loss: 11.139127731323242, loss: 11.152488708496094 average time over last 10 steps = 0.8917178392410279\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1260, validation loss: 11.165681838989258, loss: 11.393500328063965 average time over last 10 steps = 0.9888726949691773\n",
            "step 1270, validation loss: 11.161233901977539, loss: 11.107343673706055 average time over last 10 steps = 0.8921149015426636\n",
            "step 1280, validation loss: 11.109968185424805, loss: 11.326915740966797 average time over last 10 steps = 0.89268958568573\n",
            "step 1290, validation loss: 11.046722412109375, loss: 11.708711624145508 average time over last 10 steps = 0.8930334329605103\n",
            "step 1300, validation loss: 11.029820442199707, loss: 11.313629150390625 average time over last 10 steps = 0.8946834802627563\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1310, validation loss: 10.993247985839844, loss: 11.077936172485352 average time over last 10 steps = 0.9585641860961914\n",
            "step 1320, validation loss: 11.00909423828125, loss: 11.084755897521973 average time over last 10 steps = 0.8951816082000732\n",
            "step 1330, validation loss: 11.019123077392578, loss: 10.913619995117188 average time over last 10 steps = 0.8955615282058715\n",
            "step 1340, validation loss: 11.008342742919922, loss: 11.189492225646973 average time over last 10 steps = 0.8959956407546997\n",
            "step 1350, validation loss: 11.00298023223877, loss: 10.936814308166504 average time over last 10 steps = 0.895092511177063\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1360, validation loss: 11.048405647277832, loss: 10.63309097290039 average time over last 10 steps = 0.9640479803085327\n",
            "step 1370, validation loss: 11.025541305541992, loss: 11.310669898986816 average time over last 10 steps = 0.8957121849060059\n",
            "step 1380, validation loss: 11.017078399658203, loss: 10.810179710388184 average time over last 10 steps = 0.8947958469390869\n",
            "step 1390, validation loss: 10.840923309326172, loss: 11.108928680419922 average time over last 10 steps = 0.8941370964050293\n",
            "step 1400, validation loss: 10.846441268920898, loss: 10.45075798034668 average time over last 10 steps = 0.894046688079834\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1410, validation loss: 10.85867977142334, loss: 11.18748664855957 average time over last 10 steps = 0.9905734539031983\n",
            "step 1420, validation loss: 10.893333435058594, loss: 11.120450019836426 average time over last 10 steps = 0.8936216831207275\n",
            "step 1430, validation loss: 10.876312255859375, loss: 10.62807846069336 average time over last 10 steps = 0.8942812204360961\n",
            "step 1440, validation loss: 10.854835510253906, loss: 10.843913078308105 average time over last 10 steps = 0.8930768251419068\n",
            "step 1450, validation loss: 10.843793869018555, loss: 11.09286880493164 average time over last 10 steps = 0.8930790901184082\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1460, validation loss: 10.88815689086914, loss: 10.895951271057129 average time over last 10 steps = 0.9583420276641845\n",
            "step 1470, validation loss: 10.911619186401367, loss: 11.019407272338867 average time over last 10 steps = 0.8917523860931397\n",
            "step 1480, validation loss: 10.927143096923828, loss: 11.259184837341309 average time over last 10 steps = 0.8911379098892211\n",
            "step 1490, validation loss: 10.919098854064941, loss: 10.522001266479492 average time over last 10 steps = 0.8906419754028321\n",
            "step 1500, validation loss: 10.92989730834961, loss: 10.99145793914795 average time over last 10 steps = 0.8903821706771851\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1510, validation loss: 10.98187255859375, loss: 10.856380462646484 average time over last 10 steps = 0.9574704170227051\n",
            "step 1520, validation loss: 10.991800308227539, loss: 10.883316040039062 average time over last 10 steps = 0.8920508623123169\n",
            "step 1530, validation loss: 11.01092529296875, loss: 10.615739822387695 average time over last 10 steps = 0.8923617124557495\n",
            "step 1540, validation loss: 10.955429077148438, loss: 11.029010772705078 average time over last 10 steps = 0.8907882690429687\n",
            "step 1550, validation loss: 10.963869094848633, loss: 11.284337043762207 average time over last 10 steps = 0.8924486398696899\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1560, validation loss: 11.033700942993164, loss: 10.371448516845703 average time over last 10 steps = 0.9858592987060547\n",
            "step 1570, validation loss: 11.048799514770508, loss: 10.798116683959961 average time over last 10 steps = 0.8924840450286865\n",
            "step 1580, validation loss: 11.067461967468262, loss: 11.201105117797852 average time over last 10 steps = 0.8925596952438355\n",
            "step 1590, validation loss: 11.051506042480469, loss: 11.892715454101562 average time over last 10 steps = 0.8928714513778686\n",
            "step 1600, validation loss: 11.042062759399414, loss: 10.745316505432129 average time over last 10 steps = 0.8946189641952514\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1610, validation loss: 11.021306991577148, loss: 10.608139991760254 average time over last 10 steps = 0.9605983257293701\n",
            "step 1620, validation loss: 11.063133239746094, loss: 10.906912803649902 average time over last 10 steps = 0.8924281120300293\n",
            "step 1630, validation loss: 11.042139053344727, loss: 11.008203506469727 average time over last 10 steps = 0.8942707061767579\n",
            "step 1640, validation loss: 11.086129188537598, loss: 10.74112319946289 average time over last 10 steps = 0.8933166980743408\n",
            "step 1650, validation loss: 11.075857162475586, loss: 10.715412139892578 average time over last 10 steps = 0.8929193019866943\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\n",
            "\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1660, validation loss: 11.077604293823242, loss: 10.632295608520508 average time over last 10 steps = 0.9591432571411133\n",
            "step 1670, validation loss: 11.10683822631836, loss: 10.775938034057617 average time over last 10 steps = 0.8917307615280151\n",
            "step 1680, validation loss: 11.07514762878418, loss: 11.244956970214844 average time over last 10 steps = 0.8918819189071655\n",
            "step 1690, validation loss: 11.056873321533203, loss: 10.492746353149414 average time over last 10 steps = 0.8914403438568115\n",
            "step 1700, validation loss: 11.054807662963867, loss: 11.068370819091797 average time over last 10 steps = 0.893134593963623\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1710, validation loss: 11.062469482421875, loss: 11.41120433807373 average time over last 10 steps = 0.9812668085098266\n",
            "step 1720, validation loss: 11.045692443847656, loss: 11.228601455688477 average time over last 10 steps = 0.8940886497497559\n",
            "step 1730, validation loss: 11.022677421569824, loss: 10.978899002075195 average time over last 10 steps = 0.8943118572235107\n",
            "step 1740, validation loss: 11.027414321899414, loss: 11.071109771728516 average time over last 10 steps = 0.8919767618179322\n",
            "step 1750, validation loss: 11.080638885498047, loss: 11.441899299621582 average time over last 10 steps = 0.8909543037414551\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1760, validation loss: 11.085447311401367, loss: 10.756816864013672 average time over last 10 steps = 0.9602031230926513\n",
            "step 1770, validation loss: 11.075275421142578, loss: 10.982799530029297 average time over last 10 steps = 0.8942898750305176\n",
            "step 1780, validation loss: 11.07040786743164, loss: 11.078855514526367 average time over last 10 steps = 0.8952810049057007\n",
            "step 1790, validation loss: 11.01162338256836, loss: 11.084800720214844 average time over last 10 steps = 0.8979249000549316\n",
            "step 1800, validation loss: 10.99730396270752, loss: 10.791730880737305 average time over last 10 steps = 0.8969212770462036\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1810, validation loss: 10.960565567016602, loss: 10.77801513671875 average time over last 10 steps = 0.9579171657562255\n",
            "step 1820, validation loss: 10.968612670898438, loss: 11.129980087280273 average time over last 10 steps = 0.8931981086730957\n",
            "step 1830, validation loss: 10.981319427490234, loss: 10.835343360900879 average time over last 10 steps = 0.8918022871017456\n",
            "step 1840, validation loss: 11.051393508911133, loss: 10.652917861938477 average time over last 10 steps = 0.8901867628097534\n",
            "step 1850, validation loss: 11.040821075439453, loss: 10.941164016723633 average time over last 10 steps = 0.8903964757919312\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1860, validation loss: 11.036855697631836, loss: 10.976432800292969 average time over last 10 steps = 0.9834291934967041\n",
            "step 1870, validation loss: 10.995686531066895, loss: 11.4851655960083 average time over last 10 steps = 0.8932791233062745\n",
            "step 1880, validation loss: 11.029382705688477, loss: 10.82928466796875 average time over last 10 steps = 0.8942777156829834\n",
            "step 1890, validation loss: 11.016711235046387, loss: 10.875883102416992 average time over last 10 steps = 0.8968477725982666\n",
            "step 1900, validation loss: 10.942806243896484, loss: 11.238265991210938 average time over last 10 steps = 0.8965873956680298\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1910, validation loss: 10.971236228942871, loss: 11.562630653381348 average time over last 10 steps = 0.9574470520019531\n",
            "step 1920, validation loss: 10.987789154052734, loss: 10.819940567016602 average time over last 10 steps = 0.8947349309921264\n",
            "step 1930, validation loss: 11.001640319824219, loss: 11.190990447998047 average time over last 10 steps = 0.8955025911331177\n",
            "step 1940, validation loss: 10.97036361694336, loss: 12.002626419067383 average time over last 10 steps = 0.8940979719161988\n",
            "step 1950, validation loss: 10.991698265075684, loss: 11.483003616333008 average time over last 10 steps = 0.8936380863189697\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m \u001b[0m\u001b[42m\n",
            "\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m \u001b[0m\u001b[41m\n",
            "\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "step 1960, validation loss: 10.97623348236084, loss: 10.946013450622559 average time over last 10 steps = 0.9576926946640014\n",
            "step 1970, validation loss: 10.970142364501953, loss: 10.805713653564453 average time over last 10 steps = 0.8925469160079956\n",
            "step 1980, validation loss: 10.990878105163574, loss: 11.621583938598633 average time over last 10 steps = 0.8914655685424805\n",
            "step 1990, validation loss: 11.00988483428955, loss: 11.377504348754883 average time over last 10 steps = 0.8922635793685914\n",
            "step 2000, validation loss: 10.977300643920898, loss: 10.967364311218262 average time over last 10 steps = 0.8930742263793945\n",
            "Allocated: 6.83 GB\n",
            "Cached: 12.58 GB\n",
            "\n",
            "\u001b[41mProject\u001b[0m\u001b[42m Gutenberg\u001b[0m\u001b[43m is\u001b[0m\u001b[44m\n",
            "\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n",
            "\u001b[41mHe\u001b[0m\u001b[42m was\u001b[0m\u001b[43m the\u001b[0m\u001b[44m main\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\n",
            "\n",
            "\u001b[41mThe\u001b[0m\u001b[42m place\u001b[0m\u001b[43m is\u001b[0m\u001b[44m well\u001b[0m\u001b[41m known\u001b[0m\u001b[42m for\u001b[0m\u001b[43m its\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\u001b[41m\t\u001b[0m\u001b[42m\t\u001b[0m\u001b[43m\t\u001b[0m\u001b[44m\t\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_loop_multi_optimizer(2000)\n",
        "# Get current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the filename with timestamp\n",
        "filename = f\"gpt_weights_{timestamp}.pth\"\n",
        "\n",
        "# save gpt model weights to drive\n",
        "torch.save(gpt.state_dict(), f'/content/drive/MyDrive/{filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7FcqXx_xZZqD",
      "metadata": {
        "id": "7FcqXx_xZZqD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
